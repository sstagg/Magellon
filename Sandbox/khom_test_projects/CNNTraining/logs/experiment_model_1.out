
TRAINING OVERVIEW
-------------------------------
OPTIMIZER:
 Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0.0001
) 
-------------------------------
LOSS FUNCTION:
 MSELoss() 
-------------------------------
MODEL ARCHITECTURE:
 MRCNetwork(
  (cnn_network): Sequential(
    (0): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): Dropout(p=0.25, inplace=False)
    (2): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (3): Dropout(p=0.25, inplace=False)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2))
    (5): Dropout(p=0.25, inplace=False)
    (6): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (7): Dropout(p=0.25, inplace=False)
    (8): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (9): Dropout(p=0.25, inplace=False)
    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))
    (11): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (12): Dropout(p=0.25, inplace=False)
    (13): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
    )
    (14): Dropout(p=0.25, inplace=False)
    (15): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
    )
    (16): Dropout(p=0.25, inplace=False)
    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))
    (18): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (19): Dropout(p=0.25, inplace=False)
    (20): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
    )
    (21): Dropout(p=0.25, inplace=False)
    (22): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
    )
    (23): Dropout(p=0.25, inplace=False)
    (24): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
    (25): AdaptiveAvgPool2d(output_size=(6, 6))
    (26): Dropout(p=0.25, inplace=False)
    (27): Flatten(start_dim=1, end_dim=-1)
    (28): Linear(in_features=4608, out_features=64, bias=True)
    (29): ReLU()
    (30): Dropout(p=0.25, inplace=False)
  )
  (feat_network): Sequential(
    (0): Linear(in_features=67, out_features=16, bias=True)
    (1): ReLU()
    (2): Linear(in_features=16, out_features=1, bias=True)
  )
) 
-------------------------------
OTHER:
Training with batch size of 1
Running on device cuda:0
Split 10.00% of data for validation data
Preparing to train in parallel: main device on cuda:0, all devices on [0, 1]
Will save model to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
-------------------------------

Fetching MRC image data (mode: hdf5) from /nfs/home/khom/data-vlen2.hdf5
Reshaping data: True
Fetching MRC image data (mode: hdf5) from /nfs/home/khom/data-vlen2.hdf5
Reshaping data: True
Selecting subset of size 23750 out of 26389
Selecting subset of size 2639 out of 26389
Ready to train

Beginning training for 120 epochs (from epoch 1)...
Epoch 1
-------------------------------
Batch 3201/23750, loss: 8.719760  [ 3201/23750] (109.906s) val loss: 1.908382
Batch 6401/23750, loss: 6.413660  [ 6401/23750] (151.207s) val loss: 1.220492
Batch 9601/23750, loss: 0.300850  [ 9601/23750] (149.704s) val loss: 0.559097
Batch 12801/23750, loss: 0.041292  [12801/23750] (149.587s) val loss: 0.226009
Batch 16001/23750, loss: 0.004247  [16001/23750] (146.570s) val loss: 0.144672
Batch 19201/23750, loss: 4.476905  [19201/23750] (145.271s) val loss: 0.253188
Batch 22401/23750, loss: 0.694535  [22401/23750] (144.855s) val loss: 0.079017
Batch 23750/23750, loss: 0.047785  [23750/23750] (83.563s) val loss: 0.145705
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1122.139s total
-------------------------------

Epoch 2
-------------------------------
Batch 3201/23750, loss: 0.003575  [ 3201/23750] (105.740s) val loss: 0.077498
Batch 6401/23750, loss: 0.039049  [ 6401/23750] (143.358s) val loss: 0.073540
Batch 9601/23750, loss: 0.036304  [ 9601/23750] (143.591s) val loss: 0.069370
Batch 12801/23750, loss: 0.031660  [12801/23750] (143.741s) val loss: 0.070367
Batch 16001/23750, loss: 0.002244  [16001/23750] (143.588s) val loss: 0.093507
Batch 19201/23750, loss: 0.015714  [19201/23750] (143.799s) val loss: 0.071842
Batch 22401/23750, loss: 0.002206  [22401/23750] (143.856s) val loss: 0.082050
Batch 23750/23750, loss: 0.000018  [23750/23750] (83.109s) val loss: 0.071632
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.729s total
-------------------------------

Epoch 3
-------------------------------
Batch 3201/23750, loss: 0.374191  [ 3201/23750] (105.261s) val loss: 0.070089
Batch 6401/23750, loss: 0.034286  [ 6401/23750] (143.684s) val loss: 0.066309
Batch 9601/23750, loss: 0.000696  [ 9601/23750] (143.717s) val loss: 0.063199
Batch 12801/23750, loss: 0.182865  [12801/23750] (146.470s) val loss: 0.062294
Batch 16001/23750, loss: 0.075741  [16001/23750] (147.758s) val loss: 0.065987
Batch 19201/23750, loss: 0.000146  [19201/23750] (147.078s) val loss: 0.064339
Batch 22401/23750, loss: 0.058162  [22401/23750] (147.588s) val loss: 0.060914
Batch 23750/23750, loss: 0.014715  [23750/23750] (84.692s) val loss: 0.059485
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1105.862s total
-------------------------------

Epoch 4
-------------------------------
Batch 3201/23750, loss: 0.062988  [ 3201/23750] (105.080s) val loss: 0.058096
Batch 6401/23750, loss: 0.130666  [ 6401/23750] (144.125s) val loss: 0.058187
Batch 9601/23750, loss: 0.052397  [ 9601/23750] (146.549s) val loss: 0.076948
Batch 12801/23750, loss: 0.259119  [12801/23750] (147.976s) val loss: 0.060531
Batch 16001/23750, loss: 0.012107  [16001/23750] (147.667s) val loss: 0.058985
Batch 19201/23750, loss: 0.000152  [19201/23750] (147.226s) val loss: 0.061806
Batch 22401/23750, loss: 0.033055  [22401/23750] (143.697s) val loss: 0.058325
Batch 23750/23750, loss: 0.008795  [23750/23750] (82.890s) val loss: 0.060630
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1106.023s total
-------------------------------

Epoch 5
-------------------------------
Batch 3201/23750, loss: 0.037914  [ 3201/23750] (104.913s) val loss: 0.057059
Batch 6401/23750, loss: 0.003094  [ 6401/23750] (145.523s) val loss: 0.060528
Batch 9601/23750, loss: 0.026878  [ 9601/23750] (143.393s) val loss: 0.058439
Batch 12801/23750, loss: 0.000718  [12801/23750] (143.967s) val loss: 0.053214
Batch 16001/23750, loss: 0.024635  [16001/23750] (143.928s) val loss: 0.054274
Batch 19201/23750, loss: 0.001272  [19201/23750] (143.761s) val loss: 0.068745
Batch 22401/23750, loss: 0.022910  [22401/23750] (143.596s) val loss: 0.054470
Batch 23750/23750, loss: 0.276018  [23750/23750] (83.152s) val loss: 0.053819
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1091.534s total
-------------------------------

Epoch 6
-------------------------------
Batch 3201/23750, loss: 0.001186  [ 3201/23750] (105.262s) val loss: 0.048868
Batch 6401/23750, loss: 0.005557  [ 6401/23750] (143.575s) val loss: 0.047496
Batch 9601/23750, loss: 0.000617  [ 9601/23750] (143.856s) val loss: 0.052884
Batch 12801/23750, loss: 0.028702  [12801/23750] (143.701s) val loss: 0.049370
Batch 16001/23750, loss: 0.000123  [16001/23750] (143.790s) val loss: 0.051705
Batch 19201/23750, loss: 0.000693  [19201/23750] (144.016s) val loss: 0.044103
Batch 22401/23750, loss: 0.002437  [22401/23750] (143.493s) val loss: 0.044498
Batch 23750/23750, loss: 0.003518  [23750/23750] (82.887s) val loss: 0.043567
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.038s total
-------------------------------

Epoch 7
-------------------------------
Batch 3201/23750, loss: 0.010988  [ 3201/23750] (105.142s) val loss: 0.041209
Batch 6401/23750, loss: 0.001306  [ 6401/23750] (143.970s) val loss: 0.041829
Batch 9601/23750, loss: 0.063554  [ 9601/23750] (143.909s) val loss: 0.041389
Batch 12801/23750, loss: 0.000425  [12801/23750] (143.516s) val loss: 0.039246
Batch 16001/23750, loss: 0.258818  [16001/23750] (143.770s) val loss: 0.038847
Batch 19201/23750, loss: 0.013257  [19201/23750] (143.850s) val loss: 0.038126
Batch 22401/23750, loss: 0.107221  [22401/23750] (143.703s) val loss: 0.037564
Batch 23750/23750, loss: 0.005154  [23750/23750] (83.279s) val loss: 0.049913
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.288s total
-------------------------------

Epoch 8
-------------------------------
Batch 3201/23750, loss: 0.012470  [ 3201/23750] (105.021s) val loss: 0.036758
Batch 6401/23750, loss: 0.005135  [ 6401/23750] (143.758s) val loss: 0.044326
Batch 9601/23750, loss: 0.018256  [ 9601/23750] (144.142s) val loss: 0.038874
Batch 12801/23750, loss: 0.158374  [12801/23750] (143.634s) val loss: 0.035508
Batch 16001/23750, loss: 0.001712  [16001/23750] (143.492s) val loss: 0.036309
Batch 19201/23750, loss: 0.001621  [19201/23750] (143.820s) val loss: 0.034712
Batch 22401/23750, loss: 0.000033  [22401/23750] (143.858s) val loss: 0.038903
Batch 23750/23750, loss: 0.004700  [23750/23750] (83.078s) val loss: 0.035433
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.160s total
-------------------------------

Epoch 9
-------------------------------
Batch 3201/23750, loss: 0.004284  [ 3201/23750] (105.062s) val loss: 0.032500
Batch 6401/23750, loss: 0.133152  [ 6401/23750] (144.123s) val loss: 0.033922
Batch 9601/23750, loss: 0.000385  [ 9601/23750] (143.928s) val loss: 0.031429
Batch 12801/23750, loss: 0.001806  [12801/23750] (144.214s) val loss: 0.032943
Batch 16001/23750, loss: 0.009408  [16001/23750] (143.724s) val loss: 0.031645
Batch 19201/23750, loss: 0.005037  [19201/23750] (144.085s) val loss: 0.032901
Batch 22401/23750, loss: 0.008767  [22401/23750] (146.065s) val loss: 0.031427
Batch 23750/23750, loss: 0.000563  [23750/23750] (84.866s) val loss: 0.029467
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1095.495s total
-------------------------------

Epoch 10
-------------------------------
Batch 3201/23750, loss: 0.013608  [ 3201/23750] (105.130s) val loss: 0.033837
Batch 6401/23750, loss: 0.010129  [ 6401/23750] (147.382s) val loss: 0.032146
Batch 9601/23750, loss: 0.006761  [ 9601/23750] (146.653s) val loss: 0.028871
Batch 12801/23750, loss: 0.230553  [12801/23750] (147.020s) val loss: 0.033554
Batch 16001/23750, loss: 0.007265  [16001/23750] (145.689s) val loss: 0.028606
Batch 19201/23750, loss: 0.001003  [19201/23750] (144.663s) val loss: 0.029370
Batch 22401/23750, loss: 0.000527  [22401/23750] (146.158s) val loss: 0.028848
Batch 23750/23750, loss: 0.013679  [23750/23750] (84.286s) val loss: 0.031570
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1106.248s total
-------------------------------

Epoch 11
-------------------------------
Batch 3201/23750, loss: 0.213489  [ 3201/23750] (107.549s) val loss: 0.028197
Batch 6401/23750, loss: 0.002293  [ 6401/23750] (143.915s) val loss: 0.029747
Batch 9601/23750, loss: 0.000030  [ 9601/23750] (143.614s) val loss: 0.026007
Batch 12801/23750, loss: 0.053395  [12801/23750] (143.949s) val loss: 0.029233
Batch 16001/23750, loss: 0.002795  [16001/23750] (143.978s) val loss: 0.030324
Batch 19201/23750, loss: 0.000162  [19201/23750] (144.244s) val loss: 0.028092
Batch 22401/23750, loss: 0.078798  [22401/23750] (143.776s) val loss: 0.025493
Batch 23750/23750, loss: 0.062534  [23750/23750] (82.911s) val loss: 0.026737
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1093.070s total
-------------------------------

Epoch 12
-------------------------------
Batch 3201/23750, loss: 0.006260  [ 3201/23750] (104.990s) val loss: 0.025763
Batch 6401/23750, loss: 0.035816  [ 6401/23750] (143.906s) val loss: 0.024957
Batch 9601/23750, loss: 0.025073  [ 9601/23750] (143.927s) val loss: 0.028103
Batch 12801/23750, loss: 0.000006  [12801/23750] (144.102s) val loss: 0.024608
Batch 16001/23750, loss: 0.005709  [16001/23750] (143.776s) val loss: 0.026020
Batch 19201/23750, loss: 0.000354  [19201/23750] (143.860s) val loss: 0.027342
Batch 22401/23750, loss: 0.001485  [22401/23750] (143.935s) val loss: 0.024674
Batch 23750/23750, loss: 0.057004  [23750/23750] (83.180s) val loss: 0.025370
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.622s total
-------------------------------

Epoch 13
-------------------------------
Batch 3201/23750, loss: 0.127368  [ 3201/23750] (105.219s) val loss: 0.026404
Batch 6401/23750, loss: 0.000088  [ 6401/23750] (143.560s) val loss: 0.024744
Batch 9601/23750, loss: 0.015185  [ 9601/23750] (143.660s) val loss: 0.025099
Batch 12801/23750, loss: 0.100388  [12801/23750] (144.093s) val loss: 0.024568
Batch 16001/23750, loss: 0.001566  [16001/23750] (143.791s) val loss: 0.030064
Batch 19201/23750, loss: 0.000744  [19201/23750] (143.740s) val loss: 0.027389
Batch 22401/23750, loss: 0.076023  [22401/23750] (143.930s) val loss: 0.024735
Batch 23750/23750, loss: 0.003865  [23750/23750] (83.214s) val loss: 0.025953
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.200s total
-------------------------------

Epoch 14
-------------------------------
Batch 3201/23750, loss: 0.000001  [ 3201/23750] (105.025s) val loss: 0.024873
Batch 6401/23750, loss: 0.148571  [ 6401/23750] (143.726s) val loss: 0.025261
Batch 9601/23750, loss: 0.040081  [ 9601/23750] (143.887s) val loss: 0.035776
Batch 12801/23750, loss: 0.000219  [12801/23750] (143.870s) val loss: 0.022989
Batch 16001/23750, loss: 0.005455  [16001/23750] (143.922s) val loss: 0.030970
Batch 19201/23750, loss: 0.002533  [19201/23750] (143.930s) val loss: 0.024065
Batch 22401/23750, loss: 0.001062  [22401/23750] (146.925s) val loss: 0.023465
Batch 23750/23750, loss: 0.007101  [23750/23750] (84.382s) val loss: 0.022284
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1095.246s total
-------------------------------

Epoch 15
-------------------------------
Batch 3201/23750, loss: 0.000142  [ 3201/23750] (108.655s) val loss: 0.021313
Batch 6401/23750, loss: 0.016104  [ 6401/23750] (147.787s) val loss: 0.026954
Batch 9601/23750, loss: 0.000789  [ 9601/23750] (148.977s) val loss: 0.019689
Batch 12801/23750, loss: 0.001140  [12801/23750] (147.899s) val loss: 0.020657
Batch 16001/23750, loss: 0.004155  [16001/23750] (146.989s) val loss: 0.021327
Batch 19201/23750, loss: 0.039728  [19201/23750] (147.521s) val loss: 0.020312
Batch 22401/23750, loss: 0.000178  [22401/23750] (147.336s) val loss: 0.018963
Batch 23750/23750, loss: 0.009077  [23750/23750] (83.876s) val loss: 0.021776
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1118.397s total
-------------------------------

Epoch 16
-------------------------------
Batch 3201/23750, loss: 0.006471  [ 3201/23750] (108.197s) val loss: 0.020451
Batch 6401/23750, loss: 0.012374  [ 6401/23750] (147.965s) val loss: 0.019670
Batch 9601/23750, loss: 0.002554  [ 9601/23750] (147.173s) val loss: 0.019205
Batch 12801/23750, loss: 0.133004  [12801/23750] (147.640s) val loss: 0.019861
Batch 16001/23750, loss: 0.425146  [16001/23750] (147.539s) val loss: 0.020520
Batch 19201/23750, loss: 0.197814  [19201/23750] (146.791s) val loss: 0.017366
Batch 22401/23750, loss: 0.000128  [22401/23750] (147.738s) val loss: 0.022211
Batch 23750/23750, loss: 0.056704  [23750/23750] (84.663s) val loss: 0.019103
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1117.229s total
-------------------------------

Epoch 17
-------------------------------
Batch 3201/23750, loss: 0.030917  [ 3201/23750] (108.827s) val loss: 0.018575
Batch 6401/23750, loss: 0.002099  [ 6401/23750] (147.225s) val loss: 0.020090
Batch 9601/23750, loss: 0.102272  [ 9601/23750] (147.356s) val loss: 0.016282
Batch 12801/23750, loss: 0.025256  [12801/23750] (147.694s) val loss: 0.018518
Batch 16001/23750, loss: 0.000035  [16001/23750] (152.848s) val loss: 0.017141
Batch 19201/23750, loss: 0.154368  [19201/23750] (147.142s) val loss: 0.017642
Batch 22401/23750, loss: 0.000000  [22401/23750] (147.931s) val loss: 0.019245
Batch 23750/23750, loss: 0.000505  [23750/23750] (84.809s) val loss: 0.021665
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1123.041s total
-------------------------------

Epoch 18
-------------------------------
Batch 3201/23750, loss: 0.000004  [ 3201/23750] (108.691s) val loss: 0.019071
Batch 6401/23750, loss: 0.001118  [ 6401/23750] (147.694s) val loss: 0.021444
Batch 9601/23750, loss: 0.010633  [ 9601/23750] (147.389s) val loss: 0.021696
Batch 12801/23750, loss: 0.000538  [12801/23750] (147.110s) val loss: 0.015772
Batch 16001/23750, loss: 0.003425  [16001/23750] (147.074s) val loss: 0.016382
Batch 19201/23750, loss: 0.000814  [19201/23750] (147.712s) val loss: 0.022620
Batch 22401/23750, loss: 0.001282  [22401/23750] (148.106s) val loss: 0.016503
Batch 23750/23750, loss: 0.000595  [23750/23750] (84.434s) val loss: 0.018138
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1117.320s total
-------------------------------

Epoch 19
-------------------------------
Batch 3201/23750, loss: 0.000180  [ 3201/23750] (108.939s) val loss: 0.015092
Batch 6401/23750, loss: 0.055951  [ 6401/23750] (147.475s) val loss: 0.015762
Batch 9601/23750, loss: 0.001104  [ 9601/23750] (147.371s) val loss: 0.016327
Batch 12801/23750, loss: 0.022583  [12801/23750] (147.361s) val loss: 0.016386
Batch 16001/23750, loss: 0.000757  [16001/23750] (147.761s) val loss: 0.016885
Batch 19201/23750, loss: 0.000029  [19201/23750] (147.916s) val loss: 0.016074
Batch 22401/23750, loss: 0.001405  [22401/23750] (148.150s) val loss: 0.022491
Batch 23750/23750, loss: 0.000652  [23750/23750] (84.508s) val loss: 0.023006
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1118.598s total
-------------------------------

Epoch 20
-------------------------------
Batch 3201/23750, loss: 0.005690  [ 3201/23750] (105.301s) val loss: 0.018111
Batch 6401/23750, loss: 0.000023  [ 6401/23750] (144.195s) val loss: 0.018208
Batch 9601/23750, loss: 0.197916  [ 9601/23750] (144.017s) val loss: 0.015708
Batch 12801/23750, loss: 0.001405  [12801/23750] (143.746s) val loss: 0.015944
Batch 16001/23750, loss: 0.000002  [16001/23750] (147.048s) val loss: 0.014744
Batch 19201/23750, loss: 0.074780  [19201/23750] (147.232s) val loss: 0.016391
Batch 22401/23750, loss: 0.004571  [22401/23750] (147.202s) val loss: 0.018724
Batch 23750/23750, loss: 0.000388  [23750/23750] (83.006s) val loss: 0.020622
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1100.667s total
-------------------------------

Epoch 21
-------------------------------
Batch 3201/23750, loss: 0.005356  [ 3201/23750] (105.533s) val loss: 0.020442
Batch 6401/23750, loss: 0.000023  [ 6401/23750] (143.810s) val loss: 0.014078
Batch 9601/23750, loss: 0.000775  [ 9601/23750] (144.029s) val loss: 0.021520
Batch 12801/23750, loss: 0.002157  [12801/23750] (145.356s) val loss: 0.015835
Batch 16001/23750, loss: 0.012264  [16001/23750] (147.456s) val loss: 0.016497
Batch 19201/23750, loss: 0.000231  [19201/23750] (143.748s) val loss: 0.017481
Batch 22401/23750, loss: 0.007422  [22401/23750] (145.041s) val loss: 0.018115
Batch 23750/23750, loss: 0.000377  [23750/23750] (82.856s) val loss: 0.015640
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1096.541s total
-------------------------------

Epoch 22
-------------------------------
Batch 3201/23750, loss: 0.000113  [ 3201/23750] (108.192s) val loss: 0.019562
Batch 6401/23750, loss: 0.002451  [ 6401/23750] (145.364s) val loss: 0.014745
Batch 9601/23750, loss: 0.093692  [ 9601/23750] (145.436s) val loss: 0.016920
Batch 12801/23750, loss: 0.001169  [12801/23750] (146.172s) val loss: 0.014825
Batch 16001/23750, loss: 0.000000  [16001/23750] (146.762s) val loss: 0.015477
Batch 19201/23750, loss: 0.000133  [19201/23750] (147.111s) val loss: 0.013049
Batch 22401/23750, loss: 0.018031  [22401/23750] (146.635s) val loss: 0.014609
Batch 23750/23750, loss: 0.000272  [23750/23750] (84.570s) val loss: 0.015763
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1109.287s total
-------------------------------

Epoch 23
-------------------------------
Batch 3201/23750, loss: 0.031589  [ 3201/23750] (105.082s) val loss: 0.015213
Batch 6401/23750, loss: 0.000108  [ 6401/23750] (144.032s) val loss: 0.015322
Batch 9601/23750, loss: 0.000000  [ 9601/23750] (143.877s) val loss: 0.016696
Batch 12801/23750, loss: 0.000368  [12801/23750] (143.289s) val loss: 0.013762
Batch 16001/23750, loss: 0.000029  [16001/23750] (143.790s) val loss: 0.015127
Batch 19201/23750, loss: 0.000917  [19201/23750] (143.484s) val loss: 0.015188
Batch 22401/23750, loss: 0.000212  [22401/23750] (144.829s) val loss: 0.013222
Batch 23750/23750, loss: 0.008647  [23750/23750] (84.067s) val loss: 0.018803
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1091.636s total
-------------------------------

Epoch 24
-------------------------------
Batch 3201/23750, loss: 0.000108  [ 3201/23750] (105.295s) val loss: 0.015698
Batch 6401/23750, loss: 0.000068  [ 6401/23750] (144.289s) val loss: 0.020018
Batch 9601/23750, loss: 0.045107  [ 9601/23750] (144.039s) val loss: 0.017856
Batch 12801/23750, loss: 0.000118  [12801/23750] (143.616s) val loss: 0.019000
Batch 16001/23750, loss: 0.001094  [16001/23750] (143.782s) val loss: 0.018797
Batch 19201/23750, loss: 0.158707  [19201/23750] (143.900s) val loss: 0.011939
Batch 22401/23750, loss: 0.000924  [22401/23750] (143.804s) val loss: 0.017499
Batch 23750/23750, loss: 0.085810  [23750/23750] (82.815s) val loss: 0.017164
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.531s total
-------------------------------

Epoch 25
-------------------------------
Batch 3201/23750, loss: 0.000134  [ 3201/23750] (104.979s) val loss: 0.017272
Batch 6401/23750, loss: 0.000495  [ 6401/23750] (143.663s) val loss: 0.012756
Batch 9601/23750, loss: 0.142565  [ 9601/23750] (147.209s) val loss: 0.013277
Batch 12801/23750, loss: 0.000576  [12801/23750] (146.676s) val loss: 0.014791
Batch 16001/23750, loss: 0.000000  [16001/23750] (147.945s) val loss: 0.016484
Batch 19201/23750, loss: 0.023939  [19201/23750] (147.167s) val loss: 0.015666
Batch 22401/23750, loss: 0.001042  [22401/23750] (145.330s) val loss: 0.015183
Batch 23750/23750, loss: 0.000018  [23750/23750] (82.964s) val loss: 0.012458
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1104.699s total
-------------------------------

Epoch 26
-------------------------------
Batch 3201/23750, loss: 0.000592  [ 3201/23750] (107.875s) val loss: 0.023967
Batch 6401/23750, loss: 0.021788  [ 6401/23750] (147.726s) val loss: 0.015584
Batch 9601/23750, loss: 0.000059  [ 9601/23750] (147.092s) val loss: 0.014044
Batch 12801/23750, loss: 0.001364  [12801/23750] (147.485s) val loss: 0.016256
Batch 16001/23750, loss: 0.000083  [16001/23750] (147.074s) val loss: 0.012645
Batch 19201/23750, loss: 0.000001  [19201/23750] (147.640s) val loss: 0.011627
Batch 22401/23750, loss: 0.024665  [22401/23750] (148.185s) val loss: 0.012390
Batch 23750/23750, loss: 0.007504  [23750/23750] (84.420s) val loss: 0.011827
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1116.761s total
-------------------------------

Epoch 27
-------------------------------
Batch 3201/23750, loss: 0.000774  [ 3201/23750] (105.232s) val loss: 0.015073
Batch 6401/23750, loss: 0.000170  [ 6401/23750] (143.985s) val loss: 0.017547
Batch 9601/23750, loss: 0.007841  [ 9601/23750] (143.783s) val loss: 0.013549
Batch 12801/23750, loss: 0.005989  [12801/23750] (143.968s) val loss: 0.015938
Batch 16001/23750, loss: 0.000121  [16001/23750] (145.129s) val loss: 0.013697
Batch 19201/23750, loss: 0.032620  [19201/23750] (147.404s) val loss: 0.012607
Batch 22401/23750, loss: 0.005980  [22401/23750] (147.110s) val loss: 0.014289
Batch 23750/23750, loss: 0.000184  [23750/23750] (84.725s) val loss: 0.011317
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1100.597s total
-------------------------------

Epoch 28
-------------------------------
Batch 3201/23750, loss: 0.000160  [ 3201/23750] (107.231s) val loss: 0.013629
Batch 6401/23750, loss: 0.000251  [ 6401/23750] (145.329s) val loss: 0.012583
Batch 9601/23750, loss: 0.000372  [ 9601/23750] (146.737s) val loss: 0.016016
Batch 12801/23750, loss: 0.031081  [12801/23750] (147.300s) val loss: 0.012664
Batch 16001/23750, loss: 0.000403  [16001/23750] (146.564s) val loss: 0.013552
Batch 19201/23750, loss: 0.000003  [19201/23750] (144.261s) val loss: 0.013463
Batch 22401/23750, loss: 0.001816  [22401/23750] (146.270s) val loss: 0.014200
Batch 23750/23750, loss: 0.001736  [23750/23750] (84.576s) val loss: 0.012503
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1107.332s total
-------------------------------

Epoch 29
-------------------------------
Batch 3201/23750, loss: 0.015440  [ 3201/23750] (107.930s) val loss: 0.012285
Batch 6401/23750, loss: 0.000995  [ 6401/23750] (146.118s) val loss: 0.015150
Batch 9601/23750, loss: 0.012265  [ 9601/23750] (145.078s) val loss: 0.012162
Batch 12801/23750, loss: 0.000084  [12801/23750] (145.736s) val loss: 0.014026
Batch 16001/23750, loss: 0.000679  [16001/23750] (146.816s) val loss: 0.012383
Batch 19201/23750, loss: 0.015267  [19201/23750] (145.825s) val loss: 0.011652
Batch 22401/23750, loss: 0.026659  [22401/23750] (147.336s) val loss: 0.013950
Batch 23750/23750, loss: 0.001539  [23750/23750] (84.518s) val loss: 0.013021
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1108.713s total
-------------------------------

Epoch 30
-------------------------------
Batch 3201/23750, loss: 0.000951  [ 3201/23750] (105.086s) val loss: 0.019319
Batch 6401/23750, loss: 0.001593  [ 6401/23750] (143.736s) val loss: 0.011915
Batch 9601/23750, loss: 0.001742  [ 9601/23750] (144.067s) val loss: 0.014311
Batch 12801/23750, loss: 0.000005  [12801/23750] (144.294s) val loss: 0.012796
Batch 16001/23750, loss: 0.006528  [16001/23750] (143.744s) val loss: 0.011935
Batch 19201/23750, loss: 0.000643  [19201/23750] (144.040s) val loss: 0.015985
Batch 22401/23750, loss: 0.008928  [22401/23750] (145.809s) val loss: 0.012944
Batch 23750/23750, loss: 0.001659  [23750/23750] (84.122s) val loss: 0.014639
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1094.034s total
-------------------------------

Epoch 31
-------------------------------
Batch 3201/23750, loss: 0.029641  [ 3201/23750] (106.199s) val loss: 0.012903
Batch 6401/23750, loss: 0.000117  [ 6401/23750] (143.415s) val loss: 0.012572
Batch 9601/23750, loss: 0.000002  [ 9601/23750] (143.871s) val loss: 0.014413
Batch 12801/23750, loss: 0.000164  [12801/23750] (145.830s) val loss: 0.012217
Batch 16001/23750, loss: 0.000045  [16001/23750] (147.699s) val loss: 0.009997
Batch 19201/23750, loss: 0.043192  [19201/23750] (147.787s) val loss: 0.014680
Batch 22401/23750, loss: 0.000661  [22401/23750] (147.279s) val loss: 0.011314
Batch 23750/23750, loss: 0.000605  [23750/23750] (84.793s) val loss: 0.012281
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1105.958s total
-------------------------------

Epoch 32
-------------------------------
Batch 3201/23750, loss: 0.000945  [ 3201/23750] (105.212s) val loss: 0.012647
Batch 6401/23750, loss: 0.000058  [ 6401/23750] (147.045s) val loss: 0.011522
Batch 9601/23750, loss: 0.036457  [ 9601/23750] (147.080s) val loss: 0.014128
Batch 12801/23750, loss: 0.000387  [12801/23750] (143.444s) val loss: 0.012881
Batch 16001/23750, loss: 0.000045  [16001/23750] (143.661s) val loss: 0.011048
Batch 19201/23750, loss: 0.000136  [19201/23750] (143.817s) val loss: 0.013434
Batch 22401/23750, loss: 0.001610  [22401/23750] (143.468s) val loss: 0.014165
Batch 23750/23750, loss: 0.083922  [23750/23750] (82.753s) val loss: 0.013476
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1095.241s total
-------------------------------

Epoch 33
-------------------------------
Batch 3201/23750, loss: 0.000978  [ 3201/23750] (107.556s) val loss: 0.012446
Batch 6401/23750, loss: 0.002702  [ 6401/23750] (146.556s) val loss: 0.020943
Batch 9601/23750, loss: 0.006061  [ 9601/23750] (146.721s) val loss: 0.011414
Batch 12801/23750, loss: 0.000147  [12801/23750] (145.978s) val loss: 0.013502
Batch 16001/23750, loss: 0.002635  [16001/23750] (145.547s) val loss: 0.012508
Batch 19201/23750, loss: 0.000451  [19201/23750] (145.263s) val loss: 0.012027
Batch 22401/23750, loss: 0.000164  [22401/23750] (143.071s) val loss: 0.011559
Batch 23750/23750, loss: 0.001372  [23750/23750] (83.184s) val loss: 0.011994
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1102.627s total
-------------------------------

Epoch 34
-------------------------------
Batch 3201/23750, loss: 0.000260  [ 3201/23750] (105.315s) val loss: 0.011668
Batch 6401/23750, loss: 0.005143  [ 6401/23750] (143.934s) val loss: 0.012947
Batch 9601/23750, loss: 0.000003  [ 9601/23750] (143.893s) val loss: 0.014221
Batch 12801/23750, loss: 0.000142  [12801/23750] (143.607s) val loss: 0.011825
Batch 16001/23750, loss: 0.248912  [16001/23750] (143.926s) val loss: 0.011363
Batch 19201/23750, loss: 0.298972  [19201/23750] (143.746s) val loss: 0.012021
Batch 22401/23750, loss: 0.020593  [22401/23750] (144.041s) val loss: 0.010973
Batch 23750/23750, loss: 0.004723  [23750/23750] (82.869s) val loss: 0.011122
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.028s total
-------------------------------

Epoch 35
-------------------------------
Batch 3201/23750, loss: 0.000035  [ 3201/23750] (104.949s) val loss: 0.014481
Batch 6401/23750, loss: 0.000008  [ 6401/23750] (144.169s) val loss: 0.012661
Batch 9601/23750, loss: 0.001407  [ 9601/23750] (144.042s) val loss: 0.011042
Batch 12801/23750, loss: 0.000806  [12801/23750] (143.830s) val loss: 0.017115
Batch 16001/23750, loss: 0.000031  [16001/23750] (144.014s) val loss: 0.011181
Batch 19201/23750, loss: 0.000001  [19201/23750] (143.936s) val loss: 0.016839
Batch 22401/23750, loss: 0.000391  [22401/23750] (143.743s) val loss: 0.015901
Batch 23750/23750, loss: 0.000031  [23750/23750] (82.792s) val loss: 0.012352
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.223s total
-------------------------------

Epoch 36
-------------------------------
Batch 3201/23750, loss: 0.002711  [ 3201/23750] (104.995s) val loss: 0.010378
Batch 6401/23750, loss: 0.001322  [ 6401/23750] (143.468s) val loss: 0.012522
Batch 9601/23750, loss: 0.037323  [ 9601/23750] (143.814s) val loss: 0.012885
Batch 12801/23750, loss: 0.044882  [12801/23750] (144.001s) val loss: 0.013636
Batch 16001/23750, loss: 0.000430  [16001/23750] (143.761s) val loss: 0.013124
Batch 19201/23750, loss: 0.000103  [19201/23750] (143.778s) val loss: 0.014734
Batch 22401/23750, loss: 0.000240  [22401/23750] (143.507s) val loss: 0.010920
Batch 23750/23750, loss: 0.000003  [23750/23750] (82.848s) val loss: 0.012420
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1088.917s total
-------------------------------

Epoch 37
-------------------------------
Batch 3201/23750, loss: 0.028526  [ 3201/23750] (105.125s) val loss: 0.009742
Batch 6401/23750, loss: 0.000004  [ 6401/23750] (143.544s) val loss: 0.015508
Batch 9601/23750, loss: 0.000436  [ 9601/23750] (143.791s) val loss: 0.011481
Batch 12801/23750, loss: 0.000008  [12801/23750] (143.512s) val loss: 0.011525
Batch 16001/23750, loss: 0.000164  [16001/23750] (143.502s) val loss: 0.014485
Batch 19201/23750, loss: 0.002083  [19201/23750] (143.839s) val loss: 0.010128
Batch 22401/23750, loss: 0.000218  [22401/23750] (143.700s) val loss: 0.011786
Batch 23750/23750, loss: 0.054831  [23750/23750] (82.984s) val loss: 0.010344
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1088.924s total
-------------------------------

Epoch 38
-------------------------------
Batch 3201/23750, loss: 0.000070  [ 3201/23750] (105.146s) val loss: 0.012476
Batch 6401/23750, loss: 0.064701  [ 6401/23750] (144.107s) val loss: 0.011015
Batch 9601/23750, loss: 0.000000  [ 9601/23750] (144.147s) val loss: 0.010280
Batch 12801/23750, loss: 0.003915  [12801/23750] (143.702s) val loss: 0.012208
Batch 16001/23750, loss: 0.001228  [16001/23750] (143.890s) val loss: 0.009951
Batch 19201/23750, loss: 0.000745  [19201/23750] (145.080s) val loss: 0.013116
Batch 22401/23750, loss: 0.000787  [22401/23750] (145.699s) val loss: 0.011985
Batch 23750/23750, loss: 0.001385  [23750/23750] (83.959s) val loss: 0.012902
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1094.759s total
-------------------------------

Epoch 39
-------------------------------
Batch 3201/23750, loss: 0.001071  [ 3201/23750] (104.859s) val loss: 0.014692
Batch 6401/23750, loss: 0.000002  [ 6401/23750] (143.560s) val loss: 0.013499
Batch 9601/23750, loss: 0.000510  [ 9601/23750] (143.455s) val loss: 0.012168
Batch 12801/23750, loss: 0.000192  [12801/23750] (143.894s) val loss: 0.011907
Batch 16001/23750, loss: 0.024043  [16001/23750] (146.157s) val loss: 0.011205
Batch 19201/23750, loss: 0.000256  [19201/23750] (146.835s) val loss: 0.009702
Batch 22401/23750, loss: 0.000032  [22401/23750] (144.953s) val loss: 0.013545
Batch 23750/23750, loss: 0.000024  [23750/23750] (83.272s) val loss: 0.013802
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1095.983s total
-------------------------------

Epoch 40
-------------------------------
Batch 3201/23750, loss: 0.000100  [ 3201/23750] (104.776s) val loss: 0.013676
Batch 6401/23750, loss: 0.203018  [ 6401/23750] (143.359s) val loss: 0.010626
Batch 9601/23750, loss: 0.000206  [ 9601/23750] (143.540s) val loss: 0.009663
Batch 12801/23750, loss: 0.000195  [12801/23750] (143.883s) val loss: 0.011185
Batch 16001/23750, loss: 0.011513  [16001/23750] (144.126s) val loss: 0.012460
Batch 19201/23750, loss: 0.000251  [19201/23750] (143.982s) val loss: 0.019702
Batch 22401/23750, loss: 0.000372  [22401/23750] (143.587s) val loss: 0.010031
Batch 23750/23750, loss: 0.011985  [23750/23750] (83.274s) val loss: 0.010322
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.341s total
-------------------------------

Epoch 41
-------------------------------
Batch 3201/23750, loss: 0.044324  [ 3201/23750] (105.535s) val loss: 0.012132
Batch 6401/23750, loss: 0.006217  [ 6401/23750] (143.659s) val loss: 0.011395
Batch 9601/23750, loss: 0.000021  [ 9601/23750] (143.514s) val loss: 0.010612
Batch 12801/23750, loss: 0.126796  [12801/23750] (143.898s) val loss: 0.010333
Batch 16001/23750, loss: 0.000851  [16001/23750] (143.949s) val loss: 0.010309
Batch 19201/23750, loss: 0.002433  [19201/23750] (143.523s) val loss: 0.010944
Batch 22401/23750, loss: 0.034517  [22401/23750] (143.702s) val loss: 0.011185
Batch 23750/23750, loss: 0.002616  [23750/23750] (83.211s) val loss: 0.010057
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.945s total
-------------------------------

Epoch 42
-------------------------------
Batch 3201/23750, loss: 0.000151  [ 3201/23750] (105.285s) val loss: 0.011056
Batch 6401/23750, loss: 0.001705  [ 6401/23750] (143.534s) val loss: 0.013230
Batch 9601/23750, loss: 0.000440  [ 9601/23750] (143.549s) val loss: 0.011309
Batch 12801/23750, loss: 0.000290  [12801/23750] (144.108s) val loss: 0.011108
Batch 16001/23750, loss: 0.022242  [16001/23750] (143.589s) val loss: 0.013377
Batch 19201/23750, loss: 0.025254  [19201/23750] (143.730s) val loss: 0.010676
Batch 22401/23750, loss: 0.000109  [22401/23750] (143.798s) val loss: 0.011034
Batch 23750/23750, loss: 0.000000  [23750/23750] (83.032s) val loss: 0.010534
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.481s total
-------------------------------

Epoch 43
-------------------------------
Batch 3201/23750, loss: 0.003386  [ 3201/23750] (105.034s) val loss: 0.011629
Batch 6401/23750, loss: 0.000578  [ 6401/23750] (143.647s) val loss: 0.010644
Batch 9601/23750, loss: 0.071552  [ 9601/23750] (143.499s) val loss: 0.014439
Batch 12801/23750, loss: 0.000140  [12801/23750] (143.341s) val loss: 0.011991
Batch 16001/23750, loss: 0.041950  [16001/23750] (143.754s) val loss: 0.010767
Batch 19201/23750, loss: 0.000559  [19201/23750] (143.636s) val loss: 0.011564
Batch 22401/23750, loss: 0.000712  [22401/23750] (143.951s) val loss: 0.010623
Batch 23750/23750, loss: 0.000064  [23750/23750] (82.901s) val loss: 0.013066
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1088.748s total
-------------------------------

Epoch 44
-------------------------------
Batch 3201/23750, loss: 0.000054  [ 3201/23750] (105.532s) val loss: 0.010009
Batch 6401/23750, loss: 0.000168  [ 6401/23750] (143.278s) val loss: 0.014124
Batch 9601/23750, loss: 0.000511  [ 9601/23750] (143.416s) val loss: 0.012964
Batch 12801/23750, loss: 0.002806  [12801/23750] (143.784s) val loss: 0.010305
Batch 16001/23750, loss: 0.000352  [16001/23750] (143.701s) val loss: 0.011883
Batch 19201/23750, loss: 0.000265  [19201/23750] (143.563s) val loss: 0.011533
Batch 22401/23750, loss: 0.000710  [22401/23750] (143.785s) val loss: 0.012928
Batch 23750/23750, loss: 0.000002  [23750/23750] (82.926s) val loss: 0.010375
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1088.873s total
-------------------------------

Epoch 45
-------------------------------
Batch 3201/23750, loss: 0.000474  [ 3201/23750] (105.188s) val loss: 0.015734
Batch 6401/23750, loss: 0.000183  [ 6401/23750] (143.783s) val loss: 0.011113
Batch 9601/23750, loss: 0.000174  [ 9601/23750] (143.712s) val loss: 0.010462
Batch 12801/23750, loss: 0.002493  [12801/23750] (143.705s) val loss: 0.012382
Batch 16001/23750, loss: 0.000101  [16001/23750] (143.951s) val loss: 0.010001
Batch 19201/23750, loss: 0.000004  [19201/23750] (143.463s) val loss: 0.011070
Batch 22401/23750, loss: 0.007663  [22401/23750] (143.886s) val loss: 0.010830
Batch 23750/23750, loss: 0.000264  [23750/23750] (83.476s) val loss: 0.010485
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.302s total
-------------------------------

Epoch 46
-------------------------------
Batch 3201/23750, loss: 0.000094  [ 3201/23750] (106.220s) val loss: 0.009354
Batch 6401/23750, loss: 0.000128  [ 6401/23750] (145.136s) val loss: 0.010752
Batch 9601/23750, loss: 0.021987  [ 9601/23750] (145.542s) val loss: 0.012885
Batch 12801/23750, loss: 0.000021  [12801/23750] (145.215s) val loss: 0.012740
Batch 16001/23750, loss: 0.000059  [16001/23750] (145.366s) val loss: 0.012048
Batch 19201/23750, loss: 0.000115  [19201/23750] (145.470s) val loss: 0.010661
Batch 22401/23750, loss: 0.000195  [22401/23750] (145.354s) val loss: 0.009772
Batch 23750/23750, loss: 0.000031  [23750/23750] (83.724s) val loss: 0.009976
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1101.203s total
-------------------------------

Epoch 47
-------------------------------
Batch 3201/23750, loss: 0.003629  [ 3201/23750] (106.158s) val loss: 0.009917
Batch 6401/23750, loss: 0.006558  [ 6401/23750] (145.227s) val loss: 0.009750
Batch 9601/23750, loss: 0.000289  [ 9601/23750] (145.524s) val loss: 0.010900
Batch 12801/23750, loss: 0.004022  [12801/23750] (145.717s) val loss: 0.009799
Batch 16001/23750, loss: 0.000059  [16001/23750] (145.274s) val loss: 0.012820
Batch 19201/23750, loss: 0.005199  [19201/23750] (146.360s) val loss: 0.010954
Batch 22401/23750, loss: 0.000014  [22401/23750] (146.945s) val loss: 0.010236
Batch 23750/23750, loss: 0.000065  [23750/23750] (84.528s) val loss: 0.010857
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1104.865s total
-------------------------------

Epoch 48
-------------------------------
Batch 3201/23750, loss: 0.000001  [ 3201/23750] (106.594s) val loss: 0.011177
Batch 6401/23750, loss: 0.002852  [ 6401/23750] (146.974s) val loss: 0.009534
Batch 9601/23750, loss: 0.000083  [ 9601/23750] (146.503s) val loss: 0.011148
Batch 12801/23750, loss: 0.000244  [12801/23750] (144.184s) val loss: 0.011515
Batch 16001/23750, loss: 0.004361  [16001/23750] (145.646s) val loss: 0.009579
Batch 19201/23750, loss: 0.000162  [19201/23750] (145.277s) val loss: 0.009505
Batch 22401/23750, loss: 0.000851  [22401/23750] (145.525s) val loss: 0.013343
Batch 23750/23750, loss: 0.000149  [23750/23750] (83.859s) val loss: 0.011012
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1103.659s total
-------------------------------

Epoch 49
-------------------------------
Batch 3201/23750, loss: 0.000043  [ 3201/23750] (106.938s) val loss: 0.009556
Batch 6401/23750, loss: 0.010403  [ 6401/23750] (145.981s) val loss: 0.010329
Batch 9601/23750, loss: 0.000040  [ 9601/23750] (145.751s) val loss: 0.009208
Batch 12801/23750, loss: 0.000008  [12801/23750] (143.359s) val loss: 0.009474
Batch 16001/23750, loss: 0.011931  [16001/23750] (144.137s) val loss: 0.009440
Batch 19201/23750, loss: 0.000069  [19201/23750] (144.527s) val loss: 0.011766
Batch 22401/23750, loss: 0.007975  [22401/23750] (143.946s) val loss: 0.010038
Batch 23750/23750, loss: 0.000116  [23750/23750] (82.940s) val loss: 0.009555
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1096.549s total
-------------------------------

Epoch 50
-------------------------------
Batch 3201/23750, loss: 0.035379  [ 3201/23750] (105.432s) val loss: 0.011784
Batch 6401/23750, loss: 0.022634  [ 6401/23750] (150.932s) val loss: 0.009765
Batch 9601/23750, loss: 0.000000  [ 9601/23750] (147.590s) val loss: 0.009093
Batch 12801/23750, loss: 0.050084  [12801/23750] (145.577s) val loss: 0.009720
Batch 16001/23750, loss: 0.001137  [16001/23750] (143.567s) val loss: 0.009910
Batch 19201/23750, loss: 0.009246  [19201/23750] (143.846s) val loss: 0.009916
Batch 22401/23750, loss: 0.000100  [22401/23750] (143.958s) val loss: 0.009436
Batch 23750/23750, loss: 0.000083  [23750/23750] (82.965s) val loss: 0.010707
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1102.849s total
-------------------------------

Epoch 51
-------------------------------
Batch 3201/23750, loss: 0.015744  [ 3201/23750] (108.763s) val loss: 0.011664
Batch 6401/23750, loss: 0.000147  [ 6401/23750] (145.422s) val loss: 0.009512
Batch 9601/23750, loss: 0.072030  [ 9601/23750] (148.273s) val loss: 0.009752
Batch 12801/23750, loss: 0.201636  [12801/23750] (147.193s) val loss: 0.011251
Batch 16001/23750, loss: 0.000073  [16001/23750] (147.756s) val loss: 0.012832
Batch 19201/23750, loss: 0.000002  [19201/23750] (147.991s) val loss: 0.010280
Batch 22401/23750, loss: 0.000148  [22401/23750] (147.604s) val loss: 0.009606
Batch 23750/23750, loss: 0.000205  [23750/23750] (84.998s) val loss: 0.009622
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1117.072s total
-------------------------------

Epoch 52
-------------------------------
Batch 3201/23750, loss: 0.000175  [ 3201/23750] (105.774s) val loss: 0.008981
Batch 6401/23750, loss: 0.000077  [ 6401/23750] (148.116s) val loss: 0.010724
Batch 9601/23750, loss: 0.001151  [ 9601/23750] (147.482s) val loss: 0.010178
Batch 12801/23750, loss: 0.002964  [12801/23750] (147.486s) val loss: 0.009927
Batch 16001/23750, loss: 0.000869  [16001/23750] (148.511s) val loss: 0.009155
Batch 19201/23750, loss: 0.000302  [19201/23750] (147.891s) val loss: 0.009372
Batch 22401/23750, loss: 0.000253  [22401/23750] (147.856s) val loss: 0.009102
Batch 23750/23750, loss: 0.000002  [23750/23750] (85.038s) val loss: 0.009594
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1117.210s total
-------------------------------

Epoch 53
-------------------------------
Batch 3201/23750, loss: 0.000462  [ 3201/23750] (107.150s) val loss: 0.009734
Batch 6401/23750, loss: 0.003077  [ 6401/23750] (143.982s) val loss: 0.008856
Batch 9601/23750, loss: 0.000028  [ 9601/23750] (143.953s) val loss: 0.010446
Batch 12801/23750, loss: 0.001253  [12801/23750] (143.613s) val loss: 0.013635
Batch 16001/23750, loss: 0.005836  [16001/23750] (143.849s) val loss: 0.010435
Batch 19201/23750, loss: 0.023343  [19201/23750] (143.687s) val loss: 0.011334
Batch 22401/23750, loss: 0.000001  [22401/23750] (143.497s) val loss: 0.010345
Batch 23750/23750, loss: 0.001523  [23750/23750] (82.802s) val loss: 0.011769
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1091.235s total
-------------------------------

Epoch 54
-------------------------------
Batch 3201/23750, loss: 0.000012  [ 3201/23750] (105.507s) val loss: 0.009587
Batch 6401/23750, loss: 0.044352  [ 6401/23750] (143.622s) val loss: 0.009494
Batch 9601/23750, loss: 0.085508  [ 9601/23750] (143.659s) val loss: 0.012168
Batch 12801/23750, loss: 0.000306  [12801/23750] (145.854s) val loss: 0.009292
Batch 16001/23750, loss: 0.000000  [16001/23750] (147.594s) val loss: 0.009281
Batch 19201/23750, loss: 0.000077  [19201/23750] (147.666s) val loss: 0.009003
Batch 22401/23750, loss: 0.000113  [22401/23750] (143.941s) val loss: 0.011014
Batch 23750/23750, loss: 0.002600  [23750/23750] (82.908s) val loss: 0.010430
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1099.558s total
-------------------------------

Epoch 55
-------------------------------
Batch 3201/23750, loss: 0.000957  [ 3201/23750] (105.050s) val loss: 0.010164
Batch 6401/23750, loss: 0.000110  [ 6401/23750] (144.624s) val loss: 0.012387
Batch 9601/23750, loss: 0.000052  [ 9601/23750] (145.047s) val loss: 0.009341
Batch 12801/23750, loss: 0.000262  [12801/23750] (145.788s) val loss: 0.008548
Batch 16001/23750, loss: 0.000004  [16001/23750] (148.381s) val loss: 0.009597
Batch 19201/23750, loss: 0.037098  [19201/23750] (147.294s) val loss: 0.013582
Batch 22401/23750, loss: 0.013222  [22401/23750] (148.409s) val loss: 0.010966
Batch 23750/23750, loss: 0.000179  [23750/23750] (84.418s) val loss: 0.008409
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1108.075s total
-------------------------------

Epoch 56
-------------------------------
Batch 3201/23750, loss: 0.000000  [ 3201/23750] (105.432s) val loss: 0.008488
Batch 6401/23750, loss: 0.001415  [ 6401/23750] (143.812s) val loss: 0.010481
Batch 9601/23750, loss: 0.000000  [ 9601/23750] (143.906s) val loss: 0.011609
Batch 12801/23750, loss: 0.000232  [12801/23750] (143.843s) val loss: 0.009224
Batch 16001/23750, loss: 0.000046  [16001/23750] (145.785s) val loss: 0.009283
Batch 19201/23750, loss: 0.000179  [19201/23750] (143.491s) val loss: 0.009293
Batch 22401/23750, loss: 0.000011  [22401/23750] (143.805s) val loss: 0.010458
Batch 23750/23750, loss: 0.011518  [23750/23750] (83.125s) val loss: 0.009935
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1092.396s total
-------------------------------

Epoch 57
-------------------------------
Batch 3201/23750, loss: 0.000298  [ 3201/23750] (105.917s) val loss: 0.009680
Batch 6401/23750, loss: 0.000123  [ 6401/23750] (143.962s) val loss: 0.008576
Batch 9601/23750, loss: 0.035847  [ 9601/23750] (143.635s) val loss: 0.010572
Batch 12801/23750, loss: 0.035099  [12801/23750] (143.563s) val loss: 0.010790
Batch 16001/23750, loss: 0.000044  [16001/23750] (144.084s) val loss: 0.010294
Batch 19201/23750, loss: 0.000334  [19201/23750] (143.827s) val loss: 0.010829
Batch 22401/23750, loss: 0.052608  [22401/23750] (143.846s) val loss: 0.008355
Batch 23750/23750, loss: 0.000002  [23750/23750] (83.022s) val loss: 0.008889
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.789s total
-------------------------------

Epoch 58
-------------------------------
Batch 3201/23750, loss: 0.005887  [ 3201/23750] (105.424s) val loss: 0.009820
Batch 6401/23750, loss: 0.000096  [ 6401/23750] (143.587s) val loss: 0.008419
Batch 9601/23750, loss: 0.000003  [ 9601/23750] (143.978s) val loss: 0.008981
Batch 12801/23750, loss: 0.000340  [12801/23750] (143.438s) val loss: 0.009124
Batch 16001/23750, loss: 0.000622  [16001/23750] (143.920s) val loss: 0.009406
Batch 19201/23750, loss: 0.003210  [19201/23750] (143.846s) val loss: 0.010669
Batch 22401/23750, loss: 0.019218  [22401/23750] (143.640s) val loss: 0.009734
Batch 23750/23750, loss: 0.000456  [23750/23750] (83.043s) val loss: 0.010416
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.907s total
-------------------------------

Epoch 59
-------------------------------
Batch 3201/23750, loss: 0.002550  [ 3201/23750] (105.227s) val loss: 0.008567
Batch 6401/23750, loss: 0.000022  [ 6401/23750] (143.931s) val loss: 0.009970
Batch 9601/23750, loss: 0.004478  [ 9601/23750] (143.992s) val loss: 0.008764
Batch 12801/23750, loss: 0.005469  [12801/23750] (143.461s) val loss: 0.010560
Batch 16001/23750, loss: 0.010204  [16001/23750] (143.777s) val loss: 0.011034
Batch 19201/23750, loss: 0.000421  [19201/23750] (143.742s) val loss: 0.010963
Batch 22401/23750, loss: 0.000123  [22401/23750] (144.009s) val loss: 0.009355
Batch 23750/23750, loss: 0.000016  [23750/23750] (82.911s) val loss: 0.008843
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.838s total
-------------------------------

Epoch 60
-------------------------------
Batch 3201/23750, loss: 0.000002  [ 3201/23750] (105.036s) val loss: 0.010968
Batch 6401/23750, loss: 0.008659  [ 6401/23750] (143.591s) val loss: 0.009373
Batch 9601/23750, loss: 0.069997  [ 9601/23750] (143.907s) val loss: 0.010171
Batch 12801/23750, loss: 0.000002  [12801/23750] (143.772s) val loss: 0.009235
Batch 16001/23750, loss: 0.015494  [16001/23750] (143.393s) val loss: 0.009485
Batch 19201/23750, loss: 0.000000  [19201/23750] (143.762s) val loss: 0.010016
Batch 22401/23750, loss: 0.010876  [22401/23750] (143.933s) val loss: 0.008446
Batch 23750/23750, loss: 0.000254  [23750/23750] (82.999s) val loss: 0.009973
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.129s total
-------------------------------

Epoch 61
-------------------------------
Batch 3201/23750, loss: 0.000150  [ 3201/23750] (105.146s) val loss: 0.013774
Batch 6401/23750, loss: 0.000487  [ 6401/23750] (143.455s) val loss: 0.009809
Batch 9601/23750, loss: 0.000131  [ 9601/23750] (143.873s) val loss: 0.014021
Batch 12801/23750, loss: 0.000504  [12801/23750] (143.933s) val loss: 0.010351
Batch 16001/23750, loss: 0.000051  [16001/23750] (144.009s) val loss: 0.007850
Batch 19201/23750, loss: 0.031609  [19201/23750] (143.895s) val loss: 0.008492
Batch 22401/23750, loss: 0.090719  [22401/23750] (143.774s) val loss: 0.008311
Batch 23750/23750, loss: 0.005430  [23750/23750] (83.026s) val loss: 0.010675
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.891s total
-------------------------------

Epoch 62
-------------------------------
Batch 3201/23750, loss: 0.001896  [ 3201/23750] (105.388s) val loss: 0.009553
Batch 6401/23750, loss: 0.003415  [ 6401/23750] (144.165s) val loss: 0.010606
Batch 9601/23750, loss: 0.000002  [ 9601/23750] (143.945s) val loss: 0.010288
Batch 12801/23750, loss: 0.005714  [12801/23750] (143.994s) val loss: 0.009856
Batch 16001/23750, loss: 0.000169  [16001/23750] (143.654s) val loss: 0.010777
Batch 19201/23750, loss: 0.000193  [19201/23750] (143.882s) val loss: 0.011250
Batch 22401/23750, loss: 0.000017  [22401/23750] (143.468s) val loss: 0.011244
Batch 23750/23750, loss: 0.010644  [23750/23750] (83.169s) val loss: 0.009463
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.392s total
-------------------------------

Epoch 63
-------------------------------
Batch 3201/23750, loss: 0.000435  [ 3201/23750] (104.892s) val loss: 0.014383
Batch 6401/23750, loss: 0.004676  [ 6401/23750] (144.095s) val loss: 0.011101
Batch 9601/23750, loss: 0.000084  [ 9601/23750] (143.964s) val loss: 0.008445
Batch 12801/23750, loss: 0.039149  [12801/23750] (144.029s) val loss: 0.009523
Batch 16001/23750, loss: 0.000191  [16001/23750] (143.991s) val loss: 0.008761
Batch 19201/23750, loss: 0.000000  [19201/23750] (143.602s) val loss: 0.011169
Batch 22401/23750, loss: 0.000008  [22401/23750] (143.619s) val loss: 0.008943
Batch 23750/23750, loss: 0.000596  [23750/23750] (82.884s) val loss: 0.009646
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.831s total
-------------------------------

Epoch 64
-------------------------------
Batch 3201/23750, loss: 0.099459  [ 3201/23750] (105.155s) val loss: 0.008930
Batch 6401/23750, loss: 0.001570  [ 6401/23750] (143.567s) val loss: 0.008551
Batch 9601/23750, loss: 0.000310  [ 9601/23750] (143.794s) val loss: 0.010340
Batch 12801/23750, loss: 0.001294  [12801/23750] (143.884s) val loss: 0.008972
Batch 16001/23750, loss: 0.000012  [16001/23750] (143.650s) val loss: 0.009661
Batch 19201/23750, loss: 0.001449  [19201/23750] (143.547s) val loss: 0.008670
Batch 22401/23750, loss: 0.000988  [22401/23750] (143.848s) val loss: 0.009482
Batch 23750/23750, loss: 0.001396  [23750/23750] (82.951s) val loss: 0.009541
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.131s total
-------------------------------

Epoch 65
-------------------------------
Batch 3201/23750, loss: 0.000053  [ 3201/23750] (105.520s) val loss: 0.009589
Batch 6401/23750, loss: 0.040300  [ 6401/23750] (143.404s) val loss: 0.017489
Batch 9601/23750, loss: 0.018684  [ 9601/23750] (143.829s) val loss: 0.009142
Batch 12801/23750, loss: 0.000614  [12801/23750] (143.874s) val loss: 0.010197
Batch 16001/23750, loss: 0.000124  [16001/23750] (143.781s) val loss: 0.009636
Batch 19201/23750, loss: 0.000336  [19201/23750] (143.687s) val loss: 0.008729
Batch 22401/23750, loss: 0.011367  [22401/23750] (143.459s) val loss: 0.009638
Batch 23750/23750, loss: 0.000002  [23750/23750] (82.909s) val loss: 0.010723
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.221s total
-------------------------------

Epoch 66
-------------------------------
Batch 3201/23750, loss: 0.000059  [ 3201/23750] (105.151s) val loss: 0.008231
Batch 6401/23750, loss: 0.001384  [ 6401/23750] (143.886s) val loss: 0.009042
Batch 9601/23750, loss: 0.000062  [ 9601/23750] (144.095s) val loss: 0.008336
Batch 12801/23750, loss: 0.000945  [12801/23750] (143.996s) val loss: 0.009801
Batch 16001/23750, loss: 0.000703  [16001/23750] (143.859s) val loss: 0.009298
Batch 19201/23750, loss: 0.000064  [19201/23750] (144.247s) val loss: 0.009225
Batch 22401/23750, loss: 0.057628  [22401/23750] (143.836s) val loss: 0.009395
Batch 23750/23750, loss: 0.002238  [23750/23750] (83.092s) val loss: 0.008495
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.926s total
-------------------------------

Epoch 67
-------------------------------
Batch 3201/23750, loss: 0.000107  [ 3201/23750] (105.347s) val loss: 0.009127
Batch 6401/23750, loss: 0.000000  [ 6401/23750] (143.585s) val loss: 0.007993
Batch 9601/23750, loss: 0.000012  [ 9601/23750] (144.370s) val loss: 0.008463
Batch 12801/23750, loss: 0.006252  [12801/23750] (143.796s) val loss: 0.010050
Batch 16001/23750, loss: 0.000001  [16001/23750] (144.133s) val loss: 0.009321
Batch 19201/23750, loss: 0.133473  [19201/23750] (143.896s) val loss: 0.011250
Batch 22401/23750, loss: 0.000150  [22401/23750] (143.575s) val loss: 0.008912
Batch 23750/23750, loss: 0.000958  [23750/23750] (82.919s) val loss: 0.011955
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.342s total
-------------------------------

Epoch 68
-------------------------------
Batch 3201/23750, loss: 0.000088  [ 3201/23750] (105.132s) val loss: 0.009501
Batch 6401/23750, loss: 0.000032  [ 6401/23750] (143.706s) val loss: 0.010078
Batch 9601/23750, loss: 0.064861  [ 9601/23750] (143.845s) val loss: 0.012183
Batch 12801/23750, loss: 0.000061  [12801/23750] (143.626s) val loss: 0.008676
Batch 16001/23750, loss: 0.002216  [16001/23750] (143.654s) val loss: 0.008185
Batch 19201/23750, loss: 0.000003  [19201/23750] (143.984s) val loss: 0.008501
Batch 22401/23750, loss: 0.000002  [22401/23750] (143.823s) val loss: 0.008102
Batch 23750/23750, loss: 0.000031  [23750/23750] (82.990s) val loss: 0.008390
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1089.512s total
-------------------------------

Epoch 69
-------------------------------
Batch 3201/23750, loss: 0.003842  [ 3201/23750] (105.415s) val loss: 0.009198
Batch 6401/23750, loss: 0.026557  [ 6401/23750] (143.460s) val loss: 0.012313
Batch 9601/23750, loss: 0.019201  [ 9601/23750] (144.603s) val loss: 0.008217
Batch 12801/23750, loss: 0.015068  [12801/23750] (146.774s) val loss: 0.009194
Batch 16001/23750, loss: 0.000300  [16001/23750] (143.537s) val loss: 0.008053
Batch 19201/23750, loss: 0.050985  [19201/23750] (143.956s) val loss: 0.008139
Batch 22401/23750, loss: 0.000002  [22401/23750] (143.815s) val loss: 0.009167
Batch 23750/23750, loss: 0.000251  [23750/23750] (82.822s) val loss: 0.008686
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1093.168s total
-------------------------------

Epoch 70
-------------------------------
Batch 3201/23750, loss: 0.003555  [ 3201/23750] (105.247s) val loss: 0.007537
Batch 6401/23750, loss: 0.000531  [ 6401/23750] (143.460s) val loss: 0.010427
Batch 9601/23750, loss: 0.012729  [ 9601/23750] (143.938s) val loss: 0.007977
Batch 12801/23750, loss: 0.000941  [12801/23750] (145.696s) val loss: 0.009861
Batch 16001/23750, loss: 0.000090  [16001/23750] (147.955s) val loss: 0.009408
Batch 19201/23750, loss: 0.000044  [19201/23750] (147.498s) val loss: 0.010246
Batch 22401/23750, loss: 0.000014  [22401/23750] (147.153s) val loss: 0.008401
Batch 23750/23750, loss: 0.025996  [23750/23750] (84.458s) val loss: 0.012492
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1104.720s total
-------------------------------

Epoch 71
-------------------------------
Batch 3201/23750, loss: 0.000296  [ 3201/23750] (105.516s) val loss: 0.008152
Batch 6401/23750, loss: 0.000000  [ 6401/23750] (143.660s) val loss: 0.007829
Batch 9601/23750, loss: 0.000930  [ 9601/23750] (144.864s) val loss: 0.008792
Batch 12801/23750, loss: 0.000041  [12801/23750] (147.800s) val loss: 0.008643
Batch 16001/23750, loss: 0.000079  [16001/23750] (147.155s) val loss: 0.009529
Batch 19201/23750, loss: 0.000255  [19201/23750] (144.759s) val loss: 0.008437
Batch 22401/23750, loss: 0.074299  [22401/23750] (143.952s) val loss: 0.008538
Batch 23750/23750, loss: 0.000051  [23750/23750] (82.984s) val loss: 0.009440
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1099.520s total
-------------------------------

Epoch 72
-------------------------------
Batch 3201/23750, loss: 0.003359  [ 3201/23750] (105.223s) val loss: 0.009549
Batch 6401/23750, loss: 0.000084  [ 6401/23750] (146.981s) val loss: 0.008699
Batch 9601/23750, loss: 0.000346  [ 9601/23750] (147.242s) val loss: 0.010690
Batch 12801/23750, loss: 0.002563  [12801/23750] (148.039s) val loss: 0.008664
Batch 16001/23750, loss: 0.000005  [16001/23750] (147.980s) val loss: 0.007491
Batch 19201/23750, loss: 0.000039  [19201/23750] (144.666s) val loss: 0.011330
Batch 22401/23750, loss: 0.005905  [22401/23750] (144.031s) val loss: 0.008647
Batch 23750/23750, loss: 0.000128  [23750/23750] (83.064s) val loss: 0.013192
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1106.028s total
-------------------------------

Epoch 73
-------------------------------
Batch 3201/23750, loss: 0.008420  [ 3201/23750] (105.045s) val loss: 0.009013
Batch 6401/23750, loss: 0.004412  [ 6401/23750] (143.929s) val loss: 0.008186
Batch 9601/23750, loss: 0.000434  [ 9601/23750] (143.593s) val loss: 0.009666
Batch 12801/23750, loss: 0.011572  [12801/23750] (143.541s) val loss: 0.008834
Batch 16001/23750, loss: 0.000293  [16001/23750] (146.290s) val loss: 0.007996
Batch 19201/23750, loss: 0.000015  [19201/23750] (147.896s) val loss: 0.009867
Batch 22401/23750, loss: 0.000093  [22401/23750] (148.026s) val loss: 0.008198
Batch 23750/23750, loss: 0.000000  [23750/23750] (84.997s) val loss: 0.008522
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1102.492s total
-------------------------------

Epoch 74
-------------------------------
Batch 3201/23750, loss: 0.000506  [ 3201/23750] (105.573s) val loss: 0.008211
Batch 6401/23750, loss: 0.085623  [ 6401/23750] (147.885s) val loss: 0.007952
Batch 9601/23750, loss: 0.000488  [ 9601/23750] (147.443s) val loss: 0.007636
Batch 12801/23750, loss: 0.000049  [12801/23750] (147.243s) val loss: 0.007913
Batch 16001/23750, loss: 0.000162  [16001/23750] (147.482s) val loss: 0.010735
Batch 19201/23750, loss: 0.000118  [19201/23750] (148.405s) val loss: 0.010070
Batch 22401/23750, loss: 0.000518  [22401/23750] (147.463s) val loss: 0.009235
Batch 23750/23750, loss: 0.000084  [23750/23750] (85.018s) val loss: 0.010758
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1115.575s total
-------------------------------

Epoch 75
-------------------------------
Batch 3201/23750, loss: 0.000558  [ 3201/23750] (109.069s) val loss: 0.007077
Batch 6401/23750, loss: 0.000012  [ 6401/23750] (147.455s) val loss: 0.007956
Batch 9601/23750, loss: 0.003552  [ 9601/23750] (147.617s) val loss: 0.008522
Batch 12801/23750, loss: 0.004621  [12801/23750] (147.537s) val loss: 0.008289
Batch 16001/23750, loss: 0.002372  [16001/23750] (147.321s) val loss: 0.009147
Batch 19201/23750, loss: 0.000142  [19201/23750] (147.351s) val loss: 0.007210
Batch 22401/23750, loss: 0.000782  [22401/23750] (147.713s) val loss: 0.007923
Batch 23750/23750, loss: 0.000975  [23750/23750] (85.179s) val loss: 0.007653
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1118.296s total
-------------------------------

Epoch 76
-------------------------------
Batch 3201/23750, loss: 0.000623  [ 3201/23750] (108.246s) val loss: 0.008131
Batch 6401/23750, loss: 0.000017  [ 6401/23750] (145.921s) val loss: 0.007873
Batch 9601/23750, loss: 0.001730  [ 9601/23750] (146.014s) val loss: 0.007570
Batch 12801/23750, loss: 0.000136  [12801/23750] (146.328s) val loss: 0.008917
Batch 16001/23750, loss: 0.000096  [16001/23750] (146.105s) val loss: 0.008792
Batch 19201/23750, loss: 0.001370  [19201/23750] (146.377s) val loss: 0.009147
Batch 22401/23750, loss: 0.000022  [22401/23750] (144.086s) val loss: 0.009371
Batch 23750/23750, loss: 0.012385  [23750/23750] (88.215s) val loss: 0.008861
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1110.249s total
-------------------------------

Epoch 77
-------------------------------
Batch 3201/23750, loss: 0.000268  [ 3201/23750] (105.314s) val loss: 0.008610
Batch 6401/23750, loss: 0.001033  [ 6401/23750] (143.793s) val loss: 0.008225
Batch 9601/23750, loss: 0.000118  [ 9601/23750] (144.129s) val loss: 0.007786
Batch 12801/23750, loss: 0.000057  [12801/23750] (143.795s) val loss: 0.008430
Batch 16001/23750, loss: 0.000245  [16001/23750] (143.994s) val loss: 0.007102
Batch 19201/23750, loss: 0.000534  [19201/23750] (143.830s) val loss: 0.008055
Batch 22401/23750, loss: 0.000033  [22401/23750] (143.668s) val loss: 0.012220
Batch 23750/23750, loss: 0.000005  [23750/23750] (82.813s) val loss: 0.008510
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1090.147s total
-------------------------------

Epoch 78
-------------------------------
Batch 3201/23750, loss: 0.000038  [ 3201/23750] (105.489s) val loss: 0.007046
Batch 6401/23750, loss: 0.011028  [ 6401/23750] (149.149s) val loss: 0.007999
Batch 9601/23750, loss: 0.000000  [ 9601/23750] (144.798s) val loss: 0.007889
Batch 12801/23750, loss: 0.001212  [12801/23750] (144.492s) val loss: 0.009258
Batch 16001/23750, loss: 0.000025  [16001/23750] (144.075s) val loss: 0.009075
Batch 19201/23750, loss: 0.000004  [19201/23750] (144.372s) val loss: 0.008937
Batch 22401/23750, loss: 0.000009  [22401/23750] (144.362s) val loss: 0.008193
Batch 23750/23750, loss: 0.000229  [23750/23750] (83.546s) val loss: 0.009888
Saved to /nfs/home/khom/test_projects/CNNTraining/models/experiment_model_1.pth
Took 1099.310s total
-------------------------------

Epoch 79
-------------------------------
Batch 3201/23750, loss: 0.042620  [ 3201/23750] (105.971s) val loss: 0.007855
Batch 6401/23750, loss: 0.000054  [ 6401/23750] (147.554s) val loss: 0.009094
Batch 9601/23750, loss: 0.000055  [ 9601/23750] (147.811s) val loss: 0.009666
