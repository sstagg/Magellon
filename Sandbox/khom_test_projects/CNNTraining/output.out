Using device: cuda:0


Epoch 1
-------------------------------
/opt/applications/pytorch/1.7/python3.8/cuda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Batch   0/825, loss: 0.053369  [   32/26389] (1.979s)
Batch 100/825, loss: 0.091444  [ 3232/26389] (19.785s)
Batch 200/825, loss: 0.105100  [ 6432/26389] (11.362s)
Batch 300/825, loss: 0.088529  [ 9632/26389] (4.233s)
Batch 400/825, loss: 0.077778  [12832/26389] (3.345s)
Batch 500/825, loss: 0.076102  [16032/26389] (3.245s)
Batch 600/825, loss: 0.077856  [19232/26389] (3.244s)
Batch 700/825, loss: 0.071666  [22432/26389] (3.268s)
Batch 800/825, loss: 0.046548  [25632/26389] (3.249s)
Batch 824/825, loss: 0.048022  [17325/26389] (0.794s)
Took 54.506s total
-------------------------------

Epoch 2
-------------------------------
Batch   0/825, loss: 0.086467  [   32/26389] (0.049s)
Batch 100/825, loss: 0.067369  [ 3232/26389] (3.290s)
Batch 200/825, loss: 0.086847  [ 6432/26389] (3.257s)
Batch 300/825, loss: 0.092722  [ 9632/26389] (3.260s)
Batch 400/825, loss: 0.078665  [12832/26389] (3.256s)
Batch 500/825, loss: 0.082454  [16032/26389] (3.289s)
Batch 600/825, loss: 0.082613  [19232/26389] (3.260s)
Batch 700/825, loss: 0.088317  [22432/26389] (3.259s)
Batch 800/825, loss: 0.079845  [25632/26389] (3.259s)
Batch 824/825, loss: 0.100113  [17325/26389] (0.789s)
Took 26.969s total
-------------------------------

Epoch 3
-------------------------------
Batch   0/825, loss: 0.073476  [   32/26389] (0.049s)
Batch 100/825, loss: 0.098075  [ 3232/26389] (3.287s)
Batch 200/825, loss: 0.035075  [ 6432/26389] (3.261s)
Batch 300/825, loss: 0.040155  [ 9632/26389] (3.262s)
Batch 400/825, loss: 0.112497  [12832/26389] (3.263s)
Batch 500/825, loss: 0.049731  [16032/26389] (3.262s)
Batch 600/825, loss: 0.071776  [19232/26389] (3.260s)
Batch 700/825, loss: 0.066687  [22432/26389] (3.260s)
Batch 800/825, loss: 0.087258  [25632/26389] (3.257s)
Batch 824/825, loss: 0.048881  [17325/26389] (0.789s)
Took 26.951s total
-------------------------------

Epoch 4
-------------------------------
Batch   0/825, loss: 0.138588  [   32/26389] (0.049s)
Batch 100/825, loss: 0.086048  [ 3232/26389] (3.292s)
Batch 200/825, loss: 0.094185  [ 6432/26389] (3.260s)
Batch 300/825, loss: 0.033542  [ 9632/26389] (3.261s)
Batch 400/825, loss: 0.062133  [12832/26389] (3.261s)
Batch 500/825, loss: 0.111226  [16032/26389] (3.263s)
Batch 600/825, loss: 0.099379  [19232/26389] (3.283s)
Batch 700/825, loss: 0.056186  [22432/26389] (3.291s)
Batch 800/825, loss: 0.054555  [25632/26389] (3.282s)
Batch 824/825, loss: 0.060889  [17325/26389] (0.791s)
Took 27.035s total
-------------------------------

Epoch 5
-------------------------------
Batch   0/825, loss: 0.027684  [   32/26389] (0.049s)
Batch 100/825, loss: 0.136980  [ 3232/26389] (3.326s)
Batch 200/825, loss: 0.050739  [ 6432/26389] (3.285s)
Batch 300/825, loss: 0.073320  [ 9632/26389] (3.259s)
Batch 400/825, loss: 0.075082  [12832/26389] (3.262s)
Batch 500/825, loss: 0.079749  [16032/26389] (3.258s)
Batch 600/825, loss: 0.051448  [19232/26389] (3.289s)
Batch 700/825, loss: 0.024911  [22432/26389] (3.260s)
Batch 800/825, loss: 0.100811  [25632/26389] (3.255s)
Batch 824/825, loss: 0.051947  [17325/26389] (0.792s)
Took 27.036s total
-------------------------------

Epoch 6
-------------------------------
Batch   0/825, loss: 0.151905  [   32/26389] (0.049s)
Batch 100/825, loss: 0.105932  [ 3232/26389] (3.259s)
Batch 200/825, loss: 0.128522  [ 6432/26389] (3.257s)
Batch 300/825, loss: 0.105521  [ 9632/26389] (3.289s)
Batch 400/825, loss: 0.087594  [12832/26389] (3.255s)
Batch 500/825, loss: 0.059379  [16032/26389] (3.290s)
Batch 600/825, loss: 0.067187  [19232/26389] (3.260s)
Batch 700/825, loss: 0.103488  [22432/26389] (3.261s)
Batch 800/825, loss: 0.041532  [25632/26389] (3.299s)
Batch 824/825, loss: 0.044690  [17325/26389] (0.790s)
Took 27.009s total
-------------------------------

Took 189.5051 seconds
Done

