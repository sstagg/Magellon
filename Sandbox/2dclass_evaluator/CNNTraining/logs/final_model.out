Using sequence <function sequence8 at 0x7f95da22f310>

TRAINING OVERVIEW
-------------------------------
OPTIMIZER:
 Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
) 
-------------------------------
LOSS FUNCTION:
 MSELoss() 
-------------------------------
MODEL ARCHITECTURE:
 MRCNetwork(
  (cnn_network): Sequential(
    (0): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.25, inplace=False)
    (3): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): Dropout(p=0.25, inplace=False)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2))
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Dropout(p=0.25, inplace=False)
    (9): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): Dropout(p=0.25, inplace=False)
    (12): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Dropout(p=0.25, inplace=False)
    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))
    (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): Dropout(p=0.25, inplace=False)
    (18): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Dropout(p=0.25, inplace=False)
    (21): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): Dropout(p=0.25, inplace=False)
    (24): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Dropout(p=0.25, inplace=False)
    (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))
    (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): Dropout(p=0.25, inplace=False)
    (30): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (downsampler): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Dropout(p=0.25, inplace=False)
    (33): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (35): Dropout(p=0.25, inplace=False)
    (36): ResidualConvBlock(
      (nonlinear): ReLU()
      (layer1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (layer2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (batchnorm): Sequential(
        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Dropout(p=0.25, inplace=False)
    (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
    (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (41): Dropout(p=0.25, inplace=False)
    (42): AdaptiveAvgPool2d(output_size=(6, 6))
    (43): Flatten(start_dim=1, end_dim=-1)
    (44): ReLU()
  )
  (feat_network): Sequential(
    (0): Linear(in_features=4614, out_features=1, bias=True)
  )
) 
-------------------------------
OTHER:
Training with batch size of 32
Running on device cuda:0
Split 10.00% of data for validation data
Preparing to train in parallel: main device on cuda:0, all devices on [0, 1]
Will save model to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Expecting fixed size data
-------------------------------

Fetching MRC image data from /nfs/home/khom/test_projects/ClassAvgLabeling/ProcessedData/combined_data_flen.hdf5
Found fixed length data
Fetching MRC image data from /nfs/home/khom/test_projects/ClassAvgLabeling/ProcessedData/combined_data_flen.hdf5
Found fixed length data
Selecting subset of size 28983 out of 32204... done
Selecting subset of size 3221 out of 32204... done
Ready to train

Beginning training for 125 epochs (from epoch 1)...
Epoch 1
-------------------------------
Batch  76/906, loss: 0.072208  [ 2432/28983] (28.846s) val loss: 0.076107
Batch 151/906, loss: 0.065918  [ 4832/28983] (41.090s) val loss: 0.086313
Batch 226/906, loss: 0.083424  [ 7232/28983] (41.291s) val loss: 0.068861
Batch 301/906, loss: 0.068070  [ 9632/28983] (41.475s) val loss: 0.082618
Batch 376/906, loss: 0.027753  [12032/28983] (41.587s) val loss: 0.091016
Batch 451/906, loss: 0.046844  [14432/28983] (41.752s) val loss: 0.101682
Batch 526/906, loss: 0.029583  [16832/28983] (41.740s) val loss: 0.091787
Batch 601/906, loss: 0.048160  [19232/28983] (41.723s) val loss: 0.092685
Batch 676/906, loss: 0.051267  [21632/28983] (41.591s) val loss: 0.113607
Batch 751/906, loss: 0.041764  [24032/28983] (41.566s) val loss: 0.101542
Batch 826/906, loss: 0.032512  [26432/28983] (41.555s) val loss: 0.092703
Batch 901/906, loss: 0.024460  [28832/28983] (41.496s) val loss: 0.107212
Batch 906/906, loss: 0.030806  [28983/28983] (16.206s) val loss: 0.110253
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 516.762s total
-------------------------------

Epoch 2
-------------------------------
Batch  76/906, loss: 0.024635  [ 2432/28983] (27.447s) val loss: 0.102640
Batch 151/906, loss: 0.038886  [ 4832/28983] (41.450s) val loss: 0.081915
Batch 226/906, loss: 0.037618  [ 7232/28983] (41.488s) val loss: 0.085295
Batch 301/906, loss: 0.032893  [ 9632/28983] (41.450s) val loss: 0.068185
Batch 376/906, loss: 0.032487  [12032/28983] (41.455s) val loss: 0.066824
Batch 451/906, loss: 0.029378  [14432/28983] (41.476s) val loss: 0.067741
Batch 526/906, loss: 0.014912  [16832/28983] (41.480s) val loss: 0.065032
Batch 601/906, loss: 0.034700  [19232/28983] (41.449s) val loss: 0.076199
Batch 676/906, loss: 0.028115  [21632/28983] (41.432s) val loss: 0.068122
Batch 751/906, loss: 0.049375  [24032/28983] (41.476s) val loss: 0.053114
Batch 826/906, loss: 0.029783  [26432/28983] (41.413s) val loss: 0.060451
Batch 901/906, loss: 0.031142  [28832/28983] (41.468s) val loss: 0.068283
Batch 906/906, loss: 0.028247  [28983/28983] (16.124s) val loss: 0.064775
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.331s total
-------------------------------

Epoch 3
-------------------------------
Batch  76/906, loss: 0.036650  [ 2432/28983] (27.313s) val loss: 0.069327
Batch 151/906, loss: 0.033506  [ 4832/28983] (41.433s) val loss: 0.055645
Batch 226/906, loss: 0.024831  [ 7232/28983] (41.450s) val loss: 0.053976
Batch 301/906, loss: 0.014879  [ 9632/28983] (41.405s) val loss: 0.052762
Batch 376/906, loss: 0.023861  [12032/28983] (41.473s) val loss: 0.046770
Batch 451/906, loss: 0.027496  [14432/28983] (41.433s) val loss: 0.044843
Batch 526/906, loss: 0.022809  [16832/28983] (41.392s) val loss: 0.063615
Batch 601/906, loss: 0.012387  [19232/28983] (41.520s) val loss: 0.063122
Batch 676/906, loss: 0.019211  [21632/28983] (41.466s) val loss: 0.054455
Batch 751/906, loss: 0.023795  [24032/28983] (41.457s) val loss: 0.045433
Batch 826/906, loss: 0.018556  [26432/28983] (41.501s) val loss: 0.041423
Batch 901/906, loss: 0.017908  [28832/28983] (41.468s) val loss: 0.036580
Batch 906/906, loss: 0.029738  [28983/28983] (16.117s) val loss: 0.036304
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.135s total
-------------------------------

Epoch 4
-------------------------------
Batch  76/906, loss: 0.028778  [ 2432/28983] (27.376s) val loss: 0.038786
Batch 151/906, loss: 0.020200  [ 4832/28983] (41.369s) val loss: 0.028517
Batch 226/906, loss: 0.033895  [ 7232/28983] (41.469s) val loss: 0.041033
Batch 301/906, loss: 0.012286  [ 9632/28983] (41.460s) val loss: 0.037959
Batch 376/906, loss: 0.023843  [12032/28983] (41.353s) val loss: 0.036882
Batch 451/906, loss: 0.022052  [14432/28983] (41.460s) val loss: 0.030442
Batch 526/906, loss: 0.015442  [16832/28983] (41.475s) val loss: 0.025163
Batch 601/906, loss: 0.021962  [19232/28983] (41.412s) val loss: 0.031043
Batch 676/906, loss: 0.022076  [21632/28983] (41.419s) val loss: 0.033477
Batch 751/906, loss: 0.012506  [24032/28983] (41.691s) val loss: 0.029464
Batch 826/906, loss: 0.031858  [26432/28983] (41.745s) val loss: 0.034523
Batch 901/906, loss: 0.013824  [28832/28983] (41.704s) val loss: 0.022035
Batch 906/906, loss: 0.020898  [28983/28983] (16.269s) val loss: 0.029969
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.028s total
-------------------------------

Epoch 5
-------------------------------
Batch  76/906, loss: 0.009827  [ 2432/28983] (27.511s) val loss: 0.025928
Batch 151/906, loss: 0.010132  [ 4832/28983] (41.631s) val loss: 0.024244
Batch 226/906, loss: 0.006901  [ 7232/28983] (41.744s) val loss: 0.036458
Batch 301/906, loss: 0.021503  [ 9632/28983] (41.749s) val loss: 0.038328
Batch 376/906, loss: 0.012062  [12032/28983] (41.627s) val loss: 0.031554
Batch 451/906, loss: 0.010730  [14432/28983] (41.711s) val loss: 0.035013
Batch 526/906, loss: 0.018500  [16832/28983] (41.737s) val loss: 0.028246
Batch 601/906, loss: 0.011118  [19232/28983] (41.723s) val loss: 0.042282
Batch 676/906, loss: 0.004568  [21632/28983] (41.723s) val loss: 0.029049
Batch 751/906, loss: 0.010459  [24032/28983] (41.691s) val loss: 0.022644
Batch 826/906, loss: 0.009063  [26432/28983] (41.701s) val loss: 0.030140
Batch 901/906, loss: 0.008296  [28832/28983] (41.795s) val loss: 0.018899
Batch 906/906, loss: 0.017726  [28983/28983] (16.304s) val loss: 0.029992
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 517.462s total
-------------------------------

Epoch 6
-------------------------------
Batch  76/906, loss: 0.019901  [ 2432/28983] (27.501s) val loss: 0.030170
Batch 151/906, loss: 0.008419  [ 4832/28983] (41.630s) val loss: 0.027629
Batch 226/906, loss: 0.015889  [ 7232/28983] (41.707s) val loss: 0.022145
Batch 301/906, loss: 0.013094  [ 9632/28983] (41.682s) val loss: 0.028964
Batch 376/906, loss: 0.016643  [12032/28983] (41.641s) val loss: 0.022647
Batch 451/906, loss: 0.009265  [14432/28983] (41.707s) val loss: 0.025512
Batch 526/906, loss: 0.014895  [16832/28983] (41.696s) val loss: 0.027225
Batch 601/906, loss: 0.035208  [19232/28983] (41.704s) val loss: 0.021663
Batch 676/906, loss: 0.016136  [21632/28983] (41.704s) val loss: 0.020103
Batch 751/906, loss: 0.018676  [24032/28983] (41.714s) val loss: 0.032768
Batch 826/906, loss: 0.009974  [26432/28983] (41.700s) val loss: 0.021164
Batch 901/906, loss: 0.017047  [28832/28983] (41.672s) val loss: 0.019743
Batch 906/906, loss: 0.010468  [28983/28983] (16.282s) val loss: 0.024944
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 517.177s total
-------------------------------

Epoch 7
-------------------------------
Batch  76/906, loss: 0.009292  [ 2432/28983] (27.508s) val loss: 0.018013
Batch 151/906, loss: 0.014451  [ 4832/28983] (41.719s) val loss: 0.018899
Batch 226/906, loss: 0.014478  [ 7232/28983] (41.648s) val loss: 0.024119
Batch 301/906, loss: 0.013543  [ 9632/28983] (41.711s) val loss: 0.020217
Batch 376/906, loss: 0.011494  [12032/28983] (41.632s) val loss: 0.017550
Batch 451/906, loss: 0.017563  [14432/28983] (41.719s) val loss: 0.024076
Batch 526/906, loss: 0.012079  [16832/28983] (41.738s) val loss: 0.018930
Batch 601/906, loss: 0.021018  [19232/28983] (41.713s) val loss: 0.021228
Batch 676/906, loss: 0.005556  [21632/28983] (41.688s) val loss: 0.057532
Batch 751/906, loss: 0.009864  [24032/28983] (41.703s) val loss: 0.020784
Batch 826/906, loss: 0.012253  [26432/28983] (41.710s) val loss: 0.015379
Batch 901/906, loss: 0.013504  [28832/28983] (41.712s) val loss: 0.021558
Batch 906/906, loss: 0.023409  [28983/28983] (16.262s) val loss: 0.018398
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 517.308s total
-------------------------------

Epoch 8
-------------------------------
Batch  76/906, loss: 0.009817  [ 2432/28983] (27.546s) val loss: 0.016809
Batch 151/906, loss: 0.009555  [ 4832/28983] (41.599s) val loss: 0.022328
Batch 226/906, loss: 0.010119  [ 7232/28983] (41.725s) val loss: 0.021884
Batch 301/906, loss: 0.011866  [ 9632/28983] (41.694s) val loss: 0.015463
Batch 376/906, loss: 0.005831  [12032/28983] (41.637s) val loss: 0.014416
Batch 451/906, loss: 0.005521  [14432/28983] (41.695s) val loss: 0.018958
Batch 526/906, loss: 0.013641  [16832/28983] (41.740s) val loss: 0.015987
Batch 601/906, loss: 0.013406  [19232/28983] (41.706s) val loss: 0.016640
Batch 676/906, loss: 0.008619  [21632/28983] (41.762s) val loss: 0.021107
Batch 751/906, loss: 0.012393  [24032/28983] (41.661s) val loss: 0.017835
Batch 826/906, loss: 0.020361  [26432/28983] (41.752s) val loss: 0.012091
Batch 901/906, loss: 0.005898  [28832/28983] (41.685s) val loss: 0.019825
Batch 906/906, loss: 0.011103  [28983/28983] (16.279s) val loss: 0.014003
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 517.300s total
-------------------------------

Epoch 9
-------------------------------
Batch  76/906, loss: 0.011406  [ 2432/28983] (27.473s) val loss: 0.018670
Batch 151/906, loss: 0.008147  [ 4832/28983] (41.638s) val loss: 0.016976
Batch 226/906, loss: 0.010885  [ 7232/28983] (41.714s) val loss: 0.020713
Batch 301/906, loss: 0.014449  [ 9632/28983] (41.743s) val loss: 0.012828
Batch 376/906, loss: 0.007804  [12032/28983] (41.652s) val loss: 0.015433
Batch 451/906, loss: 0.008150  [14432/28983] (41.775s) val loss: 0.015034
Batch 526/906, loss: 0.010877  [16832/28983] (41.709s) val loss: 0.014591
Batch 601/906, loss: 0.016208  [19232/28983] (41.697s) val loss: 0.014129
Batch 676/906, loss: 0.007477  [21632/28983] (41.693s) val loss: 0.013793
Batch 751/906, loss: 0.008379  [24032/28983] (41.651s) val loss: 0.012399
Batch 826/906, loss: 0.007892  [26432/28983] (41.710s) val loss: 0.020985
Batch 901/906, loss: 0.011285  [28832/28983] (41.647s) val loss: 0.016991
Batch 906/906, loss: 0.003501  [28983/28983] (16.229s) val loss: 0.013235
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 517.118s total
-------------------------------

Epoch 10
-------------------------------
Batch  76/906, loss: 0.026692  [ 2432/28983] (27.324s) val loss: 0.015817
Batch 151/906, loss: 0.005194  [ 4832/28983] (41.301s) val loss: 0.013309
Batch 226/906, loss: 0.011850  [ 7232/28983] (41.332s) val loss: 0.012343
Batch 301/906, loss: 0.005320  [ 9632/28983] (41.379s) val loss: 0.015963
Batch 376/906, loss: 0.009918  [12032/28983] (41.266s) val loss: 0.014276
Batch 451/906, loss: 0.006093  [14432/28983] (41.410s) val loss: 0.011776
Batch 526/906, loss: 0.006691  [16832/28983] (41.343s) val loss: 0.013060
Batch 601/906, loss: 0.010157  [19232/28983] (41.455s) val loss: 0.011143
Batch 676/906, loss: 0.015503  [21632/28983] (41.357s) val loss: 0.014688
Batch 751/906, loss: 0.019269  [24032/28983] (41.351s) val loss: 0.027618
Batch 826/906, loss: 0.011453  [26432/28983] (41.363s) val loss: 0.021619
Batch 901/906, loss: 0.005867  [28832/28983] (41.342s) val loss: 0.014442
Batch 906/906, loss: 0.011994  [28983/28983] (16.140s) val loss: 0.018006
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.041s total
-------------------------------

Epoch 11
-------------------------------
Batch  76/906, loss: 0.006979  [ 2432/28983] (27.332s) val loss: 0.013234
Batch 151/906, loss: 0.014887  [ 4832/28983] (41.293s) val loss: 0.011347
Batch 226/906, loss: 0.006332  [ 7232/28983] (41.430s) val loss: 0.011995
Batch 301/906, loss: 0.007309  [ 9632/28983] (41.355s) val loss: 0.017690
Batch 376/906, loss: 0.010755  [12032/28983] (41.318s) val loss: 0.012763
Batch 451/906, loss: 0.009661  [14432/28983] (41.397s) val loss: 0.010576
Batch 526/906, loss: 0.010470  [16832/28983] (41.415s) val loss: 0.011959
Batch 601/906, loss: 0.009365  [19232/28983] (41.353s) val loss: 0.015696
Batch 676/906, loss: 0.012551  [21632/28983] (41.405s) val loss: 0.012008
Batch 751/906, loss: 0.011823  [24032/28983] (41.407s) val loss: 0.010771
Batch 826/906, loss: 0.009591  [26432/28983] (41.433s) val loss: 0.011074
Batch 901/906, loss: 0.007718  [28832/28983] (41.373s) val loss: 0.012136
Batch 906/906, loss: 0.006207  [28983/28983] (16.093s) val loss: 0.013323
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.282s total
-------------------------------

Epoch 12
-------------------------------
Batch  76/906, loss: 0.009175  [ 2432/28983] (27.312s) val loss: 0.009836
Batch 151/906, loss: 0.008754  [ 4832/28983] (41.322s) val loss: 0.010605
Batch 226/906, loss: 0.002808  [ 7232/28983] (41.379s) val loss: 0.010787
Batch 301/906, loss: 0.013695  [ 9632/28983] (41.377s) val loss: 0.013536
Batch 376/906, loss: 0.031168  [12032/28983] (41.321s) val loss: 0.010167
Batch 451/906, loss: 0.005093  [14432/28983] (41.420s) val loss: 0.012255
Batch 526/906, loss: 0.019038  [16832/28983] (41.385s) val loss: 0.011798
Batch 601/906, loss: 0.007989  [19232/28983] (41.360s) val loss: 0.011426
Batch 676/906, loss: 0.005975  [21632/28983] (41.408s) val loss: 0.010472
Batch 751/906, loss: 0.009970  [24032/28983] (41.439s) val loss: 0.011822
Batch 826/906, loss: 0.014721  [26432/28983] (41.409s) val loss: 0.011937
Batch 901/906, loss: 0.008939  [28832/28983] (41.435s) val loss: 0.013552
Batch 906/906, loss: 0.006659  [28983/28983] (16.221s) val loss: 0.011083
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.477s total
-------------------------------

Epoch 13
-------------------------------
Batch  76/906, loss: 0.012306  [ 2432/28983] (27.340s) val loss: 0.011521
Batch 151/906, loss: 0.017851  [ 4832/28983] (41.325s) val loss: 0.009628
Batch 226/906, loss: 0.010142  [ 7232/28983] (41.383s) val loss: 0.010553
Batch 301/906, loss: 0.005201  [ 9632/28983] (41.345s) val loss: 0.012756
Batch 376/906, loss: 0.009547  [12032/28983] (41.294s) val loss: 0.011913
Batch 451/906, loss: 0.005119  [14432/28983] (41.373s) val loss: 0.012091
Batch 526/906, loss: 0.008128  [16832/28983] (41.396s) val loss: 0.010057
Batch 601/906, loss: 0.018331  [19232/28983] (41.356s) val loss: 0.010934
Batch 676/906, loss: 0.006091  [21632/28983] (41.402s) val loss: 0.011956
Batch 751/906, loss: 0.006650  [24032/28983] (41.352s) val loss: 0.010815
Batch 826/906, loss: 0.003633  [26432/28983] (41.384s) val loss: 0.009306
Batch 901/906, loss: 0.013877  [28832/28983] (41.377s) val loss: 0.011329
Batch 906/906, loss: 0.007489  [28983/28983] (16.112s) val loss: 0.010074
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.113s total
-------------------------------

Epoch 14
-------------------------------
Batch  76/906, loss: 0.008138  [ 2432/28983] (27.365s) val loss: 0.009330
Batch 151/906, loss: 0.007382  [ 4832/28983] (41.289s) val loss: 0.012910
Batch 226/906, loss: 0.008926  [ 7232/28983] (41.432s) val loss: 0.010548
Batch 301/906, loss: 0.007315  [ 9632/28983] (41.345s) val loss: 0.009341
Batch 376/906, loss: 0.007078  [12032/28983] (41.303s) val loss: 0.011028
Batch 451/906, loss: 0.005885  [14432/28983] (41.376s) val loss: 0.009681
Batch 526/906, loss: 0.005898  [16832/28983] (41.382s) val loss: 0.011393
Batch 601/906, loss: 0.004926  [19232/28983] (41.375s) val loss: 0.009781
Batch 676/906, loss: 0.004087  [21632/28983] (41.343s) val loss: 0.009852
Batch 751/906, loss: 0.007422  [24032/28983] (41.381s) val loss: 0.010888
Batch 826/906, loss: 0.011852  [26432/28983] (41.368s) val loss: 0.010919
Batch 901/906, loss: 0.005179  [28832/28983] (41.350s) val loss: 0.010322
Batch 906/906, loss: 0.006198  [28983/28983] (16.119s) val loss: 0.009811
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.097s total
-------------------------------

Epoch 15
-------------------------------
Batch  76/906, loss: 0.012218  [ 2432/28983] (27.323s) val loss: 0.011570
Batch 151/906, loss: 0.007040  [ 4832/28983] (41.297s) val loss: 0.011841
Batch 226/906, loss: 0.008937  [ 7232/28983] (41.386s) val loss: 0.009934
Batch 301/906, loss: 0.014940  [ 9632/28983] (41.404s) val loss: 0.011604
Batch 376/906, loss: 0.009121  [12032/28983] (41.298s) val loss: 0.010084
Batch 451/906, loss: 0.005687  [14432/28983] (41.367s) val loss: 0.011304
Batch 526/906, loss: 0.007431  [16832/28983] (41.359s) val loss: 0.011031
Batch 601/906, loss: 0.008506  [19232/28983] (41.328s) val loss: 0.011115
Batch 676/906, loss: 0.009324  [21632/28983] (41.319s) val loss: 0.009995
Batch 751/906, loss: 0.006577  [24032/28983] (41.377s) val loss: 0.012623
Batch 826/906, loss: 0.005311  [26432/28983] (41.366s) val loss: 0.009298
Batch 901/906, loss: 0.011342  [28832/28983] (41.345s) val loss: 0.012622
Batch 906/906, loss: 0.016503  [28983/28983] (16.114s) val loss: 0.009178
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.932s total
-------------------------------

Epoch 16
-------------------------------
Batch  76/906, loss: 0.005594  [ 2432/28983] (27.309s) val loss: 0.010966
Batch 151/906, loss: 0.003732  [ 4832/28983] (41.314s) val loss: 0.008636
Batch 226/906, loss: 0.014323  [ 7232/28983] (41.394s) val loss: 0.009601
Batch 301/906, loss: 0.004832  [ 9632/28983] (41.375s) val loss: 0.009446
Batch 376/906, loss: 0.005307  [12032/28983] (41.321s) val loss: 0.010267
Batch 451/906, loss: 0.008403  [14432/28983] (41.374s) val loss: 0.009613
Batch 526/906, loss: 0.009885  [16832/28983] (41.392s) val loss: 0.012223
Batch 601/906, loss: 0.010119  [19232/28983] (41.477s) val loss: 0.009153
Batch 676/906, loss: 0.004254  [21632/28983] (41.404s) val loss: 0.009374
Batch 751/906, loss: 0.005307  [24032/28983] (41.383s) val loss: 0.009091
Batch 826/906, loss: 0.010532  [26432/28983] (41.404s) val loss: 0.008590
Batch 901/906, loss: 0.009932  [28832/28983] (41.357s) val loss: 0.010099
Batch 906/906, loss: 0.002832  [28983/28983] (16.140s) val loss: 0.009797
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.328s total
-------------------------------

Epoch 17
-------------------------------
Batch  76/906, loss: 0.010360  [ 2432/28983] (27.333s) val loss: 0.009574
Batch 151/906, loss: 0.003501  [ 4832/28983] (41.283s) val loss: 0.009294
Batch 226/906, loss: 0.010004  [ 7232/28983] (41.342s) val loss: 0.009248
Batch 301/906, loss: 0.005237  [ 9632/28983] (41.372s) val loss: 0.011189
Batch 376/906, loss: 0.018249  [12032/28983] (41.303s) val loss: 0.011510
Batch 451/906, loss: 0.009499  [14432/28983] (41.373s) val loss: 0.009589
Batch 526/906, loss: 0.005152  [16832/28983] (41.394s) val loss: 0.008261
Batch 601/906, loss: 0.014531  [19232/28983] (41.369s) val loss: 0.009032
Batch 676/906, loss: 0.007598  [21632/28983] (41.386s) val loss: 0.008756
Batch 751/906, loss: 0.024439  [24032/28983] (41.359s) val loss: 0.009466
Batch 826/906, loss: 0.012170  [26432/28983] (41.435s) val loss: 0.010997
Batch 901/906, loss: 0.005754  [28832/28983] (41.378s) val loss: 0.009313
Batch 906/906, loss: 0.012902  [28983/28983] (16.111s) val loss: 0.009232
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.104s total
-------------------------------

Epoch 18
-------------------------------
Batch  76/906, loss: 0.005721  [ 2432/28983] (27.366s) val loss: 0.007983
Batch 151/906, loss: 0.006401  [ 4832/28983] (41.250s) val loss: 0.008293
Batch 226/906, loss: 0.018784  [ 7232/28983] (41.319s) val loss: 0.008143
Batch 301/906, loss: 0.006179  [ 9632/28983] (41.306s) val loss: 0.010298
Batch 376/906, loss: 0.009933  [12032/28983] (41.232s) val loss: 0.008831
Batch 451/906, loss: 0.007176  [14432/28983] (41.332s) val loss: 0.009311
Batch 526/906, loss: 0.005704  [16832/28983] (41.326s) val loss: 0.008409
Batch 601/906, loss: 0.009409  [19232/28983] (41.346s) val loss: 0.008180
Batch 676/906, loss: 0.005520  [21632/28983] (41.358s) val loss: 0.008926
Batch 751/906, loss: 0.004546  [24032/28983] (41.336s) val loss: 0.009775
Batch 826/906, loss: 0.016062  [26432/28983] (41.331s) val loss: 0.008097
Batch 901/906, loss: 0.005824  [28832/28983] (41.298s) val loss: 0.010509
Batch 906/906, loss: 0.011529  [28983/28983] (16.123s) val loss: 0.008942
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.557s total
-------------------------------

Epoch 19
-------------------------------
Batch  76/906, loss: 0.005216  [ 2432/28983] (27.312s) val loss: 0.008365
Batch 151/906, loss: 0.004926  [ 4832/28983] (41.255s) val loss: 0.011089
Batch 226/906, loss: 0.010095  [ 7232/28983] (41.272s) val loss: 0.009727
Batch 301/906, loss: 0.009986  [ 9632/28983] (41.316s) val loss: 0.008993
Batch 376/906, loss: 0.006773  [12032/28983] (41.216s) val loss: 0.008361
Batch 451/906, loss: 0.005294  [14432/28983] (41.303s) val loss: 0.009636
Batch 526/906, loss: 0.003341  [16832/28983] (41.301s) val loss: 0.009829
Batch 601/906, loss: 0.008282  [19232/28983] (41.275s) val loss: 0.009013
Batch 676/906, loss: 0.004772  [21632/28983] (41.316s) val loss: 0.009075
Batch 751/906, loss: 0.012397  [24032/28983] (41.342s) val loss: 0.010929
Batch 826/906, loss: 0.007609  [26432/28983] (41.262s) val loss: 0.008099
Batch 901/906, loss: 0.006075  [28832/28983] (41.324s) val loss: 0.009162
Batch 906/906, loss: 0.005922  [28983/28983] (16.062s) val loss: 0.008774
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.173s total
-------------------------------

Epoch 20
-------------------------------
Batch  76/906, loss: 0.007799  [ 2432/28983] (27.314s) val loss: 0.008067
Batch 151/906, loss: 0.013298  [ 4832/28983] (41.247s) val loss: 0.008504
Batch 226/906, loss: 0.003480  [ 7232/28983] (41.291s) val loss: 0.008633
Batch 301/906, loss: 0.007668  [ 9632/28983] (41.310s) val loss: 0.010028
Batch 376/906, loss: 0.003989  [12032/28983] (41.218s) val loss: 0.010303
Batch 451/906, loss: 0.004204  [14432/28983] (41.289s) val loss: 0.008111
Batch 526/906, loss: 0.005792  [16832/28983] (41.317s) val loss: 0.009451
Batch 601/906, loss: 0.011406  [19232/28983] (41.326s) val loss: 0.008337
Batch 676/906, loss: 0.005190  [21632/28983] (41.280s) val loss: 0.008713
Batch 751/906, loss: 0.002991  [24032/28983] (41.268s) val loss: 0.008325
Batch 826/906, loss: 0.004997  [26432/28983] (41.313s) val loss: 0.008402
Batch 901/906, loss: 0.010370  [28832/28983] (41.295s) val loss: 0.008868
Batch 906/906, loss: 0.009790  [28983/28983] (16.073s) val loss: 0.008999
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.171s total
-------------------------------

Epoch 21
-------------------------------
Batch  76/906, loss: 0.010106  [ 2432/28983] (27.302s) val loss: 0.008130
Batch 151/906, loss: 0.008510  [ 4832/28983] (41.191s) val loss: 0.008759
Batch 226/906, loss: 0.008869  [ 7232/28983] (41.300s) val loss: 0.007659
Batch 301/906, loss: 0.009450  [ 9632/28983] (41.295s) val loss: 0.009237
Batch 376/906, loss: 0.006925  [12032/28983] (41.215s) val loss: 0.009568
Batch 451/906, loss: 0.009644  [14432/28983] (41.382s) val loss: 0.008069
Batch 526/906, loss: 0.010766  [16832/28983] (41.373s) val loss: 0.008141
Batch 601/906, loss: 0.010774  [19232/28983] (41.331s) val loss: 0.008030
Batch 676/906, loss: 0.007047  [21632/28983] (41.341s) val loss: 0.007768
Batch 751/906, loss: 0.039414  [24032/28983] (41.354s) val loss: 0.009252
Batch 826/906, loss: 0.008700  [26432/28983] (41.326s) val loss: 0.008962
Batch 901/906, loss: 0.004671  [28832/28983] (41.399s) val loss: 0.009653
Batch 906/906, loss: 0.011763  [28983/28983] (16.103s) val loss: 0.008824
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.562s total
-------------------------------

Epoch 22
-------------------------------
Batch  76/906, loss: 0.008850  [ 2432/28983] (27.332s) val loss: 0.008951
Batch 151/906, loss: 0.009989  [ 4832/28983] (41.290s) val loss: 0.008891
Batch 226/906, loss: 0.004485  [ 7232/28983] (41.372s) val loss: 0.007981
Batch 301/906, loss: 0.006216  [ 9632/28983] (41.355s) val loss: 0.007840
Batch 376/906, loss: 0.005361  [12032/28983] (41.300s) val loss: 0.009337
Batch 451/906, loss: 0.006874  [14432/28983] (41.391s) val loss: 0.007858
Batch 526/906, loss: 0.015405  [16832/28983] (41.346s) val loss: 0.008426
Batch 601/906, loss: 0.007769  [19232/28983] (41.377s) val loss: 0.008402
Batch 676/906, loss: 0.009247  [21632/28983] (41.381s) val loss: 0.008210
Batch 751/906, loss: 0.004930  [24032/28983] (41.351s) val loss: 0.008679
Batch 826/906, loss: 0.006186  [26432/28983] (41.347s) val loss: 0.009233
Batch 901/906, loss: 0.003648  [28832/28983] (41.337s) val loss: 0.007276
Batch 906/906, loss: 0.015459  [28983/28983] (16.107s) val loss: 0.007336
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.928s total
-------------------------------

Epoch 23
-------------------------------
Batch  76/906, loss: 0.007079  [ 2432/28983] (27.312s) val loss: 0.008309
Batch 151/906, loss: 0.015559  [ 4832/28983] (41.297s) val loss: 0.007736
Batch 226/906, loss: 0.004189  [ 7232/28983] (41.342s) val loss: 0.008086
Batch 301/906, loss: 0.005782  [ 9632/28983] (41.372s) val loss: 0.007676
Batch 376/906, loss: 0.006277  [12032/28983] (41.282s) val loss: 0.007638
Batch 451/906, loss: 0.009595  [14432/28983] (41.393s) val loss: 0.007976
Batch 526/906, loss: 0.002637  [16832/28983] (41.409s) val loss: 0.008790
Batch 601/906, loss: 0.004632  [19232/28983] (41.389s) val loss: 0.008094
Batch 676/906, loss: 0.006973  [21632/28983] (41.357s) val loss: 0.007610
Batch 751/906, loss: 0.007707  [24032/28983] (41.355s) val loss: 0.008376
Batch 826/906, loss: 0.008192  [26432/28983] (41.423s) val loss: 0.007008
Batch 901/906, loss: 0.015426  [28832/28983] (41.374s) val loss: 0.009401
Batch 906/906, loss: 0.006936  [28983/28983] (16.085s) val loss: 0.009288
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.058s total
-------------------------------

Epoch 24
-------------------------------
Batch  76/906, loss: 0.005585  [ 2432/28983] (27.332s) val loss: 0.007499
Batch 151/906, loss: 0.007490  [ 4832/28983] (41.298s) val loss: 0.008240
Batch 226/906, loss: 0.005613  [ 7232/28983] (41.333s) val loss: 0.007631
Batch 301/906, loss: 0.006366  [ 9632/28983] (41.358s) val loss: 0.008880
Batch 376/906, loss: 0.012780  [12032/28983] (41.301s) val loss: 0.008724
Batch 451/906, loss: 0.004188  [14432/28983] (41.351s) val loss: 0.007305
Batch 526/906, loss: 0.007621  [16832/28983] (41.371s) val loss: 0.007781
Batch 601/906, loss: 0.003017  [19232/28983] (41.382s) val loss: 0.007224
Batch 676/906, loss: 0.003692  [21632/28983] (41.408s) val loss: 0.007593
Batch 751/906, loss: 0.008987  [24032/28983] (41.403s) val loss: 0.007939
Batch 826/906, loss: 0.006340  [26432/28983] (41.426s) val loss: 0.007371
Batch 901/906, loss: 0.008113  [28832/28983] (41.298s) val loss: 0.007926
Batch 906/906, loss: 0.025256  [28983/28983] (16.188s) val loss: 0.008037
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.077s total
-------------------------------

Epoch 25
-------------------------------
Batch  76/906, loss: 0.010330  [ 2432/28983] (27.266s) val loss: 0.007298
Batch 151/906, loss: 0.018671  [ 4832/28983] (41.245s) val loss: 0.007980
Batch 226/906, loss: 0.007112  [ 7232/28983] (41.285s) val loss: 0.008614
Batch 301/906, loss: 0.009497  [ 9632/28983] (41.255s) val loss: 0.007914
Batch 376/906, loss: 0.009459  [12032/28983] (41.225s) val loss: 0.008279
Batch 451/906, loss: 0.004877  [14432/28983] (41.258s) val loss: 0.007769
Batch 526/906, loss: 0.003806  [16832/28983] (41.260s) val loss: 0.007496
Batch 601/906, loss: 0.010635  [19232/28983] (41.293s) val loss: 0.007429
Batch 676/906, loss: 0.007554  [21632/28983] (41.236s) val loss: 0.008091
Batch 751/906, loss: 0.006805  [24032/28983] (41.306s) val loss: 0.007743
Batch 826/906, loss: 0.003614  [26432/28983] (41.282s) val loss: 0.007275
Batch 901/906, loss: 0.008595  [28832/28983] (41.299s) val loss: 0.007797
Batch 906/906, loss: 0.003297  [28983/28983] (16.067s) val loss: 0.007887
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.905s total
-------------------------------

Epoch 26
-------------------------------
Batch  76/906, loss: 0.014760  [ 2432/28983] (27.272s) val loss: 0.008173
Batch 151/906, loss: 0.010177  [ 4832/28983] (41.228s) val loss: 0.010412
Batch 226/906, loss: 0.009515  [ 7232/28983] (41.293s) val loss: 0.006894
Batch 301/906, loss: 0.010285  [ 9632/28983] (41.239s) val loss: 0.007419
Batch 376/906, loss: 0.003498  [12032/28983] (41.226s) val loss: 0.007568
Batch 451/906, loss: 0.010258  [14432/28983] (41.299s) val loss: 0.008268
Batch 526/906, loss: 0.008530  [16832/28983] (41.296s) val loss: 0.007770
Batch 601/906, loss: 0.009137  [19232/28983] (41.314s) val loss: 0.007586
Batch 676/906, loss: 0.003832  [21632/28983] (41.281s) val loss: 0.007979
Batch 751/906, loss: 0.009321  [24032/28983] (41.290s) val loss: 0.008029
Batch 826/906, loss: 0.013047  [26432/28983] (41.309s) val loss: 0.008408
Batch 901/906, loss: 0.007032  [28832/28983] (41.302s) val loss: 0.007894
Batch 906/906, loss: 0.007159  [28983/28983] (16.071s) val loss: 0.007737
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.065s total
-------------------------------

Epoch 27
-------------------------------
Batch  76/906, loss: 0.012105  [ 2432/28983] (27.283s) val loss: 0.007186
Batch 151/906, loss: 0.016387  [ 4832/28983] (41.211s) val loss: 0.008019
Batch 226/906, loss: 0.008267  [ 7232/28983] (41.297s) val loss: 0.007287
Batch 301/906, loss: 0.008331  [ 9632/28983] (41.321s) val loss: 0.008557
Batch 376/906, loss: 0.002439  [12032/28983] (41.217s) val loss: 0.007749
Batch 451/906, loss: 0.005209  [14432/28983] (41.393s) val loss: 0.007189
Batch 526/906, loss: 0.006323  [16832/28983] (41.332s) val loss: 0.007026
Batch 601/906, loss: 0.007299  [19232/28983] (41.345s) val loss: 0.007080
Batch 676/906, loss: 0.003691  [21632/28983] (41.315s) val loss: 0.007539
Batch 751/906, loss: 0.006732  [24032/28983] (41.690s) val loss: 0.007373
Batch 826/906, loss: 0.005261  [26432/28983] (41.719s) val loss: 0.007520
Batch 901/906, loss: 0.014504  [28832/28983] (41.664s) val loss: 0.010015
Batch 906/906, loss: 0.004588  [28983/28983] (16.264s) val loss: 0.007492
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.857s total
-------------------------------

Epoch 28
-------------------------------
Batch  76/906, loss: 0.005258  [ 2432/28983] (27.528s) val loss: 0.008363
Batch 151/906, loss: 0.005101  [ 4832/28983] (41.624s) val loss: 0.007431
Batch 226/906, loss: 0.004974  [ 7232/28983] (41.397s) val loss: 0.007293
Batch 301/906, loss: 0.010630  [ 9632/28983] (41.317s) val loss: 0.007315
Batch 376/906, loss: 0.005544  [12032/28983] (41.206s) val loss: 0.007632
Batch 451/906, loss: 0.011748  [14432/28983] (41.292s) val loss: 0.007733
Batch 526/906, loss: 0.006371  [16832/28983] (41.287s) val loss: 0.007807
Batch 601/906, loss: 0.003011  [19232/28983] (41.378s) val loss: 0.007747
Batch 676/906, loss: 0.008165  [21632/28983] (41.303s) val loss: 0.006780
Batch 751/906, loss: 0.006754  [24032/28983] (41.298s) val loss: 0.007480
Batch 826/906, loss: 0.004984  [26432/28983] (41.300s) val loss: 0.007769
Batch 901/906, loss: 0.013703  [28832/28983] (41.292s) val loss: 0.007416
Batch 906/906, loss: 0.008428  [28983/28983] (16.055s) val loss: 0.009762
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.896s total
-------------------------------

Epoch 29
-------------------------------
Batch  76/906, loss: 0.008608  [ 2432/28983] (27.300s) val loss: 0.007380
Batch 151/906, loss: 0.010725  [ 4832/28983] (41.223s) val loss: 0.007681
Batch 226/906, loss: 0.005521  [ 7232/28983] (41.311s) val loss: 0.007376
Batch 301/906, loss: 0.004490  [ 9632/28983] (41.273s) val loss: 0.008056
Batch 376/906, loss: 0.004910  [12032/28983] (41.249s) val loss: 0.007855
Batch 451/906, loss: 0.005378  [14432/28983] (41.283s) val loss: 0.007152
Batch 526/906, loss: 0.002971  [16832/28983] (41.311s) val loss: 0.007001
Batch 601/906, loss: 0.006145  [19232/28983] (41.295s) val loss: 0.007527
Batch 676/906, loss: 0.003705  [21632/28983] (41.269s) val loss: 0.007285
Batch 751/906, loss: 0.003382  [24032/28983] (41.294s) val loss: 0.007036
Batch 826/906, loss: 0.006485  [26432/28983] (41.322s) val loss: 0.007455
Batch 901/906, loss: 0.009181  [28832/28983] (41.301s) val loss: 0.007417
Batch 906/906, loss: 0.004666  [28983/28983] (16.063s) val loss: 0.007303
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.129s total
-------------------------------

Epoch 30
-------------------------------
Batch  76/906, loss: 0.002802  [ 2432/28983] (27.280s) val loss: 0.007307
Batch 151/906, loss: 0.009602  [ 4832/28983] (41.233s) val loss: 0.007145
Batch 226/906, loss: 0.009414  [ 7232/28983] (41.303s) val loss: 0.007123
Batch 301/906, loss: 0.013187  [ 9632/28983] (41.308s) val loss: 0.007117
Batch 376/906, loss: 0.005711  [12032/28983] (41.223s) val loss: 0.007445
Batch 451/906, loss: 0.013724  [14432/28983] (41.347s) val loss: 0.006881
Batch 526/906, loss: 0.003260  [16832/28983] (41.343s) val loss: 0.007303
Batch 601/906, loss: 0.005458  [19232/28983] (41.320s) val loss: 0.007590
Batch 676/906, loss: 0.005285  [21632/28983] (41.238s) val loss: 0.007015
Batch 751/906, loss: 0.008910  [24032/28983] (41.296s) val loss: 0.008299
Batch 826/906, loss: 0.007553  [26432/28983] (41.381s) val loss: 0.007123
Batch 901/906, loss: 0.003611  [28832/28983] (41.385s) val loss: 0.007760
Batch 906/906, loss: 0.003930  [28983/28983] (16.099s) val loss: 0.007130
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.422s total
-------------------------------

Epoch 31
-------------------------------
Batch  76/906, loss: 0.005223  [ 2432/28983] (27.348s) val loss: 0.007149
Batch 151/906, loss: 0.005877  [ 4832/28983] (41.342s) val loss: 0.006831
Batch 226/906, loss: 0.003233  [ 7232/28983] (41.399s) val loss: 0.007864
Batch 301/906, loss: 0.007631  [ 9632/28983] (41.404s) val loss: 0.007752
Batch 376/906, loss: 0.009090  [12032/28983] (41.375s) val loss: 0.007767
Batch 451/906, loss: 0.005544  [14432/28983] (41.437s) val loss: 0.007911
Batch 526/906, loss: 0.006114  [16832/28983] (41.409s) val loss: 0.008221
Batch 601/906, loss: 0.004581  [19232/28983] (41.440s) val loss: 0.007141
Batch 676/906, loss: 0.004864  [21632/28983] (41.436s) val loss: 0.006998
Batch 751/906, loss: 0.010447  [24032/28983] (41.424s) val loss: 0.006780
Batch 826/906, loss: 0.010823  [26432/28983] (41.450s) val loss: 0.007421
Batch 901/906, loss: 0.013787  [28832/28983] (41.375s) val loss: 0.007428
Batch 906/906, loss: 0.003653  [28983/28983] (16.126s) val loss: 0.006809
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.676s total
-------------------------------

Epoch 32
-------------------------------
Batch  76/906, loss: 0.004710  [ 2432/28983] (27.420s) val loss: 0.008049
Batch 151/906, loss: 0.004323  [ 4832/28983] (41.370s) val loss: 0.006910
Batch 226/906, loss: 0.001939  [ 7232/28983] (41.509s) val loss: 0.006901
Batch 301/906, loss: 0.006528  [ 9632/28983] (41.372s) val loss: 0.007711
Batch 376/906, loss: 0.005023  [12032/28983] (41.298s) val loss: 0.007792
Batch 451/906, loss: 0.002638  [14432/28983] (41.368s) val loss: 0.007190
Batch 526/906, loss: 0.003368  [16832/28983] (41.414s) val loss: 0.007180
Batch 601/906, loss: 0.006409  [19232/28983] (41.365s) val loss: 0.007335
Batch 676/906, loss: 0.004421  [21632/28983] (41.389s) val loss: 0.008219
Batch 751/906, loss: 0.006880  [24032/28983] (41.360s) val loss: 0.007706
Batch 826/906, loss: 0.005563  [26432/28983] (41.372s) val loss: 0.007236
Batch 901/906, loss: 0.008993  [28832/28983] (41.362s) val loss: 0.007094
Batch 906/906, loss: 0.013022  [28983/28983] (16.106s) val loss: 0.006821
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.384s total
-------------------------------

Epoch 33
-------------------------------
Batch  76/906, loss: 0.011968  [ 2432/28983] (27.339s) val loss: 0.007418
Batch 151/906, loss: 0.008421  [ 4832/28983] (41.261s) val loss: 0.007282
Batch 226/906, loss: 0.008532  [ 7232/28983] (41.351s) val loss: 0.007305
Batch 301/906, loss: 0.003309  [ 9632/28983] (41.354s) val loss: 0.006993
Batch 376/906, loss: 0.005000  [12032/28983] (41.269s) val loss: 0.007164
Batch 451/906, loss: 0.006898  [14432/28983] (41.468s) val loss: 0.006796
Batch 526/906, loss: 0.005539  [16832/28983] (41.354s) val loss: 0.007641
Batch 601/906, loss: 0.008633  [19232/28983] (41.367s) val loss: 0.006845
Batch 676/906, loss: 0.004750  [21632/28983] (41.377s) val loss: 0.008518
Batch 751/906, loss: 0.002741  [24032/28983] (41.357s) val loss: 0.007756
Batch 826/906, loss: 0.007337  [26432/28983] (41.368s) val loss: 0.006958
Batch 901/906, loss: 0.004271  [28832/28983] (41.320s) val loss: 0.007031
Batch 906/906, loss: 0.002278  [28983/28983] (16.098s) val loss: 0.007246
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.951s total
-------------------------------

Epoch 34
-------------------------------
Batch  76/906, loss: 0.004556  [ 2432/28983] (27.287s) val loss: 0.006381
Batch 151/906, loss: 0.004741  [ 4832/28983] (41.239s) val loss: 0.007475
Batch 226/906, loss: 0.007990  [ 7232/28983] (41.333s) val loss: 0.008042
Batch 301/906, loss: 0.004954  [ 9632/28983] (41.324s) val loss: 0.006709
Batch 376/906, loss: 0.007285  [12032/28983] (41.315s) val loss: 0.008262
Batch 451/906, loss: 0.006410  [14432/28983] (41.664s) val loss: 0.007146
Batch 526/906, loss: 0.003887  [16832/28983] (41.641s) val loss: 0.007138
Batch 601/906, loss: 0.005679  [19232/28983] (41.655s) val loss: 0.007087
Batch 676/906, loss: 0.005880  [21632/28983] (41.651s) val loss: 0.007350
Batch 751/906, loss: 0.005449  [24032/28983] (41.649s) val loss: 0.006957
Batch 826/906, loss: 0.003132  [26432/28983] (41.651s) val loss: 0.006844
Batch 901/906, loss: 0.007433  [28832/28983] (41.663s) val loss: 0.007253
Batch 906/906, loss: 0.002840  [28983/28983] (16.263s) val loss: 0.007077
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.199s total
-------------------------------

Epoch 35
-------------------------------
Batch  76/906, loss: 0.004642  [ 2432/28983] (27.440s) val loss: 0.006480
Batch 151/906, loss: 0.005972  [ 4832/28983] (41.554s) val loss: 0.006982
Batch 226/906, loss: 0.008764  [ 7232/28983] (41.682s) val loss: 0.007196
Batch 301/906, loss: 0.004988  [ 9632/28983] (41.612s) val loss: 0.007160
Batch 376/906, loss: 0.004680  [12032/28983] (41.590s) val loss: 0.007181
Batch 451/906, loss: 0.006148  [14432/28983] (41.643s) val loss: 0.006899
Batch 526/906, loss: 0.003882  [16832/28983] (41.650s) val loss: 0.007103
Batch 601/906, loss: 0.008222  [19232/28983] (41.639s) val loss: 0.006473
Batch 676/906, loss: 0.008788  [21632/28983] (41.633s) val loss: 0.007075
Batch 751/906, loss: 0.003783  [24032/28983] (41.727s) val loss: 0.007323
Batch 826/906, loss: 0.003689  [26432/28983] (41.663s) val loss: 0.007280
Batch 901/906, loss: 0.017529  [28832/28983] (41.634s) val loss: 0.008199
Batch 906/906, loss: 0.007051  [28983/28983] (16.264s) val loss: 0.007543
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 516.559s total
-------------------------------

Epoch 36
-------------------------------
Batch  76/906, loss: 0.006190  [ 2432/28983] (27.451s) val loss: 0.006769
Batch 151/906, loss: 0.006468  [ 4832/28983] (41.582s) val loss: 0.006796
Batch 226/906, loss: 0.010607  [ 7232/28983] (41.662s) val loss: 0.007755
Batch 301/906, loss: 0.018560  [ 9632/28983] (41.642s) val loss: 0.007504
Batch 376/906, loss: 0.006248  [12032/28983] (41.603s) val loss: 0.007989
Batch 451/906, loss: 0.006750  [14432/28983] (41.637s) val loss: 0.006344
Batch 526/906, loss: 0.006302  [16832/28983] (41.677s) val loss: 0.006514
Batch 601/906, loss: 0.005477  [19232/28983] (41.654s) val loss: 0.006724
Batch 676/906, loss: 0.007464  [21632/28983] (41.670s) val loss: 0.006934
Batch 751/906, loss: 0.002262  [24032/28983] (41.636s) val loss: 0.007101
Batch 826/906, loss: 0.004264  [26432/28983] (41.648s) val loss: 0.006892
Batch 901/906, loss: 0.004157  [28832/28983] (41.695s) val loss: 0.006939
Batch 906/906, loss: 0.007500  [28983/28983] (16.263s) val loss: 0.006763
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 516.630s total
-------------------------------

Epoch 37
-------------------------------
Batch  76/906, loss: 0.003276  [ 2432/28983] (27.445s) val loss: 0.007320
Batch 151/906, loss: 0.008021  [ 4832/28983] (41.609s) val loss: 0.006947
Batch 226/906, loss: 0.005648  [ 7232/28983] (41.632s) val loss: 0.007543
Batch 301/906, loss: 0.004051  [ 9632/28983] (41.654s) val loss: 0.006819
Batch 376/906, loss: 0.005363  [12032/28983] (41.556s) val loss: 0.007146
Batch 451/906, loss: 0.003008  [14432/28983] (41.664s) val loss: 0.006613
Batch 526/906, loss: 0.006120  [16832/28983] (41.667s) val loss: 0.006693
Batch 601/906, loss: 0.003456  [19232/28983] (41.606s) val loss: 0.007110
Batch 676/906, loss: 0.003517  [21632/28983] (41.602s) val loss: 0.006920
Batch 751/906, loss: 0.001736  [24032/28983] (41.589s) val loss: 0.007365
Batch 826/906, loss: 0.005544  [26432/28983] (41.619s) val loss: 0.006796
Batch 901/906, loss: 0.004790  [28832/28983] (41.612s) val loss: 0.006675
Batch 906/906, loss: 0.006941  [28983/28983] (16.258s) val loss: 0.006974
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 516.330s total
-------------------------------

Epoch 38
-------------------------------
Batch  76/906, loss: 0.006908  [ 2432/28983] (27.426s) val loss: 0.008041
Batch 151/906, loss: 0.011631  [ 4832/28983] (41.566s) val loss: 0.006831
Batch 226/906, loss: 0.006579  [ 7232/28983] (41.627s) val loss: 0.006575
Batch 301/906, loss: 0.005730  [ 9632/28983] (41.616s) val loss: 0.007684
Batch 376/906, loss: 0.003653  [12032/28983] (41.556s) val loss: 0.007268
Batch 451/906, loss: 0.005697  [14432/28983] (41.586s) val loss: 0.007144
Batch 526/906, loss: 0.004648  [16832/28983] (41.632s) val loss: 0.006792
Batch 601/906, loss: 0.009700  [19232/28983] (41.596s) val loss: 0.007140
Batch 676/906, loss: 0.011461  [21632/28983] (41.590s) val loss: 0.006601
Batch 751/906, loss: 0.004995  [24032/28983] (41.625s) val loss: 0.006795
Batch 826/906, loss: 0.014675  [26432/28983] (41.588s) val loss: 0.006743
Batch 901/906, loss: 0.008165  [28832/28983] (41.633s) val loss: 0.006895
Batch 906/906, loss: 0.017272  [28983/28983] (16.243s) val loss: 0.007122
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 516.187s total
-------------------------------

Epoch 39
-------------------------------
Batch  76/906, loss: 0.004917  [ 2432/28983] (27.464s) val loss: 0.006741
Batch 151/906, loss: 0.003341  [ 4832/28983] (41.509s) val loss: 0.007279
Batch 226/906, loss: 0.004109  [ 7232/28983] (41.600s) val loss: 0.006885
Batch 301/906, loss: 0.002284  [ 9632/28983] (41.697s) val loss: 0.006726
Batch 376/906, loss: 0.011977  [12032/28983] (41.549s) val loss: 0.007549
Batch 451/906, loss: 0.006434  [14432/28983] (41.621s) val loss: 0.007000
Batch 526/906, loss: 0.005366  [16832/28983] (41.596s) val loss: 0.006539
Batch 601/906, loss: 0.008966  [19232/28983] (41.598s) val loss: 0.007245
Batch 676/906, loss: 0.009175  [21632/28983] (41.576s) val loss: 0.006957
Batch 751/906, loss: 0.003200  [24032/28983] (41.422s) val loss: 0.007092
Batch 826/906, loss: 0.005782  [26432/28983] (41.336s) val loss: 0.006406
Batch 901/906, loss: 0.006925  [28832/28983] (41.297s) val loss: 0.006641
Batch 906/906, loss: 0.008357  [28983/28983] (16.097s) val loss: 0.006914
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.013s total
-------------------------------

Epoch 40
-------------------------------
Batch  76/906, loss: 0.002656  [ 2432/28983] (27.319s) val loss: 0.006787
Batch 151/906, loss: 0.005152  [ 4832/28983] (41.286s) val loss: 0.006461
Batch 226/906, loss: 0.002984  [ 7232/28983] (41.292s) val loss: 0.006964
Batch 301/906, loss: 0.002933  [ 9632/28983] (41.265s) val loss: 0.006660
Batch 376/906, loss: 0.006675  [12032/28983] (41.173s) val loss: 0.006656
Batch 451/906, loss: 0.018027  [14432/28983] (41.264s) val loss: 0.007067
Batch 526/906, loss: 0.005004  [16832/28983] (41.297s) val loss: 0.006944
Batch 601/906, loss: 0.002431  [19232/28983] (41.242s) val loss: 0.006555
Batch 676/906, loss: 0.006392  [21632/28983] (41.282s) val loss: 0.006865
Batch 751/906, loss: 0.006258  [24032/28983] (41.292s) val loss: 0.006641
Batch 826/906, loss: 0.006389  [26432/28983] (41.239s) val loss: 0.007389
Batch 901/906, loss: 0.011106  [28832/28983] (41.284s) val loss: 0.007976
Batch 906/906, loss: 0.003615  [28983/28983] (16.052s) val loss: 0.006945
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.948s total
-------------------------------

Epoch 41
-------------------------------
Batch  76/906, loss: 0.002264  [ 2432/28983] (27.286s) val loss: 0.006373
Batch 151/906, loss: 0.009404  [ 4832/28983] (41.170s) val loss: 0.007056
Batch 226/906, loss: 0.016087  [ 7232/28983] (41.281s) val loss: 0.006803
Batch 301/906, loss: 0.003863  [ 9632/28983] (41.287s) val loss: 0.006697
Batch 376/906, loss: 0.016219  [12032/28983] (41.210s) val loss: 0.006451
Batch 451/906, loss: 0.003819  [14432/28983] (41.318s) val loss: 0.006760
Batch 526/906, loss: 0.012759  [16832/28983] (41.289s) val loss: 0.006868
Batch 601/906, loss: 0.005777  [19232/28983] (41.308s) val loss: 0.006514
Batch 676/906, loss: 0.001087  [21632/28983] (41.277s) val loss: 0.006842
Batch 751/906, loss: 0.008268  [24032/28983] (41.316s) val loss: 0.006884
Batch 826/906, loss: 0.005737  [26432/28983] (41.319s) val loss: 0.006506
Batch 901/906, loss: 0.002823  [28832/28983] (41.284s) val loss: 0.006962
Batch 906/906, loss: 0.004187  [28983/28983] (16.106s) val loss: 0.006603
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.100s total
-------------------------------

Epoch 42
-------------------------------
Batch  76/906, loss: 0.006323  [ 2432/28983] (27.279s) val loss: 0.006657
Batch 151/906, loss: 0.004791  [ 4832/28983] (41.178s) val loss: 0.006263
Batch 226/906, loss: 0.004055  [ 7232/28983] (41.280s) val loss: 0.006740
Batch 301/906, loss: 0.007611  [ 9632/28983] (41.302s) val loss: 0.006706
Batch 376/906, loss: 0.005523  [12032/28983] (41.217s) val loss: 0.006703
Batch 451/906, loss: 0.007948  [14432/28983] (41.304s) val loss: 0.006282
Batch 526/906, loss: 0.006449  [16832/28983] (41.251s) val loss: 0.007486
Batch 601/906, loss: 0.003624  [19232/28983] (41.289s) val loss: 0.006455
Batch 676/906, loss: 0.006255  [21632/28983] (41.299s) val loss: 0.006140
Batch 751/906, loss: 0.003982  [24032/28983] (41.287s) val loss: 0.007009
Batch 826/906, loss: 0.002962  [26432/28983] (41.278s) val loss: 0.007177
Batch 901/906, loss: 0.004250  [28832/28983] (41.326s) val loss: 0.006369
Batch 906/906, loss: 0.003498  [28983/28983] (16.085s) val loss: 0.006342
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.001s total
-------------------------------

Epoch 43
-------------------------------
Batch  76/906, loss: 0.002521  [ 2432/28983] (27.273s) val loss: 0.006995
Batch 151/906, loss: 0.008211  [ 4832/28983] (41.591s) val loss: 0.006768
Batch 226/906, loss: 0.003931  [ 7232/28983] (41.658s) val loss: 0.006548
Batch 301/906, loss: 0.003333  [ 9632/28983] (41.661s) val loss: 0.006693
Batch 376/906, loss: 0.010928  [12032/28983] (41.578s) val loss: 0.006646
Batch 451/906, loss: 0.007470  [14432/28983] (41.684s) val loss: 0.007239
Batch 526/906, loss: 0.003445  [16832/28983] (41.644s) val loss: 0.006506
Batch 601/906, loss: 0.005524  [19232/28983] (41.653s) val loss: 0.006610
Batch 676/906, loss: 0.010555  [21632/28983] (41.433s) val loss: 0.006474
Batch 751/906, loss: 0.007025  [24032/28983] (41.340s) val loss: 0.006646
Batch 826/906, loss: 0.011668  [26432/28983] (41.367s) val loss: 0.006316
Batch 901/906, loss: 0.004558  [28832/28983] (41.324s) val loss: 0.007084
Batch 906/906, loss: 0.002821  [28983/28983] (16.110s) val loss: 0.006622
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.966s total
-------------------------------

Epoch 44
-------------------------------
Batch  76/906, loss: 0.012273  [ 2432/28983] (27.278s) val loss: 0.007038
Batch 151/906, loss: 0.004196  [ 4832/28983] (41.348s) val loss: 0.007211
Batch 226/906, loss: 0.008360  [ 7232/28983] (41.302s) val loss: 0.006290
Batch 301/906, loss: 0.007073  [ 9632/28983] (41.320s) val loss: 0.007299
Batch 376/906, loss: 0.007603  [12032/28983] (41.270s) val loss: 0.006545
Batch 451/906, loss: 0.003527  [14432/28983] (41.315s) val loss: 0.006384
Batch 526/906, loss: 0.004859  [16832/28983] (41.333s) val loss: 0.006381
Batch 601/906, loss: 0.003375  [19232/28983] (41.337s) val loss: 0.006423
Batch 676/906, loss: 0.009346  [21632/28983] (41.633s) val loss: 0.006125
Batch 751/906, loss: 0.008000  [24032/28983] (41.614s) val loss: 0.006447
Batch 826/906, loss: 0.009302  [26432/28983] (41.623s) val loss: 0.008564
Batch 901/906, loss: 0.008565  [28832/28983] (41.521s) val loss: 0.006906
Batch 906/906, loss: 0.009067  [28983/28983] (16.100s) val loss: 0.006721
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.666s total
-------------------------------

Epoch 45
-------------------------------
Batch  76/906, loss: 0.004600  [ 2432/28983] (27.297s) val loss: 0.007388
Batch 151/906, loss: 0.004305  [ 4832/28983] (41.296s) val loss: 0.006708
Batch 226/906, loss: 0.004986  [ 7232/28983] (41.385s) val loss: 0.006535
Batch 301/906, loss: 0.009775  [ 9632/28983] (41.322s) val loss: 0.006531
Batch 376/906, loss: 0.006143  [12032/28983] (41.268s) val loss: 0.007082
Batch 451/906, loss: 0.004633  [14432/28983] (41.370s) val loss: 0.006265
Batch 526/906, loss: 0.004261  [16832/28983] (41.366s) val loss: 0.006995
Batch 601/906, loss: 0.011876  [19232/28983] (41.373s) val loss: 0.007694
Batch 676/906, loss: 0.002323  [21632/28983] (41.400s) val loss: 0.006628
Batch 751/906, loss: 0.007236  [24032/28983] (41.308s) val loss: 0.006788
Batch 826/906, loss: 0.016914  [26432/28983] (41.358s) val loss: 0.006406
Batch 901/906, loss: 0.010091  [28832/28983] (41.396s) val loss: 0.006810
Batch 906/906, loss: 0.006990  [28983/28983] (16.120s) val loss: 0.006802
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.931s total
-------------------------------

Epoch 46
-------------------------------
Batch  76/906, loss: 0.008918  [ 2432/28983] (27.318s) val loss: 0.006519
Batch 151/906, loss: 0.003009  [ 4832/28983] (41.283s) val loss: 0.006478
Batch 226/906, loss: 0.003007  [ 7232/28983] (41.329s) val loss: 0.006409
Batch 301/906, loss: 0.008967  [ 9632/28983] (41.322s) val loss: 0.006554
Batch 376/906, loss: 0.003950  [12032/28983] (41.341s) val loss: 0.006603
Batch 451/906, loss: 0.008682  [14432/28983] (41.385s) val loss: 0.007071
Batch 526/906, loss: 0.004262  [16832/28983] (41.385s) val loss: 0.006765
Batch 601/906, loss: 0.007458  [19232/28983] (41.374s) val loss: 0.006157
Batch 676/906, loss: 0.006362  [21632/28983] (41.343s) val loss: 0.007053
Batch 751/906, loss: 0.005682  [24032/28983] (41.359s) val loss: 0.006555
Batch 826/906, loss: 0.008523  [26432/28983] (41.308s) val loss: 0.006543
Batch 901/906, loss: 0.010753  [28832/28983] (41.300s) val loss: 0.006573
Batch 906/906, loss: 0.009241  [28983/28983] (16.080s) val loss: 0.006590
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.787s total
-------------------------------

Epoch 47
-------------------------------
Batch  76/906, loss: 0.008214  [ 2432/28983] (27.287s) val loss: 0.006634
Batch 151/906, loss: 0.006770  [ 4832/28983] (41.235s) val loss: 0.006535
Batch 226/906, loss: 0.006081  [ 7232/28983] (41.292s) val loss: 0.006848
Batch 301/906, loss: 0.005518  [ 9632/28983] (41.305s) val loss: 0.006863
Batch 376/906, loss: 0.005194  [12032/28983] (41.212s) val loss: 0.006343
Batch 451/906, loss: 0.005342  [14432/28983] (41.301s) val loss: 0.007337
Batch 526/906, loss: 0.007441  [16832/28983] (41.317s) val loss: 0.007304
Batch 601/906, loss: 0.004825  [19232/28983] (41.316s) val loss: 0.006678
Batch 676/906, loss: 0.013678  [21632/28983] (41.283s) val loss: 0.006279
Batch 751/906, loss: 0.006441  [24032/28983] (41.330s) val loss: 0.006589
Batch 826/906, loss: 0.005095  [26432/28983] (41.541s) val loss: 0.006225
Batch 901/906, loss: 0.002996  [28832/28983] (41.450s) val loss: 0.007328
Batch 906/906, loss: 0.004143  [28983/28983] (16.119s) val loss: 0.006933
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.637s total
-------------------------------

Epoch 48
-------------------------------
Batch  76/906, loss: 0.008160  [ 2432/28983] (27.320s) val loss: 0.006683
Batch 151/906, loss: 0.003948  [ 4832/28983] (41.244s) val loss: 0.006600
Batch 226/906, loss: 0.006625  [ 7232/28983] (41.333s) val loss: 0.007174
Batch 301/906, loss: 0.004052  [ 9632/28983] (41.319s) val loss: 0.006584
Batch 376/906, loss: 0.006596  [12032/28983] (41.292s) val loss: 0.007034
Batch 451/906, loss: 0.004223  [14432/28983] (41.325s) val loss: 0.006666
Batch 526/906, loss: 0.003764  [16832/28983] (41.330s) val loss: 0.006519
Batch 601/906, loss: 0.003306  [19232/28983] (41.342s) val loss: 0.006302
Batch 676/906, loss: 0.005861  [21632/28983] (41.345s) val loss: 0.006772
Batch 751/906, loss: 0.008929  [24032/28983] (41.374s) val loss: 0.006754
Batch 826/906, loss: 0.007409  [26432/28983] (41.376s) val loss: 0.006232
Batch 901/906, loss: 0.002514  [28832/28983] (41.360s) val loss: 0.006093
Batch 906/906, loss: 0.003483  [28983/28983] (16.136s) val loss: 0.005912
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.844s total
-------------------------------

Epoch 49
-------------------------------
Batch  76/906, loss: 0.008392  [ 2432/28983] (27.284s) val loss: 0.006732
Batch 151/906, loss: 0.011313  [ 4832/28983] (41.233s) val loss: 0.006351
Batch 226/906, loss: 0.005279  [ 7232/28983] (41.307s) val loss: 0.006335
Batch 301/906, loss: 0.007799  [ 9632/28983] (41.326s) val loss: 0.007089
Batch 376/906, loss: 0.003561  [12032/28983] (41.261s) val loss: 0.006470
Batch 451/906, loss: 0.003455  [14432/28983] (41.307s) val loss: 0.006360
Batch 526/906, loss: 0.003340  [16832/28983] (41.364s) val loss: 0.006448
Batch 601/906, loss: 0.003419  [19232/28983] (41.335s) val loss: 0.006573
Batch 676/906, loss: 0.006475  [21632/28983] (41.349s) val loss: 0.006248
Batch 751/906, loss: 0.009107  [24032/28983] (41.303s) val loss: 0.007369
Batch 826/906, loss: 0.006106  [26432/28983] (41.311s) val loss: 0.006457
Batch 901/906, loss: 0.008538  [28832/28983] (41.353s) val loss: 0.006656
Batch 906/906, loss: 0.007089  [28983/28983] (16.118s) val loss: 0.006487
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.585s total
-------------------------------

Epoch 50
-------------------------------
Batch  76/906, loss: 0.006483  [ 2432/28983] (27.275s) val loss: 0.006615
Batch 151/906, loss: 0.005457  [ 4832/28983] (41.233s) val loss: 0.006560
Batch 226/906, loss: 0.004247  [ 7232/28983] (41.359s) val loss: 0.006819
Batch 301/906, loss: 0.007573  [ 9632/28983] (41.276s) val loss: 0.006983
Batch 376/906, loss: 0.001637  [12032/28983] (41.233s) val loss: 0.006059
Batch 451/906, loss: 0.007526  [14432/28983] (41.306s) val loss: 0.006344
Batch 526/906, loss: 0.005551  [16832/28983] (41.298s) val loss: 0.006412
Batch 601/906, loss: 0.006388  [19232/28983] (41.325s) val loss: 0.006773
Batch 676/906, loss: 0.011097  [21632/28983] (41.334s) val loss: 0.006441
Batch 751/906, loss: 0.005235  [24032/28983] (41.320s) val loss: 0.006218
Batch 826/906, loss: 0.007048  [26432/28983] (41.358s) val loss: 0.006168
Batch 901/906, loss: 0.011209  [28832/28983] (41.303s) val loss: 0.006274
Batch 906/906, loss: 0.007070  [28983/28983] (16.124s) val loss: 0.006021
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.480s total
-------------------------------

Epoch 51
-------------------------------
Batch  76/906, loss: 0.007262  [ 2432/28983] (27.237s) val loss: 0.006338
Batch 151/906, loss: 0.002444  [ 4832/28983] (41.226s) val loss: 0.006730
Batch 226/906, loss: 0.003652  [ 7232/28983] (41.243s) val loss: 0.006705
Batch 301/906, loss: 0.004134  [ 9632/28983] (41.217s) val loss: 0.006005
Batch 376/906, loss: 0.005209  [12032/28983] (41.204s) val loss: 0.006288
Batch 451/906, loss: 0.002139  [14432/28983] (41.375s) val loss: 0.006291
Batch 526/906, loss: 0.005597  [16832/28983] (41.296s) val loss: 0.006043
Batch 601/906, loss: 0.003107  [19232/28983] (41.294s) val loss: 0.007551
Batch 676/906, loss: 0.001332  [21632/28983] (41.256s) val loss: 0.006787
Batch 751/906, loss: 0.004928  [24032/28983] (41.284s) val loss: 0.006547
Batch 826/906, loss: 0.003942  [26432/28983] (41.289s) val loss: 0.006874
Batch 901/906, loss: 0.007876  [28832/28983] (41.268s) val loss: 0.006310
Batch 906/906, loss: 0.010958  [28983/28983] (16.085s) val loss: 0.006420
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.918s total
-------------------------------

Epoch 52
-------------------------------
Batch  76/906, loss: 0.004662  [ 2432/28983] (27.282s) val loss: 0.006954
Batch 151/906, loss: 0.011371  [ 4832/28983] (41.219s) val loss: 0.006478
Batch 226/906, loss: 0.008896  [ 7232/28983] (41.296s) val loss: 0.006451
Batch 301/906, loss: 0.002304  [ 9632/28983] (41.263s) val loss: 0.006745
Batch 376/906, loss: 0.002632  [12032/28983] (41.223s) val loss: 0.007221
Batch 451/906, loss: 0.010827  [14432/28983] (41.269s) val loss: 0.006928
Batch 526/906, loss: 0.009943  [16832/28983] (41.251s) val loss: 0.007507
Batch 601/906, loss: 0.002622  [19232/28983] (41.355s) val loss: 0.006305
Batch 676/906, loss: 0.004680  [21632/28983] (41.303s) val loss: 0.006549
Batch 751/906, loss: 0.005611  [24032/28983] (41.240s) val loss: 0.007103
Batch 826/906, loss: 0.002241  [26432/28983] (41.301s) val loss: 0.006433
Batch 901/906, loss: 0.006378  [28832/28983] (41.265s) val loss: 0.006069
Batch 906/906, loss: 0.004592  [28983/28983] (16.101s) val loss: 0.005949
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.011s total
-------------------------------

Epoch 53
-------------------------------
Batch  76/906, loss: 0.007443  [ 2432/28983] (27.255s) val loss: 0.006445
Batch 151/906, loss: 0.007586  [ 4832/28983] (41.224s) val loss: 0.006515
Batch 226/906, loss: 0.010327  [ 7232/28983] (41.288s) val loss: 0.006449
Batch 301/906, loss: 0.007515  [ 9632/28983] (41.308s) val loss: 0.006457
Batch 376/906, loss: 0.004067  [12032/28983] (41.177s) val loss: 0.006267
Batch 451/906, loss: 0.011910  [14432/28983] (41.282s) val loss: 0.006076
Batch 526/906, loss: 0.004509  [16832/28983] (41.288s) val loss: 0.006823
Batch 601/906, loss: 0.007792  [19232/28983] (41.235s) val loss: 0.006167
Batch 676/906, loss: 0.007773  [21632/28983] (41.264s) val loss: 0.006658
Batch 751/906, loss: 0.005339  [24032/28983] (41.287s) val loss: 0.006717
Batch 826/906, loss: 0.002277  [26432/28983] (41.261s) val loss: 0.007843
Batch 901/906, loss: 0.002465  [28832/28983] (41.300s) val loss: 0.007724
Batch 906/906, loss: 0.001776  [28983/28983] (16.070s) val loss: 0.007036
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.884s total
-------------------------------

Epoch 54
-------------------------------
Batch  76/906, loss: 0.006003  [ 2432/28983] (27.223s) val loss: 0.006675
Batch 151/906, loss: 0.003189  [ 4832/28983] (41.202s) val loss: 0.006258
Batch 226/906, loss: 0.005784  [ 7232/28983] (41.249s) val loss: 0.006528
Batch 301/906, loss: 0.004880  [ 9632/28983] (41.289s) val loss: 0.006946
Batch 376/906, loss: 0.003327  [12032/28983] (41.215s) val loss: 0.006311
Batch 451/906, loss: 0.007299  [14432/28983] (41.274s) val loss: 0.006592
Batch 526/906, loss: 0.005588  [16832/28983] (41.291s) val loss: 0.006475
Batch 601/906, loss: 0.005846  [19232/28983] (41.280s) val loss: 0.006925
Batch 676/906, loss: 0.007102  [21632/28983] (41.293s) val loss: 0.007061
Batch 751/906, loss: 0.008131  [24032/28983] (41.281s) val loss: 0.006434
Batch 826/906, loss: 0.004674  [26432/28983] (41.297s) val loss: 0.006048
Batch 901/906, loss: 0.005605  [28832/28983] (41.276s) val loss: 0.006278
Batch 906/906, loss: 0.003203  [28983/28983] (16.208s) val loss: 0.006623
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.076s total
-------------------------------

Epoch 55
-------------------------------
Batch  76/906, loss: 0.003056  [ 2432/28983] (27.364s) val loss: 0.006511
Batch 151/906, loss: 0.005606  [ 4832/28983] (41.541s) val loss: 0.006281
Batch 226/906, loss: 0.003449  [ 7232/28983] (41.618s) val loss: 0.006659
Batch 301/906, loss: 0.004295  [ 9632/28983] (41.568s) val loss: 0.006220
Batch 376/906, loss: 0.005173  [12032/28983] (41.522s) val loss: 0.005998
Batch 451/906, loss: 0.007684  [14432/28983] (41.582s) val loss: 0.006696
Batch 526/906, loss: 0.009904  [16832/28983] (41.607s) val loss: 0.006831
Batch 601/906, loss: 0.004446  [19232/28983] (41.579s) val loss: 0.006847
Batch 676/906, loss: 0.002574  [21632/28983] (41.569s) val loss: 0.006133
Batch 751/906, loss: 0.003143  [24032/28983] (41.619s) val loss: 0.005960
Batch 826/906, loss: 0.005259  [26432/28983] (41.582s) val loss: 0.006046
Batch 901/906, loss: 0.004961  [28832/28983] (41.556s) val loss: 0.006792
Batch 906/906, loss: 0.006420  [28983/28983] (16.282s) val loss: 0.007269
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.852s total
-------------------------------

Epoch 56
-------------------------------
Batch  76/906, loss: 0.008833  [ 2432/28983] (27.387s) val loss: 0.006090
Batch 151/906, loss: 0.002673  [ 4832/28983] (41.515s) val loss: 0.006153
Batch 226/906, loss: 0.004963  [ 7232/28983] (41.676s) val loss: 0.007112
Batch 301/906, loss: 0.004643  [ 9632/28983] (41.594s) val loss: 0.006904
Batch 376/906, loss: 0.006572  [12032/28983] (41.509s) val loss: 0.006279
Batch 451/906, loss: 0.006702  [14432/28983] (41.591s) val loss: 0.006915
Batch 526/906, loss: 0.006258  [16832/28983] (41.638s) val loss: 0.005982
Batch 601/906, loss: 0.003391  [19232/28983] (41.598s) val loss: 0.006364
Batch 676/906, loss: 0.003733  [21632/28983] (41.618s) val loss: 0.005903
Batch 751/906, loss: 0.006121  [24032/28983] (41.323s) val loss: 0.006004
Batch 826/906, loss: 0.007397  [26432/28983] (41.289s) val loss: 0.006186
Batch 901/906, loss: 0.002640  [28832/28983] (41.264s) val loss: 0.006262
Batch 906/906, loss: 0.012231  [28983/28983] (16.094s) val loss: 0.006195
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.792s total
-------------------------------

Epoch 57
-------------------------------
Batch  76/906, loss: 0.012118  [ 2432/28983] (27.231s) val loss: 0.007245
Batch 151/906, loss: 0.016616  [ 4832/28983] (41.178s) val loss: 0.005727
Batch 226/906, loss: 0.005452  [ 7232/28983] (41.249s) val loss: 0.006119
Batch 301/906, loss: 0.019158  [ 9632/28983] (41.244s) val loss: 0.006167
Batch 376/906, loss: 0.003391  [12032/28983] (41.241s) val loss: 0.006060
Batch 451/906, loss: 0.005554  [14432/28983] (41.250s) val loss: 0.006808
Batch 526/906, loss: 0.002785  [16832/28983] (41.267s) val loss: 0.006941
Batch 601/906, loss: 0.003896  [19232/28983] (41.312s) val loss: 0.006096
Batch 676/906, loss: 0.003114  [21632/28983] (41.298s) val loss: 0.006418
Batch 751/906, loss: 0.005490  [24032/28983] (41.240s) val loss: 0.006029
Batch 826/906, loss: 0.005097  [26432/28983] (41.267s) val loss: 0.007287
Batch 901/906, loss: 0.005764  [28832/28983] (41.264s) val loss: 0.006580
Batch 906/906, loss: 0.003256  [28983/28983] (16.073s) val loss: 0.006101
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.738s total
-------------------------------

Epoch 58
-------------------------------
Batch  76/906, loss: 0.009247  [ 2432/28983] (27.252s) val loss: 0.006910
Batch 151/906, loss: 0.004011  [ 4832/28983] (41.149s) val loss: 0.006332
Batch 226/906, loss: 0.002402  [ 7232/28983] (41.297s) val loss: 0.006276
Batch 301/906, loss: 0.006367  [ 9632/28983] (41.294s) val loss: 0.006693
Batch 376/906, loss: 0.006100  [12032/28983] (41.182s) val loss: 0.006080
Batch 451/906, loss: 0.010504  [14432/28983] (41.257s) val loss: 0.006814
Batch 526/906, loss: 0.004108  [16832/28983] (41.241s) val loss: 0.006709
Batch 601/906, loss: 0.003616  [19232/28983] (41.298s) val loss: 0.006055
Batch 676/906, loss: 0.008797  [21632/28983] (41.237s) val loss: 0.006454
Batch 751/906, loss: 0.003954  [24032/28983] (41.290s) val loss: 0.006629
Batch 826/906, loss: 0.003602  [26432/28983] (41.229s) val loss: 0.006083
Batch 901/906, loss: 0.005279  [28832/28983] (41.225s) val loss: 0.006472
Batch 906/906, loss: 0.022608  [28983/28983] (16.063s) val loss: 0.006360
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.691s total
-------------------------------

Epoch 59
-------------------------------
Batch  76/906, loss: 0.014400  [ 2432/28983] (27.247s) val loss: 0.006510
Batch 151/906, loss: 0.002915  [ 4832/28983] (41.187s) val loss: 0.006276
Batch 226/906, loss: 0.007560  [ 7232/28983] (41.232s) val loss: 0.006112
Batch 301/906, loss: 0.006334  [ 9632/28983] (41.256s) val loss: 0.006417
Batch 376/906, loss: 0.006565  [12032/28983] (41.166s) val loss: 0.006192
Batch 451/906, loss: 0.005847  [14432/28983] (41.209s) val loss: 0.006192
Batch 526/906, loss: 0.005159  [16832/28983] (41.250s) val loss: 0.006168
Batch 601/906, loss: 0.006771  [19232/28983] (41.249s) val loss: 0.005880
Batch 676/906, loss: 0.003724  [21632/28983] (41.254s) val loss: 0.006881
Batch 751/906, loss: 0.003850  [24032/28983] (41.352s) val loss: 0.006209
Batch 826/906, loss: 0.003805  [26432/28983] (41.307s) val loss: 0.006170
Batch 901/906, loss: 0.004278  [28832/28983] (41.223s) val loss: 0.006000
Batch 906/906, loss: 0.006867  [28983/28983] (16.100s) val loss: 0.006037
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.673s total
-------------------------------

Epoch 60
-------------------------------
Batch  76/906, loss: 0.006132  [ 2432/28983] (27.242s) val loss: 0.006638
Batch 151/906, loss: 0.004450  [ 4832/28983] (41.192s) val loss: 0.005998
Batch 226/906, loss: 0.009998  [ 7232/28983] (41.258s) val loss: 0.006064
Batch 301/906, loss: 0.006837  [ 9632/28983] (41.219s) val loss: 0.006229
Batch 376/906, loss: 0.007502  [12032/28983] (41.177s) val loss: 0.007172
Batch 451/906, loss: 0.011085  [14432/28983] (41.265s) val loss: 0.006530
Batch 526/906, loss: 0.015290  [16832/28983] (41.264s) val loss: 0.007336
Batch 601/906, loss: 0.005361  [19232/28983] (41.214s) val loss: 0.007175
Batch 676/906, loss: 0.008029  [21632/28983] (41.225s) val loss: 0.006371
Batch 751/906, loss: 0.002126  [24032/28983] (41.237s) val loss: 0.006188
Batch 826/906, loss: 0.004745  [26432/28983] (41.277s) val loss: 0.005979
Batch 901/906, loss: 0.004751  [28832/28983] (41.242s) val loss: 0.006204
Batch 906/906, loss: 0.011501  [28983/28983] (16.070s) val loss: 0.006256
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.520s total
-------------------------------

Epoch 61
-------------------------------
Batch  76/906, loss: 0.006687  [ 2432/28983] (27.216s) val loss: 0.006159
Batch 151/906, loss: 0.005425  [ 4832/28983] (41.184s) val loss: 0.006239
Batch 226/906, loss: 0.005499  [ 7232/28983] (41.250s) val loss: 0.005816
Batch 301/906, loss: 0.003184  [ 9632/28983] (41.264s) val loss: 0.006092
Batch 376/906, loss: 0.006904  [12032/28983] (41.187s) val loss: 0.005958
Batch 451/906, loss: 0.004578  [14432/28983] (41.243s) val loss: 0.005943
Batch 526/906, loss: 0.001218  [16832/28983] (41.233s) val loss: 0.006697
Batch 601/906, loss: 0.011910  [19232/28983] (41.219s) val loss: 0.006297
Batch 676/906, loss: 0.005130  [21632/28983] (41.281s) val loss: 0.006175
Batch 751/906, loss: 0.009894  [24032/28983] (41.242s) val loss: 0.006717
Batch 826/906, loss: 0.005861  [26432/28983] (41.268s) val loss: 0.005903
Batch 901/906, loss: 0.003730  [28832/28983] (41.269s) val loss: 0.006527
Batch 906/906, loss: 0.001525  [28983/28983] (16.074s) val loss: 0.006233
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.621s total
-------------------------------

Epoch 62
-------------------------------
Batch  76/906, loss: 0.007209  [ 2432/28983] (27.255s) val loss: 0.006146
Batch 151/906, loss: 0.011834  [ 4832/28983] (41.160s) val loss: 0.006321
Batch 226/906, loss: 0.002226  [ 7232/28983] (41.291s) val loss: 0.006318
Batch 301/906, loss: 0.004962  [ 9632/28983] (41.265s) val loss: 0.006079
Batch 376/906, loss: 0.003340  [12032/28983] (41.183s) val loss: 0.005965
Batch 451/906, loss: 0.007093  [14432/28983] (41.286s) val loss: 0.006256
Batch 526/906, loss: 0.009230  [16832/28983] (41.289s) val loss: 0.005476
Batch 601/906, loss: 0.006620  [19232/28983] (41.228s) val loss: 0.006005
Batch 676/906, loss: 0.002581  [21632/28983] (41.241s) val loss: 0.005858
Batch 751/906, loss: 0.007171  [24032/28983] (41.272s) val loss: 0.006592
Batch 826/906, loss: 0.009554  [26432/28983] (41.222s) val loss: 0.006270
Batch 901/906, loss: 0.005129  [28832/28983] (41.236s) val loss: 0.006729
Batch 906/906, loss: 0.016675  [28983/28983] (16.073s) val loss: 0.006377
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.643s total
-------------------------------

Epoch 63
-------------------------------
Batch  76/906, loss: 0.003963  [ 2432/28983] (27.200s) val loss: 0.005995
Batch 151/906, loss: 0.008259  [ 4832/28983] (41.131s) val loss: 0.006002
Batch 226/906, loss: 0.004858  [ 7232/28983] (41.261s) val loss: 0.006167
Batch 301/906, loss: 0.005693  [ 9632/28983] (41.246s) val loss: 0.006568
Batch 376/906, loss: 0.001940  [12032/28983] (41.301s) val loss: 0.006220
Batch 451/906, loss: 0.004776  [14432/28983] (41.289s) val loss: 0.006135
Batch 526/906, loss: 0.003324  [16832/28983] (41.297s) val loss: 0.005946
Batch 601/906, loss: 0.002794  [19232/28983] (41.254s) val loss: 0.006099
Batch 676/906, loss: 0.003659  [21632/28983] (41.306s) val loss: 0.005944
Batch 751/906, loss: 0.004524  [24032/28983] (41.269s) val loss: 0.005761
Batch 826/906, loss: 0.004391  [26432/28983] (41.305s) val loss: 0.006398
Batch 901/906, loss: 0.005925  [28832/28983] (41.282s) val loss: 0.006721
Batch 906/906, loss: 0.005913  [28983/28983] (16.120s) val loss: 0.006684
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.909s total
-------------------------------

Epoch 64
-------------------------------
Batch  76/906, loss: 0.003274  [ 2432/28983] (27.233s) val loss: 0.005864
Batch 151/906, loss: 0.002604  [ 4832/28983] (41.218s) val loss: 0.006827
Batch 226/906, loss: 0.005615  [ 7232/28983] (41.300s) val loss: 0.006391
Batch 301/906, loss: 0.003000  [ 9632/28983] (41.325s) val loss: 0.006587
Batch 376/906, loss: 0.006560  [12032/28983] (41.203s) val loss: 0.006046
Batch 451/906, loss: 0.006624  [14432/28983] (41.293s) val loss: 0.006081
Batch 526/906, loss: 0.005816  [16832/28983] (41.276s) val loss: 0.006004
Batch 601/906, loss: 0.004027  [19232/28983] (41.318s) val loss: 0.006426
Batch 676/906, loss: 0.004687  [21632/28983] (41.293s) val loss: 0.006065
Batch 751/906, loss: 0.003603  [24032/28983] (41.321s) val loss: 0.005744
Batch 826/906, loss: 0.007225  [26432/28983] (41.287s) val loss: 0.006289
Batch 901/906, loss: 0.003915  [28832/28983] (41.289s) val loss: 0.006361
Batch 906/906, loss: 0.013209  [28983/28983] (16.113s) val loss: 0.006291
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.133s total
-------------------------------

Epoch 65
-------------------------------
Batch  76/906, loss: 0.002561  [ 2432/28983] (27.285s) val loss: 0.006198
Batch 151/906, loss: 0.002960  [ 4832/28983] (41.207s) val loss: 0.006287
Batch 226/906, loss: 0.003566  [ 7232/28983] (41.303s) val loss: 0.006046
Batch 301/906, loss: 0.004973  [ 9632/28983] (41.316s) val loss: 0.006368
Batch 376/906, loss: 0.006896  [12032/28983] (41.273s) val loss: 0.006456
Batch 451/906, loss: 0.003475  [14432/28983] (41.312s) val loss: 0.006053
Batch 526/906, loss: 0.005056  [16832/28983] (41.291s) val loss: 0.006198
Batch 601/906, loss: 0.003310  [19232/28983] (41.300s) val loss: 0.005827
Batch 676/906, loss: 0.004863  [21632/28983] (41.314s) val loss: 0.006163
Batch 751/906, loss: 0.006272  [24032/28983] (41.416s) val loss: 0.006164
Batch 826/906, loss: 0.011428  [26432/28983] (41.263s) val loss: 0.006030
Batch 901/906, loss: 0.006886  [28832/28983] (41.282s) val loss: 0.006171
Batch 906/906, loss: 0.003310  [28983/28983] (16.082s) val loss: 0.005981
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.488s total
-------------------------------

Epoch 66
-------------------------------
Batch  76/906, loss: 0.006294  [ 2432/28983] (27.454s) val loss: 0.006038
Batch 151/906, loss: 0.011085  [ 4832/28983] (41.512s) val loss: 0.006888
Batch 226/906, loss: 0.003536  [ 7232/28983] (41.210s) val loss: 0.005724
Batch 301/906, loss: 0.005224  [ 9632/28983] (41.242s) val loss: 0.006260
Batch 376/906, loss: 0.005316  [12032/28983] (41.158s) val loss: 0.006939
Batch 451/906, loss: 0.004678  [14432/28983] (41.278s) val loss: 0.005640
Batch 526/906, loss: 0.005683  [16832/28983] (41.200s) val loss: 0.006315
Batch 601/906, loss: 0.003424  [19232/28983] (41.233s) val loss: 0.005839
Batch 676/906, loss: 0.004985  [21632/28983] (41.206s) val loss: 0.005961
Batch 751/906, loss: 0.003874  [24032/28983] (41.200s) val loss: 0.006698
Batch 826/906, loss: 0.006815  [26432/28983] (41.208s) val loss: 0.005788
Batch 901/906, loss: 0.002143  [28832/28983] (41.186s) val loss: 0.005859
Batch 906/906, loss: 0.003600  [28983/28983] (16.160s) val loss: 0.005956
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.888s total
-------------------------------

Epoch 67
-------------------------------
Batch  76/906, loss: 0.008147  [ 2432/28983] (27.204s) val loss: 0.005973
Batch 151/906, loss: 0.009731  [ 4832/28983] (41.173s) val loss: 0.005917
Batch 226/906, loss: 0.004996  [ 7232/28983] (41.216s) val loss: 0.005877
Batch 301/906, loss: 0.003607  [ 9632/28983] (41.212s) val loss: 0.005776
Batch 376/906, loss: 0.004283  [12032/28983] (41.142s) val loss: 0.005843
Batch 451/906, loss: 0.003983  [14432/28983] (41.205s) val loss: 0.006146
Batch 526/906, loss: 0.004914  [16832/28983] (41.201s) val loss: 0.005942
Batch 601/906, loss: 0.003805  [19232/28983] (41.178s) val loss: 0.006468
Batch 676/906, loss: 0.004348  [21632/28983] (41.234s) val loss: 0.005798
Batch 751/906, loss: 0.010134  [24032/28983] (41.251s) val loss: 0.006578
Batch 826/906, loss: 0.002795  [26432/28983] (41.210s) val loss: 0.006534
Batch 901/906, loss: 0.004289  [28832/28983] (41.199s) val loss: 0.006579
Batch 906/906, loss: 0.002722  [28983/28983] (16.051s) val loss: 0.005852
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.126s total
-------------------------------

Epoch 68
-------------------------------
Batch  76/906, loss: 0.009082  [ 2432/28983] (27.203s) val loss: 0.006025
Batch 151/906, loss: 0.004481  [ 4832/28983] (41.124s) val loss: 0.006519
Batch 226/906, loss: 0.001066  [ 7232/28983] (41.209s) val loss: 0.006350
Batch 301/906, loss: 0.009589  [ 9632/28983] (41.193s) val loss: 0.006443
Batch 376/906, loss: 0.021469  [12032/28983] (41.110s) val loss: 0.006035
Batch 451/906, loss: 0.006446  [14432/28983] (41.225s) val loss: 0.006525
Batch 526/906, loss: 0.008670  [16832/28983] (41.231s) val loss: 0.006045
Batch 601/906, loss: 0.005122  [19232/28983] (41.188s) val loss: 0.006076
Batch 676/906, loss: 0.003682  [21632/28983] (41.207s) val loss: 0.006161
Batch 751/906, loss: 0.002981  [24032/28983] (41.213s) val loss: 0.006232
Batch 826/906, loss: 0.002871  [26432/28983] (41.246s) val loss: 0.006062
Batch 901/906, loss: 0.005039  [28832/28983] (41.194s) val loss: 0.005842
Batch 906/906, loss: 0.005464  [28983/28983] (16.065s) val loss: 0.006078
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.024s total
-------------------------------

Epoch 69
-------------------------------
Batch  76/906, loss: 0.012368  [ 2432/28983] (27.230s) val loss: 0.006820
Batch 151/906, loss: 0.004247  [ 4832/28983] (41.104s) val loss: 0.005701
Batch 226/906, loss: 0.007997  [ 7232/28983] (41.220s) val loss: 0.005861
Batch 301/906, loss: 0.003939  [ 9632/28983] (41.195s) val loss: 0.005871
Batch 376/906, loss: 0.008923  [12032/28983] (41.229s) val loss: 0.006313
Batch 451/906, loss: 0.006575  [14432/28983] (41.182s) val loss: 0.005888
Batch 526/906, loss: 0.006967  [16832/28983] (41.210s) val loss: 0.006003
Batch 601/906, loss: 0.005096  [19232/28983] (41.169s) val loss: 0.006099
Batch 676/906, loss: 0.005898  [21632/28983] (41.235s) val loss: 0.006249
Batch 751/906, loss: 0.002242  [24032/28983] (41.206s) val loss: 0.006202
Batch 826/906, loss: 0.003090  [26432/28983] (41.172s) val loss: 0.006018
Batch 901/906, loss: 0.015087  [28832/28983] (41.223s) val loss: 0.006399
Batch 906/906, loss: 0.006395  [28983/28983] (16.061s) val loss: 0.006312
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.071s total
-------------------------------

Epoch 70
-------------------------------
Batch  76/906, loss: 0.007827  [ 2432/28983] (27.193s) val loss: 0.006573
Batch 151/906, loss: 0.006908  [ 4832/28983] (41.138s) val loss: 0.006322
Batch 226/906, loss: 0.004283  [ 7232/28983] (41.198s) val loss: 0.005869
Batch 301/906, loss: 0.001986  [ 9632/28983] (41.410s) val loss: 0.006025
Batch 376/906, loss: 0.010907  [12032/28983] (41.557s) val loss: 0.006069
Batch 451/906, loss: 0.006795  [14432/28983] (41.578s) val loss: 0.005778
Batch 526/906, loss: 0.011214  [16832/28983] (41.541s) val loss: 0.005885
Batch 601/906, loss: 0.004062  [19232/28983] (41.602s) val loss: 0.005834
Batch 676/906, loss: 0.006552  [21632/28983] (41.551s) val loss: 0.005813
Batch 751/906, loss: 0.003166  [24032/28983] (41.530s) val loss: 0.006554
Batch 826/906, loss: 0.003487  [26432/28983] (41.541s) val loss: 0.006310
Batch 901/906, loss: 0.005684  [28832/28983] (41.585s) val loss: 0.005628
Batch 906/906, loss: 0.003199  [28983/28983] (16.234s) val loss: 0.005854
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.476s total
-------------------------------

Epoch 71
-------------------------------
Batch  76/906, loss: 0.011748  [ 2432/28983] (27.383s) val loss: 0.005740
Batch 151/906, loss: 0.006584  [ 4832/28983] (41.449s) val loss: 0.005877
Batch 226/906, loss: 0.003509  [ 7232/28983] (41.555s) val loss: 0.005958
Batch 301/906, loss: 0.004851  [ 9632/28983] (41.546s) val loss: 0.006167
Batch 376/906, loss: 0.004571  [12032/28983] (41.508s) val loss: 0.005702
Batch 451/906, loss: 0.007206  [14432/28983] (41.573s) val loss: 0.006331
Batch 526/906, loss: 0.003109  [16832/28983] (41.569s) val loss: 0.005839
Batch 601/906, loss: 0.004812  [19232/28983] (41.511s) val loss: 0.005865
Batch 676/906, loss: 0.004581  [21632/28983] (41.552s) val loss: 0.005823
Batch 751/906, loss: 0.006144  [24032/28983] (41.572s) val loss: 0.005606
Batch 826/906, loss: 0.003499  [26432/28983] (41.518s) val loss: 0.006128
Batch 901/906, loss: 0.006245  [28832/28983] (41.580s) val loss: 0.005737
Batch 906/906, loss: 0.002457  [28983/28983] (16.252s) val loss: 0.005947
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.380s total
-------------------------------

Epoch 72
-------------------------------
Batch  76/906, loss: 0.006327  [ 2432/28983] (27.361s) val loss: 0.006181
Batch 151/906, loss: 0.009787  [ 4832/28983] (41.462s) val loss: 0.006874
Batch 226/906, loss: 0.001850  [ 7232/28983] (41.526s) val loss: 0.006319
Batch 301/906, loss: 0.009042  [ 9632/28983] (41.536s) val loss: 0.006176
Batch 376/906, loss: 0.002462  [12032/28983] (41.481s) val loss: 0.006357
Batch 451/906, loss: 0.004411  [14432/28983] (41.516s) val loss: 0.006272
Batch 526/906, loss: 0.006271  [16832/28983] (41.551s) val loss: 0.006039
Batch 601/906, loss: 0.006649  [19232/28983] (41.566s) val loss: 0.005886
Batch 676/906, loss: 0.006124  [21632/28983] (41.572s) val loss: 0.005446
Batch 751/906, loss: 0.005634  [24032/28983] (41.519s) val loss: 0.005627
Batch 826/906, loss: 0.003493  [26432/28983] (41.549s) val loss: 0.005768
Batch 901/906, loss: 0.005873  [28832/28983] (41.519s) val loss: 0.005810
Batch 906/906, loss: 0.002480  [28983/28983] (16.270s) val loss: 0.005826
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.243s total
-------------------------------

Epoch 73
-------------------------------
Batch  76/906, loss: 0.006330  [ 2432/28983] (27.349s) val loss: 0.005743
Batch 151/906, loss: 0.008067  [ 4832/28983] (41.458s) val loss: 0.005994
Batch 226/906, loss: 0.006790  [ 7232/28983] (41.531s) val loss: 0.005858
Batch 301/906, loss: 0.002110  [ 9632/28983] (41.554s) val loss: 0.005983
Batch 376/906, loss: 0.010936  [12032/28983] (41.513s) val loss: 0.005576
Batch 451/906, loss: 0.004930  [14432/28983] (41.578s) val loss: 0.006565
Batch 526/906, loss: 0.002920  [16832/28983] (41.556s) val loss: 0.006391
Batch 601/906, loss: 0.003033  [19232/28983] (41.589s) val loss: 0.006116
Batch 676/906, loss: 0.008516  [21632/28983] (41.494s) val loss: 0.005868
Batch 751/906, loss: 0.002148  [24032/28983] (41.567s) val loss: 0.005981
Batch 826/906, loss: 0.008467  [26432/28983] (41.530s) val loss: 0.006103
Batch 901/906, loss: 0.004555  [28832/28983] (41.534s) val loss: 0.005746
Batch 906/906, loss: 0.002923  [28983/28983] (16.243s) val loss: 0.005801
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.293s total
-------------------------------

Epoch 74
-------------------------------
Batch  76/906, loss: 0.004362  [ 2432/28983] (27.362s) val loss: 0.006115
Batch 151/906, loss: 0.006595  [ 4832/28983] (41.462s) val loss: 0.005405
Batch 226/906, loss: 0.005757  [ 7232/28983] (41.653s) val loss: 0.006172
Batch 301/906, loss: 0.004734  [ 9632/28983] (41.459s) val loss: 0.005972
Batch 376/906, loss: 0.006208  [12032/28983] (41.290s) val loss: 0.006104
Batch 451/906, loss: 0.004578  [14432/28983] (41.359s) val loss: 0.006067
Batch 526/906, loss: 0.003907  [16832/28983] (41.343s) val loss: 0.005961
Batch 601/906, loss: 0.005061  [19232/28983] (41.375s) val loss: 0.006163
Batch 676/906, loss: 0.003678  [21632/28983] (41.525s) val loss: 0.006055
Batch 751/906, loss: 0.002218  [24032/28983] (41.491s) val loss: 0.005698
Batch 826/906, loss: 0.006437  [26432/28983] (41.541s) val loss: 0.005830
Batch 901/906, loss: 0.004559  [28832/28983] (41.545s) val loss: 0.005848
Batch 906/906, loss: 0.003131  [28983/28983] (16.227s) val loss: 0.006094
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.435s total
-------------------------------

Epoch 75
-------------------------------
Batch  76/906, loss: 0.003401  [ 2432/28983] (27.330s) val loss: 0.005995
Batch 151/906, loss: 0.001426  [ 4832/28983] (41.410s) val loss: 0.005838
Batch 226/906, loss: 0.005573  [ 7232/28983] (41.519s) val loss: 0.006085
Batch 301/906, loss: 0.002835  [ 9632/28983] (41.476s) val loss: 0.005833
Batch 376/906, loss: 0.004790  [12032/28983] (41.452s) val loss: 0.006518
Batch 451/906, loss: 0.001259  [14432/28983] (41.537s) val loss: 0.005805
Batch 526/906, loss: 0.002990  [16832/28983] (41.521s) val loss: 0.006138
Batch 601/906, loss: 0.006645  [19232/28983] (41.552s) val loss: 0.006191
Batch 676/906, loss: 0.004330  [21632/28983] (41.501s) val loss: 0.005575
Batch 751/906, loss: 0.009958  [24032/28983] (41.533s) val loss: 0.005578
Batch 826/906, loss: 0.002846  [26432/28983] (41.538s) val loss: 0.005665
Batch 901/906, loss: 0.004336  [28832/28983] (41.518s) val loss: 0.006240
Batch 906/906, loss: 0.003029  [28983/28983] (16.240s) val loss: 0.006296
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.921s total
-------------------------------

Epoch 76
-------------------------------
Batch  76/906, loss: 0.005373  [ 2432/28983] (27.340s) val loss: 0.005976
Batch 151/906, loss: 0.001929  [ 4832/28983] (41.229s) val loss: 0.006380
Batch 226/906, loss: 0.003428  [ 7232/28983] (41.357s) val loss: 0.006616
Batch 301/906, loss: 0.005693  [ 9632/28983] (41.343s) val loss: 0.006006
Batch 376/906, loss: 0.007018  [12032/28983] (41.264s) val loss: 0.007115
Batch 451/906, loss: 0.003320  [14432/28983] (41.359s) val loss: 0.006648
Batch 526/906, loss: 0.006418  [16832/28983] (41.326s) val loss: 0.005689
Batch 601/906, loss: 0.006890  [19232/28983] (41.341s) val loss: 0.006276
Batch 676/906, loss: 0.009221  [21632/28983] (41.342s) val loss: 0.005768
Batch 751/906, loss: 0.004674  [24032/28983] (41.344s) val loss: 0.006557
Batch 826/906, loss: 0.005533  [26432/28983] (41.359s) val loss: 0.006289
Batch 901/906, loss: 0.003238  [28832/28983] (41.340s) val loss: 0.006168
Batch 906/906, loss: 0.023757  [28983/28983] (16.144s) val loss: 0.006698
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.755s total
-------------------------------

Epoch 77
-------------------------------
Batch  76/906, loss: 0.003507  [ 2432/28983] (27.297s) val loss: 0.006516
Batch 151/906, loss: 0.004496  [ 4832/28983] (41.299s) val loss: 0.005828
Batch 226/906, loss: 0.012283  [ 7232/28983] (41.335s) val loss: 0.005674
Batch 301/906, loss: 0.008033  [ 9632/28983] (41.333s) val loss: 0.005697
Batch 376/906, loss: 0.005956  [12032/28983] (41.229s) val loss: 0.007543
Batch 451/906, loss: 0.011187  [14432/28983] (41.322s) val loss: 0.006411
Batch 526/906, loss: 0.003983  [16832/28983] (41.355s) val loss: 0.006285
Batch 601/906, loss: 0.007412  [19232/28983] (41.339s) val loss: 0.006048
Batch 676/906, loss: 0.006060  [21632/28983] (41.344s) val loss: 0.007281
Batch 751/906, loss: 0.003882  [24032/28983] (41.447s) val loss: 0.005818
Batch 826/906, loss: 0.004414  [26432/28983] (41.336s) val loss: 0.005474
Batch 901/906, loss: 0.007138  [28832/28983] (41.339s) val loss: 0.005886
Batch 906/906, loss: 0.003926  [28983/28983] (16.137s) val loss: 0.006033
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.767s total
-------------------------------

Epoch 78
-------------------------------
Batch  76/906, loss: 0.004096  [ 2432/28983] (27.262s) val loss: 0.006012
Batch 151/906, loss: 0.007081  [ 4832/28983] (41.274s) val loss: 0.005494
Batch 226/906, loss: 0.005102  [ 7232/28983] (41.339s) val loss: 0.005641
Batch 301/906, loss: 0.006046  [ 9632/28983] (41.306s) val loss: 0.005766
Batch 376/906, loss: 0.005624  [12032/28983] (41.241s) val loss: 0.005404
Batch 451/906, loss: 0.005283  [14432/28983] (41.364s) val loss: 0.006268
Batch 526/906, loss: 0.002206  [16832/28983] (41.355s) val loss: 0.005584
Batch 601/906, loss: 0.005009  [19232/28983] (41.304s) val loss: 0.005551
Batch 676/906, loss: 0.005757  [21632/28983] (41.296s) val loss: 0.005816
Batch 751/906, loss: 0.006934  [24032/28983] (41.402s) val loss: 0.006149
Batch 826/906, loss: 0.005740  [26432/28983] (41.313s) val loss: 0.006059
Batch 901/906, loss: 0.002329  [28832/28983] (41.353s) val loss: 0.005901
Batch 906/906, loss: 0.004251  [28983/28983] (16.181s) val loss: 0.005983
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.654s total
-------------------------------

Epoch 79
-------------------------------
Batch  76/906, loss: 0.008541  [ 2432/28983] (27.280s) val loss: 0.006158
Batch 151/906, loss: 0.006598  [ 4832/28983] (41.291s) val loss: 0.006022
Batch 226/906, loss: 0.003437  [ 7232/28983] (41.325s) val loss: 0.006323
Batch 301/906, loss: 0.001805  [ 9632/28983] (41.312s) val loss: 0.005815
Batch 376/906, loss: 0.004922  [12032/28983] (41.255s) val loss: 0.007017
Batch 451/906, loss: 0.004233  [14432/28983] (41.306s) val loss: 0.005907
Batch 526/906, loss: 0.003830  [16832/28983] (41.322s) val loss: 0.006174
Batch 601/906, loss: 0.011520  [19232/28983] (41.347s) val loss: 0.006624
Batch 676/906, loss: 0.003534  [21632/28983] (41.329s) val loss: 0.005923
Batch 751/906, loss: 0.005038  [24032/28983] (41.323s) val loss: 0.005478
Batch 826/906, loss: 0.004380  [26432/28983] (41.352s) val loss: 0.005826
Batch 901/906, loss: 0.004778  [28832/28983] (41.353s) val loss: 0.005846
Batch 906/906, loss: 0.004513  [28983/28983] (16.115s) val loss: 0.005880
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.590s total
-------------------------------

Epoch 80
-------------------------------
Batch  76/906, loss: 0.003046  [ 2432/28983] (27.300s) val loss: 0.006457
Batch 151/906, loss: 0.004027  [ 4832/28983] (41.268s) val loss: 0.006079
Batch 226/906, loss: 0.001444  [ 7232/28983] (41.342s) val loss: 0.005771
Batch 301/906, loss: 0.003279  [ 9632/28983] (41.359s) val loss: 0.005443
Batch 376/906, loss: 0.004894  [12032/28983] (41.250s) val loss: 0.006100
Batch 451/906, loss: 0.004113  [14432/28983] (41.346s) val loss: 0.006677
Batch 526/906, loss: 0.005831  [16832/28983] (41.298s) val loss: 0.005908
Batch 601/906, loss: 0.003199  [19232/28983] (41.357s) val loss: 0.005686
Batch 676/906, loss: 0.004905  [21632/28983] (41.329s) val loss: 0.005807
Batch 751/906, loss: 0.008284  [24032/28983] (41.313s) val loss: 0.005754
Batch 826/906, loss: 0.009840  [26432/28983] (41.320s) val loss: 0.005721
Batch 901/906, loss: 0.003876  [28832/28983] (41.331s) val loss: 0.006059
Batch 906/906, loss: 0.005161  [28983/28983] (16.107s) val loss: 0.006004
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.621s total
-------------------------------

Epoch 81
-------------------------------
Batch  76/906, loss: 0.002615  [ 2432/28983] (27.292s) val loss: 0.005720
Batch 151/906, loss: 0.003502  [ 4832/28983] (41.243s) val loss: 0.005627
Batch 226/906, loss: 0.007465  [ 7232/28983] (41.376s) val loss: 0.006208
Batch 301/906, loss: 0.007325  [ 9632/28983] (41.374s) val loss: 0.005952
Batch 376/906, loss: 0.010730  [12032/28983] (41.297s) val loss: 0.005701
Batch 451/906, loss: 0.006252  [14432/28983] (41.285s) val loss: 0.006082
Batch 526/906, loss: 0.003702  [16832/28983] (41.267s) val loss: 0.005688
Batch 601/906, loss: 0.007064  [19232/28983] (41.260s) val loss: 0.006331
Batch 676/906, loss: 0.006616  [21632/28983] (41.280s) val loss: 0.005947
Batch 751/906, loss: 0.003112  [24032/28983] (41.256s) val loss: 0.005719
Batch 826/906, loss: 0.003891  [26432/28983] (41.270s) val loss: 0.006175
Batch 901/906, loss: 0.011342  [28832/28983] (41.280s) val loss: 0.005723
Batch 906/906, loss: 0.008587  [28983/28983] (16.084s) val loss: 0.006263
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.209s total
-------------------------------

Epoch 82
-------------------------------
Batch  76/906, loss: 0.009722  [ 2432/28983] (27.254s) val loss: 0.006525
Batch 151/906, loss: 0.007182  [ 4832/28983] (41.226s) val loss: 0.006536
Batch 226/906, loss: 0.003439  [ 7232/28983] (41.265s) val loss: 0.006200
Batch 301/906, loss: 0.003836  [ 9632/28983] (41.250s) val loss: 0.006352
Batch 376/906, loss: 0.005436  [12032/28983] (41.248s) val loss: 0.005312
Batch 451/906, loss: 0.006913  [14432/28983] (41.327s) val loss: 0.005993
Batch 526/906, loss: 0.004582  [16832/28983] (41.358s) val loss: 0.006164
Batch 601/906, loss: 0.002498  [19232/28983] (41.321s) val loss: 0.006267
Batch 676/906, loss: 0.005580  [21632/28983] (41.278s) val loss: 0.005744
Batch 751/906, loss: 0.006356  [24032/28983] (41.286s) val loss: 0.005550
Batch 826/906, loss: 0.005378  [26432/28983] (41.284s) val loss: 0.005612
Batch 901/906, loss: 0.004956  [28832/28983] (41.285s) val loss: 0.006046
Batch 906/906, loss: 0.004348  [28983/28983] (16.075s) val loss: 0.005981
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.088s total
-------------------------------

Epoch 83
-------------------------------
Batch  76/906, loss: 0.010628  [ 2432/28983] (27.275s) val loss: 0.006092
Batch 151/906, loss: 0.004051  [ 4832/28983] (41.243s) val loss: 0.005995
Batch 226/906, loss: 0.002329  [ 7232/28983] (41.268s) val loss: 0.005490
Batch 301/906, loss: 0.001481  [ 9632/28983] (41.280s) val loss: 0.005492
Batch 376/906, loss: 0.004549  [12032/28983] (41.203s) val loss: 0.005847
Batch 451/906, loss: 0.004205  [14432/28983] (41.242s) val loss: 0.006041
Batch 526/906, loss: 0.004902  [16832/28983] (41.299s) val loss: 0.005774
Batch 601/906, loss: 0.004345  [19232/28983] (41.301s) val loss: 0.005887
Batch 676/906, loss: 0.004191  [21632/28983] (41.287s) val loss: 0.006090
Batch 751/906, loss: 0.005440  [24032/28983] (41.270s) val loss: 0.006283
Batch 826/906, loss: 0.000880  [26432/28983] (41.254s) val loss: 0.005698
Batch 901/906, loss: 0.004592  [28832/28983] (41.297s) val loss: 0.005429
Batch 906/906, loss: 0.002618  [28983/28983] (16.065s) val loss: 0.005601
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.923s total
-------------------------------

Epoch 84
-------------------------------
Batch  76/906, loss: 0.007765  [ 2432/28983] (27.275s) val loss: 0.006158
Batch 151/906, loss: 0.004119  [ 4832/28983] (41.214s) val loss: 0.005811
Batch 226/906, loss: 0.007374  [ 7232/28983] (41.290s) val loss: 0.005714
Batch 301/906, loss: 0.009459  [ 9632/28983] (41.483s) val loss: 0.005939
Batch 376/906, loss: 0.003014  [12032/28983] (41.454s) val loss: 0.005782
Batch 451/906, loss: 0.001084  [14432/28983] (41.484s) val loss: 0.005814
Batch 526/906, loss: 0.005078  [16832/28983] (41.488s) val loss: 0.005771
Batch 601/906, loss: 0.003735  [19232/28983] (41.521s) val loss: 0.005995
Batch 676/906, loss: 0.002711  [21632/28983] (41.552s) val loss: 0.005602
Batch 751/906, loss: 0.003681  [24032/28983] (41.528s) val loss: 0.005548
Batch 826/906, loss: 0.004891  [26432/28983] (41.505s) val loss: 0.005640
Batch 901/906, loss: 0.012911  [28832/28983] (41.535s) val loss: 0.006241
Batch 906/906, loss: 0.002891  [28983/28983] (16.300s) val loss: 0.006411
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.431s total
-------------------------------

Epoch 85
-------------------------------
Batch  76/906, loss: 0.008847  [ 2432/28983] (27.324s) val loss: 0.005785
Batch 151/906, loss: 0.003724  [ 4832/28983] (41.473s) val loss: 0.005780
Batch 226/906, loss: 0.003354  [ 7232/28983] (41.523s) val loss: 0.005451
Batch 301/906, loss: 0.006242  [ 9632/28983] (41.535s) val loss: 0.006132
Batch 376/906, loss: 0.009814  [12032/28983] (41.441s) val loss: 0.006390
Batch 451/906, loss: 0.005922  [14432/28983] (41.519s) val loss: 0.005974
Batch 526/906, loss: 0.007617  [16832/28983] (41.516s) val loss: 0.005434
Batch 601/906, loss: 0.001838  [19232/28983] (41.263s) val loss: 0.005674
Batch 676/906, loss: 0.004768  [21632/28983] (41.263s) val loss: 0.005354
Batch 751/906, loss: 0.002772  [24032/28983] (41.247s) val loss: 0.005917
Batch 826/906, loss: 0.005259  [26432/28983] (41.268s) val loss: 0.005711
Batch 901/906, loss: 0.001227  [28832/28983] (41.273s) val loss: 0.006710
Batch 906/906, loss: 0.003836  [28983/28983] (16.110s) val loss: 0.006638
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.445s total
-------------------------------

Epoch 86
-------------------------------
Batch  76/906, loss: 0.005549  [ 2432/28983] (27.200s) val loss: 0.006229
Batch 151/906, loss: 0.004155  [ 4832/28983] (41.170s) val loss: 0.005917
Batch 226/906, loss: 0.001602  [ 7232/28983] (41.334s) val loss: 0.005681
Batch 301/906, loss: 0.005502  [ 9632/28983] (41.256s) val loss: 0.006801
Batch 376/906, loss: 0.005545  [12032/28983] (41.190s) val loss: 0.006176
Batch 451/906, loss: 0.005936  [14432/28983] (41.280s) val loss: 0.009165
Batch 526/906, loss: 0.007444  [16832/28983] (41.234s) val loss: 0.006181
Batch 601/906, loss: 0.002588  [19232/28983] (41.245s) val loss: 0.005980
Batch 676/906, loss: 0.004500  [21632/28983] (41.255s) val loss: 0.005858
Batch 751/906, loss: 0.005960  [24032/28983] (41.236s) val loss: 0.005663
Batch 826/906, loss: 0.004008  [26432/28983] (41.249s) val loss: 0.005939
Batch 901/906, loss: 0.004468  [28832/28983] (41.255s) val loss: 0.005421
Batch 906/906, loss: 0.007750  [28983/28983] (16.113s) val loss: 0.005679
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.672s total
-------------------------------

Epoch 87
-------------------------------
Batch  76/906, loss: 0.001706  [ 2432/28983] (27.213s) val loss: 0.005939
Batch 151/906, loss: 0.001447  [ 4832/28983] (41.148s) val loss: 0.005916
Batch 226/906, loss: 0.003448  [ 7232/28983] (41.260s) val loss: 0.006240
Batch 301/906, loss: 0.002080  [ 9632/28983] (41.251s) val loss: 0.005445
Batch 376/906, loss: 0.002391  [12032/28983] (41.164s) val loss: 0.006119
Batch 451/906, loss: 0.004903  [14432/28983] (41.233s) val loss: 0.005888
Batch 526/906, loss: 0.005513  [16832/28983] (41.229s) val loss: 0.005888
Batch 601/906, loss: 0.011039  [19232/28983] (41.246s) val loss: 0.005911
Batch 676/906, loss: 0.004398  [21632/28983] (41.236s) val loss: 0.005808
Batch 751/906, loss: 0.001997  [24032/28983] (41.211s) val loss: 0.005678
Batch 826/906, loss: 0.006388  [26432/28983] (41.220s) val loss: 0.005892
Batch 901/906, loss: 0.003761  [28832/28983] (41.278s) val loss: 0.005837
Batch 906/906, loss: 0.007134  [28983/28983] (16.113s) val loss: 0.005788
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.476s total
-------------------------------

Epoch 88
-------------------------------
Batch  76/906, loss: 0.013077  [ 2432/28983] (27.200s) val loss: 0.006344
Batch 151/906, loss: 0.005388  [ 4832/28983] (41.152s) val loss: 0.006227
Batch 226/906, loss: 0.005025  [ 7232/28983] (41.253s) val loss: 0.005858
Batch 301/906, loss: 0.003034  [ 9632/28983] (41.229s) val loss: 0.005797
Batch 376/906, loss: 0.003094  [12032/28983] (41.160s) val loss: 0.006013
Batch 451/906, loss: 0.003988  [14432/28983] (41.240s) val loss: 0.005848
Batch 526/906, loss: 0.003237  [16832/28983] (41.276s) val loss: 0.005734
Batch 601/906, loss: 0.000617  [19232/28983] (41.325s) val loss: 0.005544
Batch 676/906, loss: 0.015952  [21632/28983] (41.260s) val loss: 0.005537
Batch 751/906, loss: 0.005608  [24032/28983] (41.284s) val loss: 0.005397
Batch 826/906, loss: 0.004960  [26432/28983] (41.280s) val loss: 0.005796
Batch 901/906, loss: 0.003700  [28832/28983] (41.228s) val loss: 0.007765
Batch 906/906, loss: 0.001490  [28983/28983] (16.079s) val loss: 0.008018
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.651s total
-------------------------------

Epoch 89
-------------------------------
Batch  76/906, loss: 0.006936  [ 2432/28983] (27.224s) val loss: 0.005679
Batch 151/906, loss: 0.004382  [ 4832/28983] (41.162s) val loss: 0.005693
Batch 226/906, loss: 0.005201  [ 7232/28983] (41.242s) val loss: 0.006414
Batch 301/906, loss: 0.001749  [ 9632/28983] (41.242s) val loss: 0.006103
Batch 376/906, loss: 0.005983  [12032/28983] (41.201s) val loss: 0.005974
Batch 451/906, loss: 0.008859  [14432/28983] (41.271s) val loss: 0.006524
Batch 526/906, loss: 0.008788  [16832/28983] (41.224s) val loss: 0.006011
Batch 601/906, loss: 0.011890  [19232/28983] (41.245s) val loss: 0.005863
Batch 676/906, loss: 0.004607  [21632/28983] (41.264s) val loss: 0.006126
Batch 751/906, loss: 0.002500  [24032/28983] (41.341s) val loss: 0.005576
Batch 826/906, loss: 0.004250  [26432/28983] (41.294s) val loss: 0.005487
Batch 901/906, loss: 0.001725  [28832/28983] (41.264s) val loss: 0.005589
Batch 906/906, loss: 0.005981  [28983/28983] (16.104s) val loss: 0.005623
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.733s total
-------------------------------

Epoch 90
-------------------------------
Batch  76/906, loss: 0.003393  [ 2432/28983] (27.202s) val loss: 0.005731
Batch 151/906, loss: 0.008044  [ 4832/28983] (41.189s) val loss: 0.005579
Batch 226/906, loss: 0.002726  [ 7232/28983] (41.261s) val loss: 0.005784
Batch 301/906, loss: 0.003252  [ 9632/28983] (41.228s) val loss: 0.005771
Batch 376/906, loss: 0.002753  [12032/28983] (41.201s) val loss: 0.006344
Batch 451/906, loss: 0.002781  [14432/28983] (41.299s) val loss: 0.006111
Batch 526/906, loss: 0.009002  [16832/28983] (41.274s) val loss: 0.005550
Batch 601/906, loss: 0.002031  [19232/28983] (41.265s) val loss: 0.005653
Batch 676/906, loss: 0.002960  [21632/28983] (41.272s) val loss: 0.006031
Batch 751/906, loss: 0.005550  [24032/28983] (41.235s) val loss: 0.006022
Batch 826/906, loss: 0.005157  [26432/28983] (41.262s) val loss: 0.005873
Batch 901/906, loss: 0.004425  [28832/28983] (41.263s) val loss: 0.005645
Batch 906/906, loss: 0.002585  [28983/28983] (16.119s) val loss: 0.005466
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.853s total
-------------------------------

Epoch 91
-------------------------------
Batch  76/906, loss: 0.004958  [ 2432/28983] (27.220s) val loss: 0.006669
Batch 151/906, loss: 0.003985  [ 4832/28983] (41.215s) val loss: 0.006288
Batch 226/906, loss: 0.005271  [ 7232/28983] (41.262s) val loss: 0.006013
Batch 301/906, loss: 0.003185  [ 9632/28983] (41.219s) val loss: 0.006188
Batch 376/906, loss: 0.004435  [12032/28983] (41.179s) val loss: 0.005667
Batch 451/906, loss: 0.006522  [14432/28983] (41.268s) val loss: 0.006615
Batch 526/906, loss: 0.004053  [16832/28983] (41.536s) val loss: 0.005842
Batch 601/906, loss: 0.001749  [19232/28983] (41.584s) val loss: 0.005585
Batch 676/906, loss: 0.004150  [21632/28983] (41.603s) val loss: 0.005649
Batch 751/906, loss: 0.004392  [24032/28983] (41.553s) val loss: 0.006119
Batch 826/906, loss: 0.004355  [26432/28983] (41.558s) val loss: 0.005643
Batch 901/906, loss: 0.008903  [28832/28983] (41.592s) val loss: 0.005641
Batch 906/906, loss: 0.006410  [28983/28983] (16.294s) val loss: 0.005523
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.892s total
-------------------------------

Epoch 92
-------------------------------
Batch  76/906, loss: 0.009010  [ 2432/28983] (27.387s) val loss: 0.005821
Batch 151/906, loss: 0.002979  [ 4832/28983] (41.506s) val loss: 0.005880
Batch 226/906, loss: 0.003861  [ 7232/28983] (41.662s) val loss: 0.005409
Batch 301/906, loss: 0.005880  [ 9632/28983] (41.590s) val loss: 0.006251
Batch 376/906, loss: 0.006679  [12032/28983] (41.357s) val loss: 0.005638
Batch 451/906, loss: 0.001960  [14432/28983] (41.265s) val loss: 0.005387
Batch 526/906, loss: 0.006664  [16832/28983] (41.297s) val loss: 0.005733
Batch 601/906, loss: 0.007002  [19232/28983] (41.250s) val loss: 0.005663
Batch 676/906, loss: 0.007174  [21632/28983] (41.307s) val loss: 0.005492
Batch 751/906, loss: 0.003169  [24032/28983] (41.299s) val loss: 0.005901
Batch 826/906, loss: 0.005069  [26432/28983] (41.283s) val loss: 0.005602
Batch 901/906, loss: 0.003825  [28832/28983] (41.249s) val loss: 0.006445
Batch 906/906, loss: 0.003048  [28983/28983] (16.108s) val loss: 0.005883
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 513.226s total
-------------------------------

Epoch 93
-------------------------------
Batch  76/906, loss: 0.002543  [ 2432/28983] (27.232s) val loss: 0.005820
Batch 151/906, loss: 0.002743  [ 4832/28983] (41.238s) val loss: 0.005666
Batch 226/906, loss: 0.002431  [ 7232/28983] (41.259s) val loss: 0.006160
Batch 301/906, loss: 0.006948  [ 9632/28983] (41.261s) val loss: 0.006359
Batch 376/906, loss: 0.007398  [12032/28983] (41.326s) val loss: 0.005935
Batch 451/906, loss: 0.006764  [14432/28983] (41.293s) val loss: 0.005501
Batch 526/906, loss: 0.003015  [16832/28983] (41.305s) val loss: 0.006048
Batch 601/906, loss: 0.001793  [19232/28983] (41.304s) val loss: 0.006105
Batch 676/906, loss: 0.001722  [21632/28983] (41.257s) val loss: 0.006210
Batch 751/906, loss: 0.006159  [24032/28983] (41.291s) val loss: 0.005996
Batch 826/906, loss: 0.004849  [26432/28983] (41.246s) val loss: 0.005878
Batch 901/906, loss: 0.004308  [28832/28983] (41.262s) val loss: 0.006017
Batch 906/906, loss: 0.001695  [28983/28983] (16.081s) val loss: 0.005932
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 512.029s total
-------------------------------

Epoch 94
-------------------------------
Batch  76/906, loss: 0.002947  [ 2432/28983] (27.223s) val loss: 0.006660
Batch 151/906, loss: 0.005287  [ 4832/28983] (41.152s) val loss: 0.005681
Batch 226/906, loss: 0.002610  [ 7232/28983] (41.270s) val loss: 0.006287
Batch 301/906, loss: 0.002924  [ 9632/28983] (41.221s) val loss: 0.005786
Batch 376/906, loss: 0.004820  [12032/28983] (41.142s) val loss: 0.006287
Batch 451/906, loss: 0.006688  [14432/28983] (41.232s) val loss: 0.005735
Batch 526/906, loss: 0.005293  [16832/28983] (41.253s) val loss: 0.005701
Batch 601/906, loss: 0.004463  [19232/28983] (41.282s) val loss: 0.005874
Batch 676/906, loss: 0.006524  [21632/28983] (41.229s) val loss: 0.005566
Batch 751/906, loss: 0.006722  [24032/28983] (41.230s) val loss: 0.006087
Batch 826/906, loss: 0.003094  [26432/28983] (41.263s) val loss: 0.005517
Batch 901/906, loss: 0.008311  [28832/28983] (41.237s) val loss: 0.006030
Batch 906/906, loss: 0.004930  [28983/28983] (16.082s) val loss: 0.005745
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.506s total
-------------------------------

Epoch 95
-------------------------------
Batch  76/906, loss: 0.005246  [ 2432/28983] (27.232s) val loss: 0.005709
Batch 151/906, loss: 0.006691  [ 4832/28983] (41.176s) val loss: 0.005643
Batch 226/906, loss: 0.006059  [ 7232/28983] (41.267s) val loss: 0.006222
Batch 301/906, loss: 0.002560  [ 9632/28983] (41.295s) val loss: 0.005573
Batch 376/906, loss: 0.005701  [12032/28983] (41.186s) val loss: 0.005865
Batch 451/906, loss: 0.003887  [14432/28983] (41.257s) val loss: 0.006343
Batch 526/906, loss: 0.005371  [16832/28983] (41.297s) val loss: 0.005682
Batch 601/906, loss: 0.004751  [19232/28983] (41.266s) val loss: 0.005922
Batch 676/906, loss: 0.007530  [21632/28983] (41.274s) val loss: 0.005797
Batch 751/906, loss: 0.008636  [24032/28983] (41.370s) val loss: 0.005680
Batch 826/906, loss: 0.002902  [26432/28983] (41.224s) val loss: 0.006396
Batch 901/906, loss: 0.005096  [28832/28983] (41.178s) val loss: 0.006782
Batch 906/906, loss: 0.005575  [28983/28983] (16.065s) val loss: 0.006385
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.722s total
-------------------------------

Epoch 96
-------------------------------
Batch  76/906, loss: 0.007550  [ 2432/28983] (27.163s) val loss: 0.005709
Batch 151/906, loss: 0.004009  [ 4832/28983] (41.136s) val loss: 0.006528
Batch 226/906, loss: 0.010550  [ 7232/28983] (41.171s) val loss: 0.005939
Batch 301/906, loss: 0.007079  [ 9632/28983] (41.198s) val loss: 0.005755
Batch 376/906, loss: 0.003718  [12032/28983] (41.092s) val loss: 0.005652
Batch 451/906, loss: 0.011440  [14432/28983] (41.151s) val loss: 0.005589
Batch 526/906, loss: 0.007224  [16832/28983] (41.156s) val loss: 0.005818
Batch 601/906, loss: 0.002353  [19232/28983] (41.181s) val loss: 0.006043
Batch 676/906, loss: 0.013086  [21632/28983] (41.213s) val loss: 0.005974
Batch 751/906, loss: 0.003489  [24032/28983] (41.190s) val loss: 0.005864
Batch 826/906, loss: 0.004299  [26432/28983] (41.188s) val loss: 0.006182
Batch 901/906, loss: 0.003725  [28832/28983] (41.228s) val loss: 0.006509
Batch 906/906, loss: 0.002652  [28983/28983] (16.169s) val loss: 0.006117
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.884s total
-------------------------------

Epoch 97
-------------------------------
Batch  76/906, loss: 0.004191  [ 2432/28983] (27.181s) val loss: 0.006152
Batch 151/906, loss: 0.002415  [ 4832/28983] (41.084s) val loss: 0.005792
Batch 226/906, loss: 0.003689  [ 7232/28983] (41.195s) val loss: 0.005699
Batch 301/906, loss: 0.005005  [ 9632/28983] (41.186s) val loss: 0.005647
Batch 376/906, loss: 0.002903  [12032/28983] (41.116s) val loss: 0.005715
Batch 451/906, loss: 0.003673  [14432/28983] (41.200s) val loss: 0.005747
Batch 526/906, loss: 0.005470  [16832/28983] (41.175s) val loss: 0.006376
Batch 601/906, loss: 0.002480  [19232/28983] (41.208s) val loss: 0.005598
Batch 676/906, loss: 0.003531  [21632/28983] (41.198s) val loss: 0.005721
Batch 751/906, loss: 0.003229  [24032/28983] (41.192s) val loss: 0.005961
Batch 826/906, loss: 0.002304  [26432/28983] (41.181s) val loss: 0.005729
Batch 901/906, loss: 0.001559  [28832/28983] (41.190s) val loss: 0.005885
Batch 906/906, loss: 0.006839  [28983/28983] (16.067s) val loss: 0.006127
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.823s total
-------------------------------

Epoch 98
-------------------------------
Batch  76/906, loss: 0.005999  [ 2432/28983] (27.197s) val loss: 0.006127
Batch 151/906, loss: 0.004729  [ 4832/28983] (41.139s) val loss: 0.005647
Batch 226/906, loss: 0.004608  [ 7232/28983] (41.172s) val loss: 0.005652
Batch 301/906, loss: 0.004162  [ 9632/28983] (41.176s) val loss: 0.006069
Batch 376/906, loss: 0.003044  [12032/28983] (41.094s) val loss: 0.006323
Batch 451/906, loss: 0.009057  [14432/28983] (41.170s) val loss: 0.005834
Batch 526/906, loss: 0.004785  [16832/28983] (41.208s) val loss: 0.005911
Batch 601/906, loss: 0.003532  [19232/28983] (41.196s) val loss: 0.006175
Batch 676/906, loss: 0.005927  [21632/28983] (41.169s) val loss: 0.005734
Batch 751/906, loss: 0.003003  [24032/28983] (41.159s) val loss: 0.005872
Batch 826/906, loss: 0.005063  [26432/28983] (41.211s) val loss: 0.005751
Batch 901/906, loss: 0.005832  [28832/28983] (41.186s) val loss: 0.005612
Batch 906/906, loss: 0.005328  [28983/28983] (16.059s) val loss: 0.005740
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.767s total
-------------------------------

Epoch 99
-------------------------------
Batch  76/906, loss: 0.004496  [ 2432/28983] (27.154s) val loss: 0.005920
Batch 151/906, loss: 0.003935  [ 4832/28983] (41.107s) val loss: 0.005650
Batch 226/906, loss: 0.004917  [ 7232/28983] (41.156s) val loss: 0.006145
Batch 301/906, loss: 0.009497  [ 9632/28983] (41.201s) val loss: 0.005629
Batch 376/906, loss: 0.003801  [12032/28983] (41.252s) val loss: 0.006307
Batch 451/906, loss: 0.002109  [14432/28983] (41.242s) val loss: 0.005848
Batch 526/906, loss: 0.002842  [16832/28983] (41.211s) val loss: 0.005463
Batch 601/906, loss: 0.003613  [19232/28983] (41.218s) val loss: 0.006159
Batch 676/906, loss: 0.003238  [21632/28983] (41.218s) val loss: 0.005368
Batch 751/906, loss: 0.004689  [24032/28983] (41.228s) val loss: 0.005631
Batch 826/906, loss: 0.002763  [26432/28983] (41.243s) val loss: 0.005578
Batch 901/906, loss: 0.003129  [28832/28983] (41.221s) val loss: 0.006308
Batch 906/906, loss: 0.005320  [28983/28983] (16.072s) val loss: 0.006037
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.172s total
-------------------------------

Epoch 100
-------------------------------
Batch  76/906, loss: 0.004773  [ 2432/28983] (27.163s) val loss: 0.005454
Batch 151/906, loss: 0.003571  [ 4832/28983] (41.134s) val loss: 0.006078
Batch 226/906, loss: 0.001562  [ 7232/28983] (41.176s) val loss: 0.005486
Batch 301/906, loss: 0.004846  [ 9632/28983] (41.203s) val loss: 0.006711
Batch 376/906, loss: 0.002545  [12032/28983] (41.127s) val loss: 0.005944
Batch 451/906, loss: 0.003131  [14432/28983] (41.225s) val loss: 0.005631
Batch 526/906, loss: 0.001733  [16832/28983] (41.191s) val loss: 0.005617
Batch 601/906, loss: 0.004465  [19232/28983] (41.275s) val loss: 0.005929
Batch 676/906, loss: 0.005837  [21632/28983] (41.523s) val loss: 0.005694
Batch 751/906, loss: 0.009379  [24032/28983] (41.203s) val loss: 0.005625
Batch 826/906, loss: 0.002351  [26432/28983] (41.210s) val loss: 0.006615
Batch 901/906, loss: 0.003765  [28832/28983] (41.224s) val loss: 0.006470
Batch 906/906, loss: 0.000918  [28983/28983] (16.092s) val loss: 0.005815
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.411s total
-------------------------------

Epoch 101
-------------------------------
Batch  76/906, loss: 0.004875  [ 2432/28983] (27.187s) val loss: 0.006107
Batch 151/906, loss: 0.002676  [ 4832/28983] (41.133s) val loss: 0.006203
Batch 226/906, loss: 0.006744  [ 7232/28983] (41.210s) val loss: 0.005792
Batch 301/906, loss: 0.008833  [ 9632/28983] (41.190s) val loss: 0.005557
Batch 376/906, loss: 0.002748  [12032/28983] (41.112s) val loss: 0.005567
Batch 451/906, loss: 0.005600  [14432/28983] (41.234s) val loss: 0.005687
Batch 526/906, loss: 0.005503  [16832/28983] (41.205s) val loss: 0.006298
Batch 601/906, loss: 0.003088  [19232/28983] (41.211s) val loss: 0.005792
Batch 676/906, loss: 0.008669  [21632/28983] (41.199s) val loss: 0.005743
Batch 751/906, loss: 0.006015  [24032/28983] (41.244s) val loss: 0.006436
Batch 826/906, loss: 0.003587  [26432/28983] (41.238s) val loss: 0.005545
Batch 901/906, loss: 0.003960  [28832/28983] (41.204s) val loss: 0.006078
Batch 906/906, loss: 0.001945  [28983/28983] (16.087s) val loss: 0.005664
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.119s total
-------------------------------

Epoch 102
-------------------------------
Batch  76/906, loss: 0.001915  [ 2432/28983] (27.161s) val loss: 0.005845
Batch 151/906, loss: 0.002121  [ 4832/28983] (41.140s) val loss: 0.005735
Batch 226/906, loss: 0.002724  [ 7232/28983] (41.170s) val loss: 0.005974
Batch 301/906, loss: 0.005160  [ 9632/28983] (41.186s) val loss: 0.005951
Batch 376/906, loss: 0.004989  [12032/28983] (41.125s) val loss: 0.007158
Batch 451/906, loss: 0.005058  [14432/28983] (41.165s) val loss: 0.005500
Batch 526/906, loss: 0.004723  [16832/28983] (41.168s) val loss: 0.005841
Batch 601/906, loss: 0.003273  [19232/28983] (41.187s) val loss: 0.006517
Batch 676/906, loss: 0.003656  [21632/28983] (41.191s) val loss: 0.005733
Batch 751/906, loss: 0.007593  [24032/28983] (41.205s) val loss: 0.006091
Batch 826/906, loss: 0.003089  [26432/28983] (41.186s) val loss: 0.005811
Batch 901/906, loss: 0.004445  [28832/28983] (41.204s) val loss: 0.005238
Batch 906/906, loss: 0.002047  [28983/28983] (16.105s) val loss: 0.005229
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.860s total
-------------------------------

Epoch 103
-------------------------------
Batch  76/906, loss: 0.005690  [ 2432/28983] (27.191s) val loss: 0.006224
Batch 151/906, loss: 0.007276  [ 4832/28983] (41.045s) val loss: 0.006580
Batch 226/906, loss: 0.005103  [ 7232/28983] (41.148s) val loss: 0.006119
Batch 301/906, loss: 0.002638  [ 9632/28983] (41.163s) val loss: 0.005618
Batch 376/906, loss: 0.002678  [12032/28983] (41.092s) val loss: 0.005942
Batch 451/906, loss: 0.008311  [14432/28983] (41.171s) val loss: 0.005577
Batch 526/906, loss: 0.006934  [16832/28983] (41.145s) val loss: 0.005516
Batch 601/906, loss: 0.002203  [19232/28983] (41.190s) val loss: 0.005738
Batch 676/906, loss: 0.003970  [21632/28983] (41.157s) val loss: 0.005589
Batch 751/906, loss: 0.002952  [24032/28983] (41.181s) val loss: 0.005713
Batch 826/906, loss: 0.003867  [26432/28983] (41.156s) val loss: 0.007391
Batch 901/906, loss: 0.004619  [28832/28983] (41.159s) val loss: 0.006091
Batch 906/906, loss: 0.002067  [28983/28983] (16.067s) val loss: 0.006154
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.543s total
-------------------------------

Epoch 104
-------------------------------
Batch  76/906, loss: 0.007937  [ 2432/28983] (27.199s) val loss: 0.006200
Batch 151/906, loss: 0.002625  [ 4832/28983] (41.110s) val loss: 0.005642
Batch 226/906, loss: 0.003398  [ 7232/28983] (41.218s) val loss: 0.005623
Batch 301/906, loss: 0.001845  [ 9632/28983] (41.148s) val loss: 0.005863
Batch 376/906, loss: 0.003840  [12032/28983] (41.073s) val loss: 0.005872
Batch 451/906, loss: 0.003306  [14432/28983] (41.165s) val loss: 0.005912
Batch 526/906, loss: 0.008753  [16832/28983] (41.145s) val loss: 0.006033
Batch 601/906, loss: 0.007528  [19232/28983] (41.179s) val loss: 0.005444
Batch 676/906, loss: 0.004137  [21632/28983] (41.204s) val loss: 0.005901
Batch 751/906, loss: 0.003122  [24032/28983] (41.174s) val loss: 0.005525
Batch 826/906, loss: 0.003525  [26432/28983] (41.454s) val loss: 0.005838
Batch 901/906, loss: 0.004210  [28832/28983] (41.518s) val loss: 0.005931
Batch 906/906, loss: 0.006508  [28983/28983] (16.253s) val loss: 0.006204
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.632s total
-------------------------------

Epoch 105
-------------------------------
Batch  76/906, loss: 0.004679  [ 2432/28983] (27.307s) val loss: 0.005397
Batch 151/906, loss: 0.004677  [ 4832/28983] (41.453s) val loss: 0.005367
Batch 226/906, loss: 0.008086  [ 7232/28983] (41.493s) val loss: 0.005401
Batch 301/906, loss: 0.003859  [ 9632/28983] (41.523s) val loss: 0.005983
Batch 376/906, loss: 0.003317  [12032/28983] (41.550s) val loss: 0.005702
Batch 451/906, loss: 0.002711  [14432/28983] (41.494s) val loss: 0.005453
Batch 526/906, loss: 0.003322  [16832/28983] (41.507s) val loss: 0.005490
Batch 601/906, loss: 0.002466  [19232/28983] (41.495s) val loss: 0.006046
Batch 676/906, loss: 0.003502  [21632/28983] (41.484s) val loss: 0.005474
Batch 751/906, loss: 0.008860  [24032/28983] (41.504s) val loss: 0.005698
Batch 826/906, loss: 0.004843  [26432/28983] (41.526s) val loss: 0.006408
Batch 901/906, loss: 0.004229  [28832/28983] (41.518s) val loss: 0.005921
Batch 906/906, loss: 0.004780  [28983/28983] (16.260s) val loss: 0.005633
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.918s total
-------------------------------

Epoch 106
-------------------------------
Batch  76/906, loss: 0.003389  [ 2432/28983] (27.324s) val loss: 0.005692
Batch 151/906, loss: 0.003646  [ 4832/28983] (41.417s) val loss: 0.005491
Batch 226/906, loss: 0.005698  [ 7232/28983] (41.491s) val loss: 0.006025
Batch 301/906, loss: 0.010360  [ 9632/28983] (41.489s) val loss: 0.005972
Batch 376/906, loss: 0.003800  [12032/28983] (41.426s) val loss: 0.006174
Batch 451/906, loss: 0.004183  [14432/28983] (41.509s) val loss: 0.005410
Batch 526/906, loss: 0.004824  [16832/28983] (41.524s) val loss: 0.005703
Batch 601/906, loss: 0.001528  [19232/28983] (41.480s) val loss: 0.005648
Batch 676/906, loss: 0.003119  [21632/28983] (41.503s) val loss: 0.005347
Batch 751/906, loss: 0.003257  [24032/28983] (41.532s) val loss: 0.005744
Batch 826/906, loss: 0.005655  [26432/28983] (41.504s) val loss: 0.005759
Batch 901/906, loss: 0.003129  [28832/28983] (41.504s) val loss: 0.005616
Batch 906/906, loss: 0.008065  [28983/28983] (16.218s) val loss: 0.007069
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.743s total
-------------------------------

Epoch 107
-------------------------------
Batch  76/906, loss: 0.003944  [ 2432/28983] (27.336s) val loss: 0.005858
Batch 151/906, loss: 0.007566  [ 4832/28983] (41.412s) val loss: 0.005512
Batch 226/906, loss: 0.009184  [ 7232/28983] (41.490s) val loss: 0.007324
Batch 301/906, loss: 0.004178  [ 9632/28983] (41.478s) val loss: 0.005618
Batch 376/906, loss: 0.004682  [12032/28983] (41.455s) val loss: 0.005678
Batch 451/906, loss: 0.003298  [14432/28983] (41.474s) val loss: 0.005419
Batch 526/906, loss: 0.003070  [16832/28983] (41.494s) val loss: 0.005295
Batch 601/906, loss: 0.003432  [19232/28983] (41.507s) val loss: 0.005294
Batch 676/906, loss: 0.004536  [21632/28983] (41.516s) val loss: 0.006097
Batch 751/906, loss: 0.005401  [24032/28983] (41.567s) val loss: 0.005687
Batch 826/906, loss: 0.004374  [26432/28983] (41.527s) val loss: 0.005719
Batch 901/906, loss: 0.005040  [28832/28983] (41.540s) val loss: 0.005828
Batch 906/906, loss: 0.004632  [28983/28983] (16.258s) val loss: 0.005766
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 514.904s total
-------------------------------

Epoch 108
-------------------------------
Batch  76/906, loss: 0.004300  [ 2432/28983] (27.346s) val loss: 0.005501
Batch 151/906, loss: 0.010197  [ 4832/28983] (41.481s) val loss: 0.005558
Batch 226/906, loss: 0.004764  [ 7232/28983] (41.508s) val loss: 0.005561
Batch 301/906, loss: 0.006452  [ 9632/28983] (41.539s) val loss: 0.005570
Batch 376/906, loss: 0.005481  [12032/28983] (41.455s) val loss: 0.005879
Batch 451/906, loss: 0.009135  [14432/28983] (41.552s) val loss: 0.005408
Batch 526/906, loss: 0.003732  [16832/28983] (41.568s) val loss: 0.005677
Batch 601/906, loss: 0.006114  [19232/28983] (41.546s) val loss: 0.006005
Batch 676/906, loss: 0.002917  [21632/28983] (41.501s) val loss: 0.005791
Batch 751/906, loss: 0.006907  [24032/28983] (41.529s) val loss: 0.005541
Batch 826/906, loss: 0.004575  [26432/28983] (41.499s) val loss: 0.006074
Batch 901/906, loss: 0.005074  [28832/28983] (41.584s) val loss: 0.005791
Batch 906/906, loss: 0.008105  [28983/28983] (16.318s) val loss: 0.005552
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 515.261s total
-------------------------------

Epoch 109
-------------------------------
Batch  76/906, loss: 0.003137  [ 2432/28983] (27.363s) val loss: 0.005738
Batch 151/906, loss: 0.005293  [ 4832/28983] (41.316s) val loss: 0.005542
Batch 226/906, loss: 0.005616  [ 7232/28983] (41.188s) val loss: 0.005863
Batch 301/906, loss: 0.004351  [ 9632/28983] (41.195s) val loss: 0.005567
Batch 376/906, loss: 0.014487  [12032/28983] (41.067s) val loss: 0.006303
Batch 451/906, loss: 0.004237  [14432/28983] (41.174s) val loss: 0.006049
Batch 526/906, loss: 0.005114  [16832/28983] (41.149s) val loss: 0.006063
Batch 601/906, loss: 0.004316  [19232/28983] (41.159s) val loss: 0.005415
Batch 676/906, loss: 0.004615  [21632/28983] (41.196s) val loss: 0.005522
Batch 751/906, loss: 0.005619  [24032/28983] (41.203s) val loss: 0.005358
Batch 826/906, loss: 0.004871  [26432/28983] (41.220s) val loss: 0.005308
Batch 901/906, loss: 0.004382  [28832/28983] (41.197s) val loss: 0.005973
Batch 906/906, loss: 0.014589  [28983/28983] (16.068s) val loss: 0.005951
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.205s total
-------------------------------

Epoch 110
-------------------------------
Batch  76/906, loss: 0.007501  [ 2432/28983] (27.184s) val loss: 0.005419
Batch 151/906, loss: 0.003581  [ 4832/28983] (41.099s) val loss: 0.005198
Batch 226/906, loss: 0.002332  [ 7232/28983] (41.190s) val loss: 0.005661
Batch 301/906, loss: 0.004618  [ 9632/28983] (41.166s) val loss: 0.005437
Batch 376/906, loss: 0.002029  [12032/28983] (41.120s) val loss: 0.005380
Batch 451/906, loss: 0.005204  [14432/28983] (41.227s) val loss: 0.005961
Batch 526/906, loss: 0.012955  [16832/28983] (41.191s) val loss: 0.005354
Batch 601/906, loss: 0.003306  [19232/28983] (41.188s) val loss: 0.005953
Batch 676/906, loss: 0.010811  [21632/28983] (41.238s) val loss: 0.005730
Batch 751/906, loss: 0.002384  [24032/28983] (41.201s) val loss: 0.005717
Batch 826/906, loss: 0.002659  [26432/28983] (41.161s) val loss: 0.005778
Batch 901/906, loss: 0.003465  [28832/28983] (41.193s) val loss: 0.005509
Batch 906/906, loss: 0.007757  [28983/28983] (16.081s) val loss: 0.005626
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.906s total
-------------------------------

Epoch 111
-------------------------------
Batch  76/906, loss: 0.002798  [ 2432/28983] (27.163s) val loss: 0.005679
Batch 151/906, loss: 0.003390  [ 4832/28983] (41.115s) val loss: 0.005568
Batch 226/906, loss: 0.004213  [ 7232/28983] (41.199s) val loss: 0.005670
Batch 301/906, loss: 0.003589  [ 9632/28983] (41.165s) val loss: 0.006943
Batch 376/906, loss: 0.004870  [12032/28983] (41.197s) val loss: 0.005842
Batch 451/906, loss: 0.008198  [14432/28983] (41.188s) val loss: 0.005768
Batch 526/906, loss: 0.003495  [16832/28983] (41.205s) val loss: 0.005667
Batch 601/906, loss: 0.002798  [19232/28983] (41.182s) val loss: 0.006001
Batch 676/906, loss: 0.006930  [21632/28983] (41.265s) val loss: 0.006954
Batch 751/906, loss: 0.004434  [24032/28983] (41.208s) val loss: 0.005926
Batch 826/906, loss: 0.003793  [26432/28983] (41.215s) val loss: 0.005819
Batch 901/906, loss: 0.004120  [28832/28983] (41.239s) val loss: 0.005645
Batch 906/906, loss: 0.003187  [28983/28983] (16.079s) val loss: 0.006162
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.100s total
-------------------------------

Epoch 112
-------------------------------
Batch  76/906, loss: 0.004254  [ 2432/28983] (27.212s) val loss: 0.005987
Batch 151/906, loss: 0.007075  [ 4832/28983] (41.166s) val loss: 0.005302
Batch 226/906, loss: 0.001298  [ 7232/28983] (41.183s) val loss: 0.005778
Batch 301/906, loss: 0.004446  [ 9632/28983] (41.164s) val loss: 0.006068
Batch 376/906, loss: 0.001984  [12032/28983] (41.108s) val loss: 0.005673
Batch 451/906, loss: 0.003968  [14432/28983] (41.200s) val loss: 0.006422
Batch 526/906, loss: 0.003462  [16832/28983] (41.175s) val loss: 0.005679
Batch 601/906, loss: 0.002653  [19232/28983] (41.233s) val loss: 0.005985
Batch 676/906, loss: 0.003799  [21632/28983] (41.152s) val loss: 0.005967
Batch 751/906, loss: 0.005894  [24032/28983] (41.177s) val loss: 0.005720
Batch 826/906, loss: 0.003902  [26432/28983] (41.165s) val loss: 0.005895
Batch 901/906, loss: 0.002443  [28832/28983] (41.179s) val loss: 0.006060
Batch 906/906, loss: 0.002699  [28983/28983] (16.054s) val loss: 0.006031
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.812s total
-------------------------------

Epoch 113
-------------------------------
Batch  76/906, loss: 0.004446  [ 2432/28983] (27.176s) val loss: 0.005752
Batch 151/906, loss: 0.001846  [ 4832/28983] (41.139s) val loss: 0.005703
Batch 226/906, loss: 0.005126  [ 7232/28983] (41.166s) val loss: 0.005839
Batch 301/906, loss: 0.000932  [ 9632/28983] (41.137s) val loss: 0.005390
Batch 376/906, loss: 0.004573  [12032/28983] (41.104s) val loss: 0.005698
Batch 451/906, loss: 0.004553  [14432/28983] (41.160s) val loss: 0.006110
Batch 526/906, loss: 0.004378  [16832/28983] (41.169s) val loss: 0.006012
Batch 601/906, loss: 0.003492  [19232/28983] (41.128s) val loss: 0.005557
Batch 676/906, loss: 0.004433  [21632/28983] (41.204s) val loss: 0.006207
Batch 751/906, loss: 0.007781  [24032/28983] (41.188s) val loss: 0.005710
Batch 826/906, loss: 0.001915  [26432/28983] (41.166s) val loss: 0.005795
Batch 901/906, loss: 0.003143  [28832/28983] (41.199s) val loss: 0.005849
Batch 906/906, loss: 0.005317  [28983/28983] (16.048s) val loss: 0.005791
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.597s total
-------------------------------

Epoch 114
-------------------------------
Batch  76/906, loss: 0.002349  [ 2432/28983] (27.144s) val loss: 0.005515
Batch 151/906, loss: 0.004881  [ 4832/28983] (41.119s) val loss: 0.006273
Batch 226/906, loss: 0.001526  [ 7232/28983] (41.180s) val loss: 0.005968
Batch 301/906, loss: 0.003444  [ 9632/28983] (41.190s) val loss: 0.006189
Batch 376/906, loss: 0.005417  [12032/28983] (41.128s) val loss: 0.005604
Batch 451/906, loss: 0.003658  [14432/28983] (41.165s) val loss: 0.005779
Batch 526/906, loss: 0.005205  [16832/28983] (41.185s) val loss: 0.005699
Batch 601/906, loss: 0.004643  [19232/28983] (41.185s) val loss: 0.006381
Batch 676/906, loss: 0.002686  [21632/28983] (41.179s) val loss: 0.005604
Batch 751/906, loss: 0.005318  [24032/28983] (41.194s) val loss: 0.006268
Batch 826/906, loss: 0.003010  [26432/28983] (41.178s) val loss: 0.005370
Batch 901/906, loss: 0.003240  [28832/28983] (41.189s) val loss: 0.005828
Batch 906/906, loss: 0.000628  [28983/28983] (16.161s) val loss: 0.005548
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.832s total
-------------------------------

Epoch 115
-------------------------------
Batch  76/906, loss: 0.003014  [ 2432/28983] (27.187s) val loss: 0.005681
Batch 151/906, loss: 0.003733  [ 4832/28983] (41.095s) val loss: 0.006044
Batch 226/906, loss: 0.004419  [ 7232/28983] (41.199s) val loss: 0.005756
Batch 301/906, loss: 0.002364  [ 9632/28983] (41.182s) val loss: 0.006055
Batch 376/906, loss: 0.006102  [12032/28983] (41.102s) val loss: 0.005751
Batch 451/906, loss: 0.004837  [14432/28983] (41.179s) val loss: 0.006330
Batch 526/906, loss: 0.004762  [16832/28983] (41.193s) val loss: 0.006694
Batch 601/906, loss: 0.008157  [19232/28983] (41.187s) val loss: 0.005504
Batch 676/906, loss: 0.002517  [21632/28983] (41.169s) val loss: 0.005854
Batch 751/906, loss: 0.002280  [24032/28983] (41.149s) val loss: 0.006370
Batch 826/906, loss: 0.007614  [26432/28983] (41.172s) val loss: 0.006458
Batch 901/906, loss: 0.004078  [28832/28983] (41.192s) val loss: 0.005859
Batch 906/906, loss: 0.002627  [28983/28983] (16.064s) val loss: 0.005909
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.704s total
-------------------------------

Epoch 116
-------------------------------
Batch  76/906, loss: 0.005325  [ 2432/28983] (27.187s) val loss: 0.005924
Batch 151/906, loss: 0.002712  [ 4832/28983] (41.111s) val loss: 0.005681
Batch 226/906, loss: 0.005203  [ 7232/28983] (41.268s) val loss: 0.006305
Batch 301/906, loss: 0.003388  [ 9632/28983] (41.239s) val loss: 0.005701
Batch 376/906, loss: 0.001650  [12032/28983] (41.179s) val loss: 0.005638
Batch 451/906, loss: 0.005449  [14432/28983] (41.193s) val loss: 0.006294
Batch 526/906, loss: 0.004388  [16832/28983] (41.190s) val loss: 0.005895
Batch 601/906, loss: 0.002730  [19232/28983] (41.185s) val loss: 0.005540
Batch 676/906, loss: 0.002353  [21632/28983] (41.192s) val loss: 0.006496
Batch 751/906, loss: 0.001353  [24032/28983] (41.165s) val loss: 0.005495
Batch 826/906, loss: 0.001839  [26432/28983] (41.161s) val loss: 0.005103
Batch 901/906, loss: 0.002290  [28832/28983] (41.171s) val loss: 0.005611
Batch 906/906, loss: 0.008541  [28983/28983] (16.088s) val loss: 0.005757
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.000s total
-------------------------------

Epoch 117
-------------------------------
Batch  76/906, loss: 0.006412  [ 2432/28983] (27.179s) val loss: 0.005727
Batch 151/906, loss: 0.000974  [ 4832/28983] (41.110s) val loss: 0.005574
Batch 226/906, loss: 0.003037  [ 7232/28983] (41.159s) val loss: 0.005806
Batch 301/906, loss: 0.005902  [ 9632/28983] (41.171s) val loss: 0.005499
Batch 376/906, loss: 0.004380  [12032/28983] (41.126s) val loss: 0.006264
Batch 451/906, loss: 0.002307  [14432/28983] (41.165s) val loss: 0.005498
Batch 526/906, loss: 0.005649  [16832/28983] (41.172s) val loss: 0.005545
Batch 601/906, loss: 0.003768  [19232/28983] (41.177s) val loss: 0.005922
Batch 676/906, loss: 0.003249  [21632/28983] (41.161s) val loss: 0.005997
Batch 751/906, loss: 0.005078  [24032/28983] (41.182s) val loss: 0.006329
Batch 826/906, loss: 0.003674  [26432/28983] (41.187s) val loss: 0.006050
Batch 901/906, loss: 0.004319  [28832/28983] (41.185s) val loss: 0.006284
Batch 906/906, loss: 0.002399  [28983/28983] (16.071s) val loss: 0.006049
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 510.718s total
-------------------------------

Epoch 118
-------------------------------
Batch  76/906, loss: 0.004354  [ 2432/28983] (27.176s) val loss: 0.006178
Batch 151/906, loss: 0.001524  [ 4832/28983] (41.109s) val loss: 0.005727
Batch 226/906, loss: 0.003173  [ 7232/28983] (41.202s) val loss: 0.005980
Batch 301/906, loss: 0.004236  [ 9632/28983] (41.202s) val loss: 0.006116
Batch 376/906, loss: 0.003618  [12032/28983] (41.151s) val loss: 0.006037
Batch 451/906, loss: 0.003071  [14432/28983] (41.212s) val loss: 0.006587
Batch 526/906, loss: 0.004582  [16832/28983] (41.251s) val loss: 0.005831
Batch 601/906, loss: 0.003113  [19232/28983] (41.322s) val loss: 0.005521
Batch 676/906, loss: 0.008068  [21632/28983] (41.197s) val loss: 0.006844
Batch 751/906, loss: 0.005626  [24032/28983] (41.233s) val loss: 0.005589
Batch 826/906, loss: 0.003157  [26432/28983] (41.189s) val loss: 0.006191
Batch 901/906, loss: 0.009061  [28832/28983] (41.216s) val loss: 0.005867
Batch 906/906, loss: 0.009913  [28983/28983] (16.081s) val loss: 0.006187
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.196s total
-------------------------------

Epoch 119
-------------------------------
Batch  76/906, loss: 0.005108  [ 2432/28983] (27.210s) val loss: 0.005662
Batch 151/906, loss: 0.002310  [ 4832/28983] (41.114s) val loss: 0.005855
Batch 226/906, loss: 0.003137  [ 7232/28983] (41.218s) val loss: 0.005959
Batch 301/906, loss: 0.009018  [ 9632/28983] (41.235s) val loss: 0.005459
Batch 376/906, loss: 0.004390  [12032/28983] (41.159s) val loss: 0.005437
Batch 451/906, loss: 0.002211  [14432/28983] (41.212s) val loss: 0.005834
Batch 526/906, loss: 0.004732  [16832/28983] (41.239s) val loss: 0.005711
Batch 601/906, loss: 0.006287  [19232/28983] (41.221s) val loss: 0.006000
Batch 676/906, loss: 0.007320  [21632/28983] (41.232s) val loss: 0.006400
Batch 751/906, loss: 0.003212  [24032/28983] (41.265s) val loss: 0.005538
Batch 826/906, loss: 0.005264  [26432/28983] (41.234s) val loss: 0.005677
Batch 901/906, loss: 0.004139  [28832/28983] (41.217s) val loss: 0.005635
Batch 906/906, loss: 0.004426  [28983/28983] (16.087s) val loss: 0.005901
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.291s total
-------------------------------

Epoch 120
-------------------------------
Batch  76/906, loss: 0.003470  [ 2432/28983] (27.166s) val loss: 0.005417
Batch 151/906, loss: 0.002706  [ 4832/28983] (41.154s) val loss: 0.005648
Batch 226/906, loss: 0.001827  [ 7232/28983] (41.203s) val loss: 0.005293
Batch 301/906, loss: 0.001736  [ 9632/28983] (41.209s) val loss: 0.005817
Batch 376/906, loss: 0.004514  [12032/28983] (41.152s) val loss: 0.005771
Batch 451/906, loss: 0.004271  [14432/28983] (41.215s) val loss: 0.005481
Batch 526/906, loss: 0.003551  [16832/28983] (41.191s) val loss: 0.005811
Batch 601/906, loss: 0.005869  [19232/28983] (41.208s) val loss: 0.006264
Batch 676/906, loss: 0.004266  [21632/28983] (41.227s) val loss: 0.005334
Batch 751/906, loss: 0.002728  [24032/28983] (41.259s) val loss: 0.005488
Batch 826/906, loss: 0.004144  [26432/28983] (41.228s) val loss: 0.005889
Batch 901/906, loss: 0.005173  [28832/28983] (41.221s) val loss: 0.005618
Batch 906/906, loss: 0.004615  [28983/28983] (16.086s) val loss: 0.005515
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.201s total
-------------------------------

Epoch 121
-------------------------------
Batch  76/906, loss: 0.003216  [ 2432/28983] (27.192s) val loss: 0.005559
Batch 151/906, loss: 0.007004  [ 4832/28983] (41.116s) val loss: 0.005639
Batch 226/906, loss: 0.007335  [ 7232/28983] (41.191s) val loss: 0.005622
Batch 301/906, loss: 0.001781  [ 9632/28983] (41.183s) val loss: 0.005684
Batch 376/906, loss: 0.001839  [12032/28983] (41.137s) val loss: 0.005309
Batch 451/906, loss: 0.007262  [14432/28983] (41.215s) val loss: 0.005474
Batch 526/906, loss: 0.002174  [16832/28983] (41.239s) val loss: 0.005294
Batch 601/906, loss: 0.006255  [19232/28983] (41.199s) val loss: 0.006538
Batch 676/906, loss: 0.000900  [21632/28983] (41.207s) val loss: 0.005590
Batch 751/906, loss: 0.003709  [24032/28983] (41.193s) val loss: 0.005687
Batch 826/906, loss: 0.005050  [26432/28983] (41.190s) val loss: 0.005632
Batch 901/906, loss: 0.009964  [28832/28983] (41.205s) val loss: 0.006338
Batch 906/906, loss: 0.002682  [28983/28983] (16.073s) val loss: 0.005893
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.017s total
-------------------------------

Epoch 122
-------------------------------
Batch  76/906, loss: 0.002408  [ 2432/28983] (27.182s) val loss: 0.005551
Batch 151/906, loss: 0.002704  [ 4832/28983] (41.155s) val loss: 0.006143
Batch 226/906, loss: 0.003891  [ 7232/28983] (41.267s) val loss: 0.006281
Batch 301/906, loss: 0.003938  [ 9632/28983] (41.180s) val loss: 0.005409
Batch 376/906, loss: 0.005966  [12032/28983] (41.150s) val loss: 0.005500
Batch 451/906, loss: 0.002301  [14432/28983] (41.214s) val loss: 0.005400
Batch 526/906, loss: 0.005688  [16832/28983] (41.230s) val loss: 0.005930
Batch 601/906, loss: 0.005434  [19232/28983] (41.202s) val loss: 0.006042
Batch 676/906, loss: 0.006139  [21632/28983] (41.194s) val loss: 0.005776
Batch 751/906, loss: 0.003975  [24032/28983] (41.211s) val loss: 0.005875
Batch 826/906, loss: 0.009675  [26432/28983] (41.196s) val loss: 0.006076
Batch 901/906, loss: 0.003839  [28832/28983] (41.196s) val loss: 0.005508
Batch 906/906, loss: 0.004781  [28983/28983] (16.108s) val loss: 0.005456
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.154s total
-------------------------------

Epoch 123
-------------------------------
Batch  76/906, loss: 0.003184  [ 2432/28983] (27.196s) val loss: 0.005458
Batch 151/906, loss: 0.006550  [ 4832/28983] (41.121s) val loss: 0.005723
Batch 226/906, loss: 0.004806  [ 7232/28983] (41.218s) val loss: 0.005227
Batch 301/906, loss: 0.003302  [ 9632/28983] (41.181s) val loss: 0.006027
Batch 376/906, loss: 0.003929  [12032/28983] (41.181s) val loss: 0.005577
Batch 451/906, loss: 0.001406  [14432/28983] (41.151s) val loss: 0.005704
Batch 526/906, loss: 0.003399  [16832/28983] (41.205s) val loss: 0.005737
Batch 601/906, loss: 0.002877  [19232/28983] (41.185s) val loss: 0.005834
Batch 676/906, loss: 0.002154  [21632/28983] (41.195s) val loss: 0.006714
Batch 751/906, loss: 0.002856  [24032/28983] (41.241s) val loss: 0.005720
Batch 826/906, loss: 0.003072  [26432/28983] (41.236s) val loss: 0.005678
Batch 901/906, loss: 0.003261  [28832/28983] (41.237s) val loss: 0.005351
Batch 906/906, loss: 0.006251  [28983/28983] (16.092s) val loss: 0.005356
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.114s total
-------------------------------

Epoch 124
-------------------------------
Batch  76/906, loss: 0.003505  [ 2432/28983] (27.189s) val loss: 0.005605
Batch 151/906, loss: 0.004012  [ 4832/28983] (41.131s) val loss: 0.005523
Batch 226/906, loss: 0.003907  [ 7232/28983] (41.240s) val loss: 0.005352
Batch 301/906, loss: 0.006382  [ 9632/28983] (41.209s) val loss: 0.006181
Batch 376/906, loss: 0.006317  [12032/28983] (41.152s) val loss: 0.005656
Batch 451/906, loss: 0.004664  [14432/28983] (41.240s) val loss: 0.005696
Batch 526/906, loss: 0.005080  [16832/28983] (41.191s) val loss: 0.005731
Batch 601/906, loss: 0.002608  [19232/28983] (41.223s) val loss: 0.006099
Batch 676/906, loss: 0.007362  [21632/28983] (41.214s) val loss: 0.005724
Batch 751/906, loss: 0.004286  [24032/28983] (41.213s) val loss: 0.005803
Batch 826/906, loss: 0.003610  [26432/28983] (41.223s) val loss: 0.005392
Batch 901/906, loss: 0.010119  [28832/28983] (41.232s) val loss: 0.006180
Batch 906/906, loss: 0.007473  [28983/28983] (16.105s) val loss: 0.006064
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.259s total
-------------------------------

Epoch 125
-------------------------------
Batch  76/906, loss: 0.002224  [ 2432/28983] (27.188s) val loss: 0.006732
Batch 151/906, loss: 0.002169  [ 4832/28983] (41.165s) val loss: 0.005406
Batch 226/906, loss: 0.006234  [ 7232/28983] (41.225s) val loss: 0.006019
Batch 301/906, loss: 0.005483  [ 9632/28983] (41.221s) val loss: 0.005915
Batch 376/906, loss: 0.005477  [12032/28983] (41.155s) val loss: 0.005436
Batch 451/906, loss: 0.002704  [14432/28983] (41.234s) val loss: 0.005668
Batch 526/906, loss: 0.003734  [16832/28983] (41.214s) val loss: 0.005672
Batch 601/906, loss: 0.003080  [19232/28983] (41.204s) val loss: 0.005371
Batch 676/906, loss: 0.009658  [21632/28983] (41.209s) val loss: 0.005395
Batch 751/906, loss: 0.002646  [24032/28983] (41.281s) val loss: 0.006223
Batch 826/906, loss: 0.004577  [26432/28983] (41.243s) val loss: 0.005349
Batch 901/906, loss: 0.009915  [28832/28983] (41.215s) val loss: 0.005907
Batch 906/906, loss: 0.005443  [28983/28983] (16.098s) val loss: 0.006490
Saved to /nfs/home/khom/test_projects/CNNTraining/models/final_model_2.pth
Took 511.326s total
-------------------------------

Took 64107.1911 seconds
Done!

